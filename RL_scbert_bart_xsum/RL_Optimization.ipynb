{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"RL_Transformers.ipynb"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Automatically generated by Colaboratory."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Original file is located at\n", "    https://colab.research.google.com/drive/1_V_Rl_Row_jpku091J0dJ2-lAEYtTmMp\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Commented out IPython magic to ensure Python compatibility.<br>\n", "title install { form-width: \"200px\" }<br>\n", "%cd /content/drive/MyDrive/Thesis/RL_scbert_bart_xsum<br>\n", "pip install -r requirements.txt<br>\n", "%cd /content/drive/MyDrive/Thesis/RL_scbert_bart_xsum/trl/trl<br>\n", "pip install transformers"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from transformers import AutoModelForSeq2SeqLM, BartTokenizer, BartModel, BartForConditionalGeneration, BartConfig, GPT2Config,GPT2LMHeadModel\n", "from transformers import top_k_top_p_filtering, GPT2Model\n", "from torch import nn\n", "from torch.nn import Identity\n", "import torch.nn.functional as F\n", "import torch"]}, {"cell_type": "markdown", "metadata": {}, "source": ["imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from transformers import GPT2Tokenizer, AutoModel, BartTokenizer,AutoTokenizer\n", "import sys\n", "sys.path.append('D:\\\\Thesis\\\\RL_scbert_bart_xsum\\\\trl\\\\trl')\n", "from gpt2 import *"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import gpt2\n", "from bart_xsum import *\n", "from ppo import *\n", "from transformers import BartPretrainedModel"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "def setup_seed(seed):\n", "  torch.manual_seed(seed)\n", "  torch.cuda.manual_seed_all(seed)\n", "  np.random.seed(seed)\n", "  torch.backends.cudnn.deteministic = True\n", "setup_seed(57)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n# **Load Model**\n<br>\n", "#@title init reward model { form-width: \"10%\" }<br>\n", "from transformers import BertModel,BertPreTrainedModel<br>\n", "import torch.nn as nn<br>\n", "class BertRegresser(BertPreTrainedModel):<br>\n", "    def __init__(self, config):<br>\n", "        super().__init__(config)<br>\n", "        self.bert = BertModel(config)<br>\n", "        #The output layer that takes the [CLS] representation and gives an output<br>\n", "        self.regressor = nn.Sequential(<br>\n", "            nn.Dropout(0.5),<br>\n", "            nn.Linear(768, 1))<br>\n", "    def forward(self, input_ids, attention_mask):<br>\n", "        #Feed the input to Bert model to obtain contextualized representations<br>\n", "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)<br>\n", "        #Obtain the representations of [CLS] heads<br>\n", "        logits = outputs[1]<br>\n", "        output = self.regressor(logits)<br>\n", "        <br>\n", "        return output<br>\n", "#@title load model, reference model and reward model { form-width: \"10%\" }<br>\n", "import os<br>\n", "config = BartConfig('facebook/bart-large-xsum', output_hidden_states=True)<br>\n", "model_name = 'D:\\\\Thesis\\\\RL_scbert_bart_xsum\\\\bart_large_xsum'<br>\n", "#load preptrained model<br>\n", "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, output_hidden_states=True).to('cuda')<br>\n", "#load reference model<br>\n", "ref_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, output_hidden_states=True).to('cuda')<br>\n", "#load reward model<br>\n", "reward_model = BertRegresser.from_pretrained('allenai/scibert_scivocab_uncased')<br>\n", "model_state, optimizer_state = torch.load('D:\\\\Thesis\\\\Models\\\\reward_model\\\\checkpoint')<br>\n", "reward_model.load_state_dict(model_state)<br>\n", "reward_model.to('cuda')<br>\n", "#load Valuehead<br>\n", "hmodel = ValueHead(config).to('cuda')<br>\n", "#@title load tokenizer<br>\n", "from transformers import AutoTokenizer<br>\n", "#load reward tokenizer<br>\n", "reward_tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')<br>\n", "#load model tokenizer<br>\n", "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-xsum')<br>\n", " **Load Data (Final Model is trained with \"gen_title_score_pairs_bestone\")**\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["title Load annotated data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "anno_sample = pd.read_json('D:\\\\Thesis\\\\output\\\\annotated_json\\\\dataset_140samples.json')\n", "def creat_tupel(sample_np):\n", "  ab = [sample_np[0]]*6\n", "  ht = [sample_np[1]]*6\n", "  indices = np.array([2, 5, 8, 11, 14, 17])\n", "  sysms = list(sample_np[2].keys())\n", "  sysms = ['original'] + sysms\n", "  gents = list(sample_np[2].values())\n", "  gents = [sample_np[1]] + gents\n", "  gents_scores = list(sample_np[3].values())\n", "  gents_scores = [gents_scores[i] for i in indices]\n", "  max_idx = gents_scores.index(max(gents_scores))\n", "  res = np.transpose(np.array([ab, ht, gents, gents_scores, sysms]))\n", "  return res[max_idx,:].reshape(1,5), res\n", "anno_sample_np =anno_sample.to_numpy()\n", "res = []\n", "res1 = []\n", "for row in anno_sample_np:\n", "  r1, r2 = creat_tupel(row)\n", "  res += r1.tolist()\n", "  res1 += r2.tolist()\n", "gen_title_score_pairs = np.array(res1)\n", "gen_title_score_pairs_bestone = np.array(res)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n# **3 Datasettings (only for analysis in default RL, final model using cross learning with all sample witgh best title)**\n<br>\n", "#@title pick bad annotated data or from bart-xsum<br>\n", "gen_title_score_pairs_bad = []<br>\n", "scores = gen_title_score_pairs_bestone[:,-2]<br>\n", "scores = np.array([float(s) for s in scores])<br>\n", "for row in gen_title_score_pairs_bestone:<br>\n", "  if float(row[-2]) <= np.mean(scores):<br>\n", "    gen_title_score_pairs_bad.append(row)<br>\n", "gen_title_score_pairs_bad = np.array(gen_title_score_pairs_bad)<br>\n", "#@title pick annotated data from bart-xsum<br>\n", "gen_title_score_pairs_xsum = []<br>\n", "for row in gen_title_score_pairs:<br>\n", "  if row[-1] == 'bart_xsum':<br>\n", "    gen_title_score_pairs_xsum.append(row)<br>\n", "gen_title_score_pairs_xsum = np.array(gen_title_score_pairs_xsum)<br>\n", "#@title pick good annotated data or from bart-xsum<br>\n", "gen_title_score_pairs_good = []<br>\n", "scores = gen_title_score_pairs_bestone[:,-2]<br>\n", "scores = np.array([float(s) for s in scores])<br>\n", "for row in gen_title_score_pairs_bestone:<br>\n", "  if float(row[-2]) >= np.mean(scores) or row[-1] == 'bart_xsum':<br>\n", "    gen_title_score_pairs_good.append(row)<br>\n", "gen_title_score_pairs_good = np.array(gen_title_score_pairs_good)<br>\n", " **2 Train Mode (Cross learning/ Default RL)**\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["title cross learning trainer { form-width: \"10%\" }"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["gen_kwargs = {\n", "    \"min_length\":-1,\n", "    \"top_k\": 2,\n", "    \"top_p\": 0.8,\n", "    \"do_sample\": True,\n", "    \"pad_token_id\": tokenizer.eos_token_id,\n", "    #\"length_penalty\" : -20.0,\n", "    #\"num_return_sequences\" : 5,\n", "    #\"repetition_penalty\" : 1.5,\n", "}\n", "def ACT_step(title_score_pairs, start_ids, stop_ids, tokenizer, model, ppo_trainer):\n", "  res = []\n", "  for i in range(start_ids, stop_ids):\n", "    row = title_score_pairs[i]\n", "    ref_response_txt = row[2]\n", "    #model_name = row[4]\n", "    original_title = row[1]\n", "    query_txt = row[0]\n", "    query_tensor = tokenizer(query_txt, return_tensors=\"pt\").to('cuda')\n", "    #act step\n", "    ref_response_tensor = tokenizer(ref_response_txt, return_tensors='pt').to('cuda')\n", "     # define a reward for response\n", "    t = '[CLS]' + query_txt + '[SEP]' + ref_response_txt\n", "    ref_reward_encode = reward_tokenizer(t, return_tensors='pt').to('cuda')\n", "    #reward_input = reward_encode.input_ids\n", "    #reward_att = reward_encode.attention_mask\n", "    ref_reward = reward_model(ref_reward_encode['input_ids'], ref_reward_encode['attention_mask']).squeeze(-1)\n", "    ref_reward = torch.tensor([ref_reward.item()]).to('cuda')\n", "    #reward = torch.tensor(float(row[3])).to('cuda')\n", "    # train model with ppo\n", "    train_stats = ppo_trainer.step(query_tensor[\"input_ids\"], ref_response_tensor[\"input_ids\"], ref_reward)\n\n", "    # get model response\n", "    '''response_tensor = model.generate(\n", "                input_ids = query_tensor[\"input_ids\"],\n", "                attention_mask = query_tensor[\"attention_mask\"],\n", "                max_length = 30,\n", "                num_beams = 5,\n", "                num_return_sequences = 1,\n", "                repetition_penalty=2.0, \n", "                length_penalty=10.0,\n", "                early_stopping = True,\n", "                ).to('cuda')'''\n", "    response_tensor = model.generate(input_ids = query_tensor[\"input_ids\"],\n", "                attention_mask = query_tensor[\"attention_mask\"], max_new_tokens=30, **gen_kwargs)[-30:].to('cuda')\n", "    response_txt = tokenizer.batch_decode(response_tensor, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n", "    #test ref model response(generated title from fine-tunde bart-xsum)\n", "    \n\n", "    # define a reward for response\n", "    t = '[CLS]' + query_txt + '[SEP]' + response_txt\n", "    reward_encode = reward_tokenizer(t, return_tensors='pt').to('cuda')\n", "    #reward_input = reward_encode.input_ids\n", "    #reward_att = reward_encode.attention_mask\n", "    reward = reward_model(reward_encode['input_ids'], reward_encode['attention_mask']).squeeze(-1)\n", "    reward = torch.tensor([reward.item()]).to('cuda')\n\n", "    # train model with ppo\n", "    train_stats = ppo_trainer.step(query_tensor[\"input_ids\"], response_tensor, reward)\n\n", "    #generate title with rewarded model\n", "    '''new_model_response_ids = model.generate(\n", "                input_ids = query_tensor[\"input_ids\"],\n", "                attention_mask = query_tensor[\"attention_mask\"],\n", "                max_length = 30,\n", "                num_beams = 5,\n", "                num_return_sequences = 1,\n", "                repetition_penalty=2.0, \n", "                length_penalty=10.0,\n", "                early_stopping = True,\n", "                )'''\n", "    new_model_response_ids = model.generate(input_ids = query_tensor[\"input_ids\"],\n", "                attention_mask = query_tensor[\"attention_mask\"], max_new_tokens=30, **gen_kwargs)[-30:].to('cuda')\n", "    new_model_response_ids = new_model_response_ids.cpu().data.numpy()\n", "    new_model_response_txt = tokenizer.batch_decode(new_model_response_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n", "    res.append([response_txt, new_model_response_txt])\n", "    if i % 10 == 0:\n", "      print('Original title: ', original_title)\n", "      print('Generated reference title: ', ref_response_txt)\n", "      print('RL-rewarded-after-step bart_xsum generated title: ', new_model_response_txt)\n", "      print('- - - -'*20 + '>')\n", "  return res"]}, {"cell_type": "markdown", "metadata": {}, "source": ["title default RL trainer { form-width: \"10%\" }"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["gen_kwargs = {\n", "    \"min_length\":-1,\n", "    \"top_k\": 2,\n", "    \"top_p\": 0.8,\n", "    \"do_sample\": True,\n", "    \"pad_token_id\": tokenizer.eos_token_id,\n", "    #\"length_penalty\" : 4.0,\n", "    #\"repetition_penalty\" : 1.5,\n", "}\n", "def RL_steps(title_score_pairs, start_ids, stop_ids, tokenizer, model, ppo_trainer):\n", "  res = []\n", "  for i in range(start_ids, stop_ids):\n", "    row = title_score_pairs[i]\n", "    #model_name = row[4]\n", "    original_title = row[1]\n", "    query_txt = row[0]\n", "    query_tensor = tokenizer(query_txt, return_tensors=\"pt\").to('cuda')\n", "    # get model response\n", "    '''response_tensor = model.generate(\n", "                input_ids = query_tensor[\"input_ids\"],\n", "                attention_mask = query_tensor[\"attention_mask\"],\n", "                max_length = 30,\n", "                num_beams = 5,\n", "                num_return_sequences = 1,\n", "                repetition_penalty=2.0, \n", "                length_penalty=10.0,\n", "                early_stopping = True,\n", "                ).to('cuda')'''\n", "                \n", "    response_tensor = model.generate(input_ids = query_tensor[\"input_ids\"],\n", "                attention_mask = query_tensor[\"attention_mask\"], max_new_tokens=30, **gen_kwargs)[-30:].to('cuda')\n", "    response_txt = tokenizer.batch_decode(response_tensor, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n", "    #test ref model response(generated title from fine-tunde bart-xsum)\n", "    #ref_response_txt = row[2]\n\n", "    # define a reward for response\n", "    t = '[CLS]' + query_txt + '[SEP]' + response_txt\n", "    reward_encode = reward_tokenizer(t, return_tensors='pt').to('cuda')\n", "    #reward_input = reward_encode.input_ids\n", "    #reward_att = reward_encode.attention_mask\n", "    reward = reward_model(reward_encode['input_ids'], reward_encode['attention_mask']).squeeze(-1)\n", "    #reward = row[2].item()\n", "    reward = torch.tensor([reward.item()]).to('cuda')\n\n", "    # train model with ppo\n", "    train_stats = ppo_trainer.step(query_tensor[\"input_ids\"], response_tensor, reward)\n\n", "    #generate title with rewarded model\n", "    new_model_response_ids = model.generate(\n", "                input_ids = query_tensor[\"input_ids\"],\n", "                attention_mask = query_tensor[\"attention_mask\"],\n", "                max_length = 30,\n", "                num_beams = 5,\n", "                num_return_sequences = 1,\n", "                repetition_penalty=2.0, \n", "                length_penalty=10.0,\n", "                early_stopping = True,\n", "                )\n", "    new_model_response_ids = new_model_response_ids.cpu().data.numpy()\n", "    new_model_response_txt = tokenizer.batch_decode(new_model_response_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n", "    res.append([response_txt, new_model_response_txt])\n", "    if i % 6 == 0:\n", "      print('Original title: ', original_title)\n", "      #print('Generated reference title: ', ref_response_txt)\n", "      print('RL-rewarded-after-step bart_xsum generated title: ', new_model_response_txt)\n", "      print('- - - -'*20 + '>')\n", "  return res"]}, {"cell_type": "markdown", "metadata": {}, "source": ["title test setup"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "df1 = pd.read_csv('/content/drive/MyDrive/Thesis/RL_scbert_bart_xsum/output/output_111_annotated_from_bart_xsum_lowLR.csv', index_col=0)<br>\n", "df2 = pd.read_csv('/content/drive/MyDrive/Thesis/RL_scbert_bart_xsum/output/output_111_annotated_from_bart_xsum_midLrEp.csv', index_col=0)<br>\n", "df3 = pd.read_csv('/content/drive/MyDrive/Thesis/RL_scbert_bart_xsum/output/output_111_annotated_from_bart_xsum_verylowLR.csv', index_col=0)<br>\n", "df4 = pd.read_csv('/content/drive/MyDrive/Thesis/RL_scbert_bart_xsum/output/output_111_annotated_from_bart_xsum_midLrEp_good_scores.csv', index_col=0)<br>\n", "ab = df1[['abstract']].to_numpy().squeeze()<br>\n", "ot = df1[['original title']].to_numpy().squeeze()<br>\n", "gt = df1[['generated title before RL']].to_numpy().squeeze()<br>\n", "t1 = df1[['generated title after RL']].to_numpy().squeeze()<br>\n", "t2 = df2[['title-xsum-reward']].to_numpy().squeeze()<br>\n", "t3 = df3[['generated title after RL']].to_numpy().squeeze()<br>\n", "t4 = df1[['generated title after RL']].to_numpy().squeeze()<br>\n", "ttt = np.array([ab,ot,gt,t1,t2,t3,t4]).transpose()<br>\n", "df = pd.DataFrame(ttt)<br>\n", "df.columns =['abstracz','human title', 'before RL', 'low LR', 'mid LR', 'very low LR', 'mid LR goog only']<br>\n", "df.to_csv('/content/drive/MyDrive/Thesis/RL_scbert_bart_xsum/output/output_111_dif_setup.csv')<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n# **Train Settings and Do Train**\n<br>\n", "from threading import active_count<br>\n", "#@title initialize PPOtrainer<br>\n", "# initialize trainer<br>\n", "#ppo_config = {'batch_size': 1, 'forward_batch_size': 1}<br>\n", "ppo_config = {<br>\n", "        \"lr\": 2e-6,#1.41e-5,#6e-7,#\"lr\": 3e-6,#,<br>\n", "        \"adap_kl_ctrl\": True,<br>\n", "        \"init_kl_coef\":0.2,<br>\n", "        \"target\": 6,<br>\n", "        \"horizon\":10000,<br>\n", "        \"gamma\":1,<br>\n", "        \"lam\":0.95,<br>\n", "        \"cliprange\": .2,<br>\n", "        \"cliprange_value\":.2,<br>\n", "        \"vf_coef\":.1,<br>\n", "        \"batch_size\": 1,<br>\n", "        \"forward_batch_size\": 1,<br>\n", "        \"ppo_epochs\": 3,<br>\n", "    }<br>\n", "ppo_trainer = PPOTrainer(model, ref_model, hmodel, **ppo_config)<br>\n", "res = ACT_step(gen_title_score_pairs_bestone, 0, len(gen_title_score_pairs_bestone), tokenizer, model, ppo_trainer)<br>\n", "#res = RL_steps(gen_title_score_pairs_bad, 0, len(gen_title_score_pairs_bad), tokenizer, model, ppo_trainer)<br>\n", " **Debug**\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_txt = \"This bachelor thesis explores the generation of title based on a given abstract using neural language model. Recently, neural language models have been used in many scenarios with practical applications. For example, in scientific writing, automatic summary generation from long texts is used to assist in the reading and selection of relevant scientific articles. Title is an important part of scientific article, but the title generation using neural language and optimization for neural language model based on human preferences are less studied. This thesis addresses this gap and presents an optimized model based on state-of-the-art pre-trained neural language model which generate human-preferred titles from a given abstract. The model is fine-tuned on datasets of scientific article and optimized from human preferences using the novel learning perspective in reinforcement learning environment. The result shows that, the neural language model have powerful capabilities on the abstract-to-title task and the reinforcement learning approach is effective in scalable learning of neural language model.\"\n", " \n", "query_tensor = tokenizer(query_txt, return_tensors=\"pt\").to('cuda')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ref_tensor=model.generate(input_ids = query_tensor[\"input_ids\"], \n", "                          attention_mask = query_tensor[\"attention_mask\"], \n", "                          max_new_tokens=30, \n", "                          **gen_kwargs)[-30:].to('cuda')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ref_tensor = model.generate(\n", "              input_ids = query_tensor[\"input_ids\"],\n", "              attention_mask = query_tensor[\"attention_mask\"],\n", "              max_length = 30,\n", "              num_beams = 5,\n", "              num_return_sequences = 1,\n", "              repetition_penalty=2.0, \n", "              length_penalty=10.0,\n", "              early_stopping = True,\n", "              ).to('cuda')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ref_txt = tokenizer.batch_decode(ref_tensor, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n# **Generation**\n<br>\n", "#@title write out file { form-width: \"10%\" }<br>\n", "outres = []<br>\n", "for row in gen_title_score_pairs_bestone:<br>\n", "  ab = row[0]<br>\n", "  ht = row[1]<br>\n", "  ogt = row[2]<br>\n", "  query_txt = ab<br>\n", "  query_tensor = tokenizer(query_txt, return_tensors=\"pt\").to('cuda')<br>\n", "  #get ref model response<br>\n", "\nref_tensor = ref_model.generate("]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["              input_ids = query_tensor[\"input_ids\"],\n", "              attention_mask = query_tensor[\"attention_mask\"],\n", "              max_length = 30,\n", "              num_beams = 5,\n", "              num_return_sequences = 1,\n", "              repetition_penalty=2.0, \n", "              length_penalty=10.0,\n", "              early_stopping = True,\n", "              ).to('cuda')'''\n", "  ref_tensor=ref_model.generate(input_ids = query_tensor[\"input_ids\"], \n", "                          attention_mask = query_tensor[\"attention_mask\"], \n", "                          max_new_tokens=30, \n", "                          **gen_kwargs)[-30:].to('cuda')\n", "  ref_txt = tokenizer.batch_decode(ref_tensor, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n", "  # get model response\n", "  '''response_tensor = model.generate(\n", "              input_ids = query_tensor[\"input_ids\"],\n", "              attention_mask = query_tensor[\"attention_mask\"],\n", "              max_length = 30,\n", "              num_beams = 5,\n", "              num_return_sequences = 1,\n", "              repetition_penalty=2.0, \n", "              length_penalty=10.0,\n", "              early_stopping = True,\n", "              ).to('cuda')'''\n", "  response_tensor = model.generate(input_ids = query_tensor[\"input_ids\"], attention_mask = query_tensor[\"attention_mask\"], max_new_tokens=30, **gen_kwargs)[-30:].to('cuda')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  response_txt = tokenizer.batch_decode(response_tensor, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n", "  outres.append([ab, ht,ogt, ref_txt, response_txt])\n", "import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.DataFrame(outres)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.columns = ['abstract', 'original title','best title' , 'generated title before RL', 'generated title after RL']\n", "path='D:\\Thesis\\RL_scbert_bart_xsum\\output\\act_'+ \"{:.9f}\".format(ppo_config['lr'])+'_'+str(ppo_config['ppo_epochs'])+'.csv'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["f.to_csv(path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df.drop(['original title'], axis=1)\n", "df.columns = ['abstract', 'best title', 'title-xsum', 'title-xsum-reward']\n", "df_np = df.to_numpy()\n", "n_np = []\n", "for row in df_np:\n", "  ab = row[0]\n", "  ts = row[1:]\n", "  #ts[0] = ts[0]\n", "  #ts[0] = ts[0]\n", "  #ts = np.random.permutation(ts)\n", "  n_np.append([ab, ts[1], ts[2]])\n", "n_np = np.array(n_np)\n", "se = pd.DataFrame(n_np[:30])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n# **Analysis**\n<br>\n", "import pandas as pd<br>\n", "#@title load bartscore scorer<br>\n", "# %cd /content/drive/MyDrive/Thesis/BARTScore<br>\n", "import sys<br>\n", "sys.path.append('D:\\\\Thesis\\\\BARTScore-main')<br>\n", "from bart_score import BARTScorer<br>\n", "bart_scorer = BARTScorer(device='cuda:0',checkpoint='D:\\\\Thesis\\\\BARTScore-main\\\\bart_xsum')<br>\n", "# Commented out IPython magic to ensure Python compatibility.<br>\n", "#@title load moverscore scorer<br>\n", "# %cd /content/drive/MyDrive/Thesis/emnlp19-moverscore-master<br>\n", "ys.path.append('D:\\\\Thesis\\\\emnlp19-moverscore-master')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from moverscore_v2 import get_idf_dict, word_mover_score\n", "from typing import List, Union, Iterable\n", "from collections import defaultdict\n", "import numpy as np\n", "def sentence_score(hypothesis: str, references: List[str], trace=0):\n", "    \n", "    idf_dict_hyp = defaultdict(lambda: 1.)\n", "    idf_dict_ref = defaultdict(lambda: 1.)\n", "    \n", "    hypothesis = [hypothesis] * len(references)\n", "    \n", "    sentence_score = 0 \n", "    scores = word_mover_score(references, hypothesis, idf_dict_ref, idf_dict_hyp, stop_words=[], n_gram=1, remove_subwords=False)\n", "    \n", "    sentence_score = np.mean(scores)\n", "    \n", "    if trace > 0:\n", "        print(hypothesis, references, sentence_score)\n", "            \n", "    return sentence_score\n", "'''\n", "# Commented out IPython magic to ensure Python compatibility.\n", "#@title load bertscore scorer"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%cd /content/drive/MyDrive/Thesis/bert_score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "sys.path.append('D:\\\\Thesis\\\\bert_score-master')\n", "from bert_score import score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "df = pd.read_csv('D:\\\\Thesis\\\\RL_scbert_bart_xsum\\\\output\\\\output_111_annotated_from_bart_xsum_act_bad_final0.000002000_3.csv', index_col=0)[:30]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["abs = df['abstract'].to_list()\n", "ots = df['original title'].to_list()\n", "bts = df['best title'].to_list()\n", "ogts = df['generated title before RL'].to_list()\n", "rlts = df['generated title after RL'].to_list()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scores11 = bart_scorer.score(abs, ots, batch_size=1)\n", "scores21 = bart_scorer.score(abs, ogts, batch_size=1)\n", "scores31 = bart_scorer.score(abs, rlts, batch_size=1)\n", "'''\n", "scores12 = [sentence_score(ot, [ab]) for ot,ab in zip(ots, abs)]\n", "scores22 = [sentence_score(ogt, [ab]) for ogt,ab in zip(ogts, abs)]\n", "scores32 = [sentence_score(rlt, [ab]) for rlt,ab in zip(rlts, abs)]'''"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["p,r,score13 = score(ots, abs, lang=\"en\")\n", "p,r,score23 = score(ogts, abs, lang=\"en\")\n", "p,r,score33 = score(rlts, abs , lang=\"en\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ARTScore"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('abs_ots: ', sum(scores11)/len(scores11))\n", "print('abs_ogts: ', sum(scores21)/len(scores21))\n", "print('abs_rlts: ', sum(scores31)/len(scores31))\n", "import numpy as np\n", "#BertScore\n", "print('abs_ots: ', np.array(score13.tolist()).mean())\n", "print('abs_ogts: ', np.array(score23.tolist()).mean())\n", "print('abs_rlts: ', np.array(score33.tolist()).mean())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["overScore"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nprint('abs_ots: ', sum(scores12)/len(scores12))<br>\n", "print('abs_ogts: ', sum(scores22)/len(scores22))<br>\n", "int('abs_rlts: ', sum(scores32)/len(scores32))\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["r1 = [np.exp(-0.654991332689921), 0.8518536269664765, 0.5175741747308048]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["r2 = [np.exp(-0.6468217780192693), 0.8508123060067495, 0.5174440166876286]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["3 = [np.exp(-0.6468217780192693), 0.5174440166876286, 0.8508123060067495]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.decomposition import PCA\n", "from sklearn.preprocessing import normalize\n", "import numpy as np\n", "normalized_metrics = normalize(np.array([r1, r2]), axis=0, norm='l1')\n", "normalized_metrics"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.decomposition import PCA\n", "from sklearn.preprocessing import normalize\n", "import numpy as np\n", "normalized_metrics = normalize(np.array([r1, r2]), axis=0, norm='l1')\n", "normalized_metrics"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}