{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git_root\n",
    "\n",
    "PROJECT_ROOT = None\n",
    "in_colab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if in_colab:\n",
    "  print('Running on CoLab')\n",
    "  PROJECT_ROOT = \"/content/drive/MyDrive/DL4NLP/abstract-to-title-generation\"\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "\n",
    "else:\n",
    "  print('Running on local machine')\n",
    "  from git_root import git_root\n",
    "  PROJECT_ROOT = git_root()\n",
    "\n",
    "%cd {PROJECT_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data only pulls changed data\n",
    "!dvc pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset, load_metric\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIR = f\"{PROJECT_ROOT}/data\"\n",
    "FILTERED_DATA = f\"{PROJECT_ROOT}/data/filtered\"\n",
    "OUTPUT_DIR = f\"{PROJECT_ROOT}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and verify device for pytorch\n",
    "if torch.cuda.is_available():\n",
    "  device_id = \"cuda:0\"\n",
    "elif torch.backends.mps.is_available():\n",
    "  device_id = \"mps\"\n",
    "else:\n",
    "  device_id = \"cpu\"\n",
    "  \n",
    "print(device_id)\n",
    "\n",
    "device = torch.device(device_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"google/pegasus-xsum\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{FILTERED_DATA}/1024_characters_pairs.csv\", index_col=0)\n",
    "\n",
    "df = df.drop(columns=[\"title_length\", \"abstract_length\", \"token_len\"])\n",
    "df_train = df[:11864]\n",
    "df_valid = df[11864:]\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "valid_dataset = Dataset.from_pandas(df_valid)\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 512\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"abstract\"], max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"title\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "    \n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "valid_dataset = valid_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-lm_al_paper\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=6e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    gradient_accumulation_steps=8,\n",
    "    save_steps = 1000,\n",
    "    logging_steps = 185,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "old_collator = trainer.data_collator\n",
    "\n",
    "trainer.data_collator = lambda data: dict(old_collator(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(f\"{OUTPUT_DIR}/bigbird-pegasus\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test samples\n",
    "test_samples = pd.read_csv(f\"{FILTERED_DATA}/Kopie von test_pairs.csv\", index_col=0)\n",
    "test_samples[\"token_len\"] = test_samples[\"abstract\"].apply(lambda s: len('<pad>' + s + '</s>'))\n",
    "test_samples = test_samples[test_samples.token_len < 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_eval_pairs(model, tokenizer, abstracts, titles):\n",
    "    \n",
    "  preds = []\n",
    "\n",
    "  for abstract, title in zip(abstracts, titles):\n",
    "\n",
    "    encoding = tokenizer.encode_plus(abstract, return_tensors = \"pt\")\n",
    "    inputs = encoding[\"input_ids\"].to(device)\n",
    "    attention_masks = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    title_ids = model.generate(\n",
    "            input_ids = inputs,\n",
    "            attention_mask = attention_masks,\n",
    "            max_length = 30,\n",
    "            num_beams = 5,\n",
    "            num_return_sequences = 5,\n",
    "            repetition_penalty=2.0, \n",
    "            length_penalty=10.0,\n",
    "            early_stopping = True,\n",
    "            )\n",
    "\n",
    "    result = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in title_ids]\n",
    "    s=\"\"\n",
    "\n",
    "    for t in result:\n",
    "      s = s + \"<TITLE>\" + t\n",
    "    preds.append(s)\n",
    "\n",
    "    if len(preds) % 500 == 0:\n",
    "      print(\"original title: \", title)\n",
    "      print(\"generated title: \", preds[-1:])\n",
    "\n",
    "  return preds, titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = test_samples.abstract.to_list()\n",
    "titles = test_samples.title.to_list()\n",
    "\n",
    "# Generate titles\n",
    "preds, titles = creat_eval_pairs(model, tokenizer, abstracts, titles)\n",
    "pred_target_pairs = pd.DataFrame(list(zip(preds, titles)), columns=['predictions', 'targets'])\n",
    "pred_target_pairs.to_csv(\"/content/drive/MyDrive/Thesis/output/preds_targets_pairs/pegasus.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit ('3.10.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "426a8962a4e397ac98841b32bd3cc74bd467652b7acdfcb3db4c17a0c6c7a6b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
