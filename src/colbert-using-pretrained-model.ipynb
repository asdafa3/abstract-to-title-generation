{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from config import *\n",
    "import keras\n",
    "\n",
    "model = keras.models.load_model(f\"{MODEL_DIR}/colbert-trained/\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# complete code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:02.080436Z",
     "iopub.status.busy": "2021-03-29T08:43:02.079602Z",
     "iopub.status.idle": "2021-03-29T08:43:02.130477Z",
     "shell.execute_reply": "2021-03-29T08:43:02.129577Z"
    },
    "papermill": {
     "duration": 0.079797,
     "end_time": "2021-03-29T08:43:02.130587",
     "exception": false,
     "start_time": "2021-03-29T08:43:02.05079",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from ast import literal_eval\n",
    "\n",
    "def run(command):\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "    out, err = process.communicate()\n",
    "    print(out.decode('utf-8').strip())\n",
    "\n",
    "print('# CPU')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^model name\"')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^cpu MHz\"')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^cpu cores\"')\n",
    "\n",
    "print('# RAM')\n",
    "run('cat /proc/meminfo | egrep \"^MemTotal\"')\n",
    "\n",
    "print('# GPU')\n",
    "run('lspci | grep VGA')\n",
    "\n",
    "print('# OS')\n",
    "run('uname -a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:02.177099Z",
     "iopub.status.busy": "2021-03-29T08:43:02.176463Z",
     "iopub.status.idle": "2021-03-29T08:43:11.678132Z",
     "shell.execute_reply": "2021-03-29T08:43:11.678729Z"
    },
    "papermill": {
     "duration": 9.528184,
     "end_time": "2021-03-29T08:43:11.678854",
     "exception": false,
     "start_time": "2021-03-29T08:43:02.15067",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "# import bert_tokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras \n",
    "\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from transformers import *\n",
    "\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re    #for regex\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019612,
     "end_time": "2021-03-29T08:43:11.7194",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.699788",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Prep / tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019527,
     "end_time": "2021-03-29T08:43:11.758635",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.739108",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### 1. Read data and tokenizer\n",
    "\n",
    "Read tokenizer and data, as well as defining the maximum sequence length that will be used for the input to Bert (maximum is usually 512 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:11.804568Z",
     "iopub.status.busy": "2021-03-29T08:43:11.802828Z",
     "iopub.status.idle": "2021-03-29T08:43:11.805554Z",
     "shell.execute_reply": "2021-03-29T08:43:11.808368Z"
    },
    "papermill": {
     "duration": 0.030283,
     "end_time": "2021-03-29T08:43:11.808497",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.778214",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_sample_count = 1000 # 4000\n",
    "test_count = 1000\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 20\n",
    "MAX_SENTENCES = 5\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:11.853265Z",
     "iopub.status.busy": "2021-03-29T08:43:11.852537Z",
     "iopub.status.idle": "2021-03-29T08:43:12.526565Z",
     "shell.execute_reply": "2021-03-29T08:43:12.525978Z"
    },
    "papermill": {
     "duration": 0.698464,
     "end_time": "2021-03-29T08:43:12.526679",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.828215",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/input/200k-short-texts-for-humor-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020423,
     "end_time": "2021-03-29T08:43:12.568031",
     "exception": false,
     "start_time": "2021-03-29T08:43:12.547608",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:12.616099Z",
     "iopub.status.busy": "2021-03-29T08:43:12.61558Z",
     "iopub.status.idle": "2021-03-29T08:43:13.406837Z",
     "shell.execute_reply": "2021-03-29T08:43:13.406399Z"
    },
    "papermill": {
     "duration": 0.818548,
     "end_time": "2021-03-29T08:43:13.406935",
     "exception": false,
     "start_time": "2021-03-29T08:43:12.588387",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/200k-short-texts-for-humor-detection/dataset.csv')\n",
    "\n",
    "df_train = pd.read_csv('/kaggle/input/200k-short-texts-for-humor-detection/train.csv')\n",
    "display(df_train.head(3))\n",
    "df_train = df_train[:training_sample_count]\n",
    "\n",
    "df_test = pd.read_csv('/kaggle/input/200k-short-texts-for-humor-detection/dev.csv')\n",
    "display(df_test.head(3))\n",
    "df_test = df_test[:test_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:13.459951Z",
     "iopub.status.busy": "2021-03-29T08:43:13.455747Z",
     "iopub.status.idle": "2021-03-29T08:43:13.46956Z",
     "shell.execute_reply": "2021-03-29T08:43:13.470086Z"
    },
    "papermill": {
     "duration": 0.04181,
     "end_time": "2021-03-29T08:43:13.470207",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.428397",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df_y = df_test.copy()\n",
    "del df_test['humor']\n",
    "\n",
    "df_sub = test_df_y.copy()\n",
    "\n",
    "print(len(df),len(df_train),len(df_test))\n",
    "display(df_train.head())\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:13.520664Z",
     "iopub.status.busy": "2021-03-29T08:43:13.520069Z",
     "iopub.status.idle": "2021-03-29T08:43:13.525057Z",
     "shell.execute_reply": "2021-03-29T08:43:13.524603Z"
    },
    "papermill": {
     "duration": 0.031866,
     "end_time": "2021-03-29T08:43:13.525141",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.493275",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(list(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:13.578613Z",
     "iopub.status.busy": "2021-03-29T08:43:13.577767Z",
     "iopub.status.idle": "2021-03-29T08:43:13.583083Z",
     "shell.execute_reply": "2021-03-29T08:43:13.582502Z"
    },
    "papermill": {
     "duration": 0.034743,
     "end_time": "2021-03-29T08:43:13.583166",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.548423",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_categories = list(df_train.columns[[1]])\n",
    "input_categories = list(df_train.columns[[0]])\n",
    "\n",
    "TARGET_COUNT = len(output_categories)\n",
    "\n",
    "print('\\ninput categories:\\n\\t', input_categories)\n",
    "print('\\noutput TARGET_COUNT:\\n\\t', TARGET_COUNT)\n",
    "print('\\noutput categories:\\n\\t', output_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023995,
     "end_time": "2021-03-29T08:43:13.630641",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.606646",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 2. Preprocessing functions\n",
    "\n",
    "These are some functions that will be used to preprocess the raw text data into useable Bert inputs.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:13.683343Z",
     "iopub.status.busy": "2021-03-29T08:43:13.682538Z",
     "iopub.status.idle": "2021-03-29T08:43:13.906994Z",
     "shell.execute_reply": "2021-03-29T08:43:13.906555Z"
    },
    "papermill": {
     "duration": 0.252597,
     "end_time": "2021-03-29T08:43:13.907097",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.6545",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "MODEL_TYPE = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:13.960752Z",
     "iopub.status.busy": "2021-03-29T08:43:13.960068Z",
     "iopub.status.idle": "2021-03-29T08:43:14.515658Z",
     "shell.execute_reply": "2021-03-29T08:43:14.516092Z"
    },
    "papermill": {
     "duration": 0.584315,
     "end_time": "2021-03-29T08:43:14.516208",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.931893",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:14.581044Z",
     "iopub.status.busy": "2021-03-29T08:43:14.580438Z",
     "iopub.status.idle": "2021-03-29T08:43:14.583687Z",
     "shell.execute_reply": "2021-03-29T08:43:14.58327Z"
    },
    "papermill": {
     "duration": 0.04248,
     "end_time": "2021-03-29T08:43:14.583771",
     "exception": false,
     "start_time": "2021-03-29T08:43:14.541291",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_id(str1, str2, truncation_strategy, length):\n",
    "\n",
    "    inputs = tokenizer.encode_plus(str1, str2,\n",
    "        add_special_tokens=True,\n",
    "        max_length=length,\n",
    "        truncation_strategy=truncation_strategy)\n",
    "\n",
    "    input_ids =  inputs[\"input_ids\"]\n",
    "    input_masks = [1] * len(input_ids)\n",
    "    input_segments = inputs[\"token_type_ids\"]\n",
    "    padding_length = length - len(input_ids)\n",
    "    padding_id = tokenizer.pad_token_id\n",
    "    input_ids = input_ids + ([padding_id] * padding_length)\n",
    "    input_masks = input_masks + ([0] * padding_length)\n",
    "    input_segments = input_segments + ([0] * padding_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer):\n",
    "    model_input = []\n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input.append([])\n",
    "    \n",
    "    for _, row in tqdm(df[columns].iterrows()):\n",
    "        i = 0\n",
    "        \n",
    "        # sent\n",
    "        sentences = sent_tokenize(row.text)\n",
    "        for xx in range(MAX_SENTENCES):\n",
    "            s = sentences[xx] if xx<len(sentences) else ''\n",
    "            ids_q, masks_q, segments_q = return_id(s, None, 'longest_first', MAX_SENTENCE_LENGTH)\n",
    "            model_input[i].append(ids_q)\n",
    "            i+=1\n",
    "            model_input[i].append(masks_q)\n",
    "            i+=1\n",
    "            model_input[i].append(segments_q)\n",
    "            i+=1\n",
    "        \n",
    "        # full row\n",
    "        ids_q, masks_q, segments_q = return_id(row.text, None, 'longest_first', MAX_LENGTH)\n",
    "        model_input[i].append(ids_q)\n",
    "        i+=1\n",
    "        model_input[i].append(masks_q)\n",
    "        i+=1\n",
    "        model_input[i].append(segments_q)\n",
    "        \n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input[xx] = np.asarray(model_input[xx], dtype=np.int32)\n",
    "        \n",
    "    print(model_input[0].shape)\n",
    "    return model_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:14.691953Z",
     "iopub.status.busy": "2021-03-29T08:43:14.691155Z",
     "iopub.status.idle": "2021-03-29T08:49:42.485601Z",
     "shell.execute_reply": "2021-03-29T08:49:42.484561Z"
    },
    "papermill": {
     "duration": 387.845343,
     "end_time": "2021-03-29T08:49:42.485726",
     "exception": false,
     "start_time": "2021-03-29T08:43:14.640383",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs      = compute_input_arrays(df_train, input_categories, tokenizer)\n",
    "test_inputs = compute_input_arrays(df_test, input_categories, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:49:42.557361Z",
     "iopub.status.busy": "2021-03-29T08:49:42.556418Z",
     "iopub.status.idle": "2021-03-29T08:49:42.56174Z",
     "shell.execute_reply": "2021-03-29T08:49:42.562218Z"
    },
    "papermill": {
     "duration": 0.047335,
     "end_time": "2021-03-29T08:49:42.56236",
     "exception": false,
     "start_time": "2021-03-29T08:49:42.515025",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(inputs), len(inputs[0]), len(inputs[0][0]))\n",
    "\n",
    "# check out input for 7th row\n",
    "xx = 7\n",
    "print(df_train.iloc[xx,0])\n",
    "print(sent_tokenize(df_train.iloc[xx,0]))\n",
    "inputs[0][xx], inputs[3][xx], inputs[6][xx], inputs[15][xx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:49:42.631001Z",
     "iopub.status.busy": "2021-03-29T08:49:42.630194Z",
     "iopub.status.idle": "2021-03-29T08:49:42.63394Z",
     "shell.execute_reply": "2021-03-29T08:49:42.633541Z"
    },
    "papermill": {
     "duration": 0.040866,
     "end_time": "2021-03-29T08:49:42.634025",
     "exception": false,
     "start_time": "2021-03-29T08:49:42.593159",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])\n",
    "\n",
    "outputs = compute_output_arrays(df_train, output_categories)\n",
    "outputs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040148,
     "end_time": "2021-03-29T08:50:18.903097",
     "exception": false,
     "start_time": "2021-03-29T08:50:18.862949",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 5. Training, validation and testing\n",
    "\n",
    "Loops over the folds in gkf and trains each fold for 3 epochs --- with a learning rate of 3e-5 and batch_size of 6. A simple binary crossentropy is used as the objective-/loss-function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:50:19.001693Z",
     "iopub.status.busy": "2021-03-29T08:50:18.999548Z",
     "iopub.status.idle": "2021-03-29T08:50:19.013531Z",
     "shell.execute_reply": "2021-03-29T08:50:19.012967Z"
    },
    "papermill": {
     "duration": 0.073314,
     "end_time": "2021-03-29T08:50:19.013676",
     "exception": false,
     "start_time": "2021-03-29T08:50:18.940362",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "import sklearn\n",
    "def print_evaluation_metrics(y_true, y_pred, label='', is_regression=True, label2=''):\n",
    "    print('==================', label2)\n",
    "    ### For regression\n",
    "    if is_regression:\n",
    "        print('mean_absolute_error',label,':', sklearn.metrics.mean_absolute_error(y_true, y_pred))\n",
    "        print('mean_squared_error',label,':', sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "        print('r2 score',label,':', sklearn.metrics.r2_score(y_true, y_pred))\n",
    "        #     print('max_error',label,':', sklearn.metrics.max_error(y_true, y_pred))\n",
    "        return sklearn.metrics.mean_squared_error(y_true, y_pred)\n",
    "    else:\n",
    "        ### FOR Classification\n",
    "#         print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
    "#         print('average_precision_score',label,':', sklearn.metrics.average_precision_score(y_true, y_pred))\n",
    "#         print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
    "#         print('accuracy_score',label,':', sklearn.metrics.accuracy_score(y_true, y_pred))\n",
    "        print('f1_score',label,':', sklearn.metrics.f1_score(y_true, y_pred))\n",
    "        \n",
    "        matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "        print(matrix)\n",
    "        TP,TN,FP,FN = matrix[1][1],matrix[0][0],matrix[0][1],matrix[1][0]\n",
    "        Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "        Precision = TP/(TP+FP)\n",
    "        Recall = TP/(TP+FN)\n",
    "        F1 = 2*(Recall * Precision) / (Recall + Precision)\n",
    "        print('Acc', Accuracy, 'Prec', Precision, 'Rec', Recall, 'F1',F1)\n",
    "        return sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "print_evaluation_metrics([1,0], [0.9,0.1], '', True)\n",
    "print_evaluation_metrics([1,0], [1,1], '', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038588,
     "end_time": "2021-03-29T08:50:19.090696",
     "exception": false,
     "start_time": "2021-03-29T08:50:19.052108",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Loss function selection\n",
    "Regression problem between 0 and 1, so binary_crossentropy and mean_absolute_error seem good.\n",
    "\n",
    "Here are the explanations: https://www.dlology.com/blog/how-to-choose-last-layer-activation-and-loss-function/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_inputs = inputs\n",
    "valid_outputs = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict(valid_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:57:41.182252Z",
     "iopub.status.busy": "2021-03-29T11:57:41.181517Z",
     "iopub.status.idle": "2021-03-29T11:57:41.184593Z",
     "shell.execute_reply": "2021-03-29T11:57:41.185027Z"
    },
    "papermill": {
     "duration": 9.430336,
     "end_time": "2021-03-29T11:57:41.18514",
     "exception": false,
     "start_time": "2021-03-29T11:57:31.754804",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(valid_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:58:00.357834Z",
     "iopub.status.busy": "2021-03-29T11:58:00.356828Z",
     "iopub.status.idle": "2021-03-29T11:58:00.379559Z",
     "shell.execute_reply": "2021-03-29T11:58:00.380362Z"
    },
    "papermill": {
     "duration": 9.363135,
     "end_time": "2021-03-29T11:58:00.380535",
     "exception": false,
     "start_time": "2021-03-29T11:57:51.0174",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(valid_outputs.shape, preds.shape)\n",
    "print_evaluation_metrics(np.array(valid_outputs), np.array(preds), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 9.331535,
     "end_time": "2021-03-29T12:04:44.212433",
     "exception": false,
     "start_time": "2021-03-29T12:04:34.880898",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Binary submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T12:05:03.687138Z",
     "iopub.status.busy": "2021-03-29T12:05:03.686449Z",
     "iopub.status.idle": "2021-03-29T12:05:06.339052Z",
     "shell.execute_reply": "2021-03-29T12:05:06.337971Z"
    },
    "papermill": {
     "duration": 12.111,
     "end_time": "2021-03-29T12:05:06.339173",
     "exception": false,
     "start_time": "2021-03-29T12:04:54.228173",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in np.arange(0.1, 0.99, 0.1).tolist():\n",
    "    df_sub['pred_bi'] = (test_preds > split)\n",
    "\n",
    "    print_evaluation_metrics(df_sub['humor'], df_sub['pred_bi'], '', False, 'SPLIT on '+str(split))\n",
    "\n",
    "    df_sub.to_csv('sub3.csv', index=False)\n",
    "    df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T12:05:25.599968Z",
     "iopub.status.busy": "2021-03-29T12:05:25.599118Z",
     "iopub.status.idle": "2021-03-29T12:05:25.894039Z",
     "shell.execute_reply": "2021-03-29T12:05:25.894475Z"
    },
    "papermill": {
     "duration": 10.02187,
     "end_time": "2021-03-29T12:05:25.894599",
     "exception": false,
     "start_time": "2021-03-29T12:05:15.872729",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sub['pred_bi'] = (test_preds > 0.5)\n",
    "\n",
    "print_evaluation_metrics(df_sub['humor'], df_sub['pred_bi'], '', False, 'SPLIT on '+str(split))\n",
    "\n",
    "df_sub.to_csv('sub.csv', index=False)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T12:05:44.469166Z",
     "iopub.status.busy": "2021-03-29T12:05:44.468382Z",
     "iopub.status.idle": "2021-03-29T12:05:44.483077Z",
     "shell.execute_reply": "2021-03-29T12:05:44.482673Z"
    },
    "papermill": {
     "duration": 9.253716,
     "end_time": "2021-03-29T12:05:44.483167",
     "exception": false,
     "start_time": "2021-03-29T12:05:35.229451",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Texts that the model failed to correctly predict:')\n",
    "df_sub[df_sub['pred_bi']!=df_sub['humor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
