{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Kopie von bart_huggingface_trainer.ipynb","provenance":[{"file_id":"1DlV2tsDOx5o4ZQRKCAWsxHcUYcURFRHm","timestamp":1643234729469}],"machine_shape":"hm","collapsed_sections":[],"mount_file_id":"1HJjGJSGzgcgrE_dD9nCE0uOwl5EWlL_6","authorship_tag":"ABX9TyP2E+mKBxG28qHtO/nIUQAA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6791cc54159d48dcb9349a271e7d2044":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3e326190377d43989ee054a148ed9a0a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bf72310f347a417a8af4e87621513c0c","IPY_MODEL_e273d1fca37941a6871b1735bb3b710a","IPY_MODEL_f698e26dbf774bcbb2225edd5aaada35"]}},"3e326190377d43989ee054a148ed9a0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf72310f347a417a8af4e87621513c0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8598fec3b6a3475fa488de1f800e7c4d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad8c8c9507184b59a8f00c5df39158c5"}},"e273d1fca37941a6871b1735bb3b710a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c1f05b8249ac488294cd42907257afa9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":12,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":12,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e01c22ea2473403da217c4ad9169f172"}},"f698e26dbf774bcbb2225edd5aaada35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eaf968c74d6f40b997255fcdb62e93a3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 12/12 [00:02&lt;00:00,  5.55ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c12eb35ebbdd45c1a26aed7dcd599bff"}},"8598fec3b6a3475fa488de1f800e7c4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ad8c8c9507184b59a8f00c5df39158c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1f05b8249ac488294cd42907257afa9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e01c22ea2473403da217c4ad9169f172":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eaf968c74d6f40b997255fcdb62e93a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c12eb35ebbdd45c1a26aed7dcd599bff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b24072f8b1694bf6af0606c14660becc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c0616784d2543dba7d43597f648d32d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fea52f0c9539457e851da1aeaf45cedd","IPY_MODEL_f53f7a8102024889b9b4adb36d8bd5de","IPY_MODEL_e2184d3b947548678b0e57e18ce99f79"]}},"2c0616784d2543dba7d43597f648d32d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fea52f0c9539457e851da1aeaf45cedd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c54475782ca54c788148eb9dcbe248af","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d8dce2aa43e84f2eb7639abcf31cba7c"}},"f53f7a8102024889b9b4adb36d8bd5de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_95a797672a2945ddba7cbf8f77fe61d7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_64cbd7954f43400899d0866c3762ce9c"}},"e2184d3b947548678b0e57e18ce99f79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d5f6ac4161f94263a13a2fcfefb35421","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  3.47ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe7c0b3ca9a0443185f7a0aef77cc8e5"}},"c54475782ca54c788148eb9dcbe248af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d8dce2aa43e84f2eb7639abcf31cba7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95a797672a2945ddba7cbf8f77fe61d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"64cbd7954f43400899d0866c3762ce9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d5f6ac4161f94263a13a2fcfefb35421":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fe7c0b3ca9a0443185f7a0aef77cc8e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"813ffc2c98e74337a9c1118dd964ddec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0939ac155f4e4a9a9c34428c9979a887","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_025828a218214eb2861e7754faf2ff1b","IPY_MODEL_788759ae79e64d90b5dab2fbc11b3089"]}},"0939ac155f4e4a9a9c34428c9979a887":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"025828a218214eb2861e7754faf2ff1b":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5fc94612a291473282ffa08a606c7280","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":1688,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1688,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f4b1002dcd3b47f187014c8ccda5b7cc"}},"788759ae79e64d90b5dab2fbc11b3089":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c55a06bc24a34a6fa51836f9257c7053","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 1.65k/1.65k [00:00&lt;00:00, 84.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84e2b30f7bb44b86a3c61e054d58183f"}},"5fc94612a291473282ffa08a606c7280":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f4b1002dcd3b47f187014c8ccda5b7cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c55a06bc24a34a6fa51836f9257c7053":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"84e2b30f7bb44b86a3c61e054d58183f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f7135f5d09b4442aa97dbff239d41f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7f41847da54041628cdecf0a12e946d6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ce6677126c47422d95851b55571f0924","IPY_MODEL_66093cf660e245278217bd930d702770"]}},"7f41847da54041628cdecf0a12e946d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce6677126c47422d95851b55571f0924":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8469b1d9def7442e8a97603fd131be95","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae1256eb27cb4e359e3ce139a903453a"}},"66093cf660e245278217bd930d702770":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b81d89a4bfa84591afac04d65b764ccc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 878k/878k [00:01&lt;00:00, 828kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7f51338d0df44768efda2586db54ed2"}},"8469b1d9def7442e8a97603fd131be95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ae1256eb27cb4e359e3ce139a903453a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b81d89a4bfa84591afac04d65b764ccc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f7f51338d0df44768efda2586db54ed2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fcd750086b73440aacaf83f0a4cae88b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d5e2bcb3c9f44a39aeea0894b1a39bb3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a133ee2eb8d8497eb551b98948418026","IPY_MODEL_9ba5218c702b43bab0a4d052228e6fc1"]}},"d5e2bcb3c9f44a39aeea0894b1a39bb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a133ee2eb8d8497eb551b98948418026":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f94930b5f6324c33a86bfc19405b7968","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b6dee50f0134faebe511db712d9f25b"}},"9ba5218c702b43bab0a4d052228e6fc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_76da30d26deb4f0eb136ef0e6e36aa67","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 446k/446k [00:00&lt;00:00, 502kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2a2ab8e71db944d9969e694c843a4743"}},"f94930b5f6324c33a86bfc19405b7968":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3b6dee50f0134faebe511db712d9f25b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"76da30d26deb4f0eb136ef0e6e36aa67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2a2ab8e71db944d9969e694c843a4743":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e21a0564b2d540568dc07edef059328b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8efb7fbc96bb4090b60d0f64ba6c487b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7b838c6500bb4666b5beb226173c5792","IPY_MODEL_fa5af04628d2481199fdbc7f1adeef75"]}},"8efb7fbc96bb4090b60d0f64ba6c487b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b838c6500bb4666b5beb226173c5792":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9791a53106fe486ba62c910a9c96009a","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_de7e2367cf624dcab91ad1e39acb114f"}},"fa5af04628d2481199fdbc7f1adeef75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5843b0a5323a4e2e97cf8ff7b5d227f8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 1.29M/1.29M [00:01&lt;00:00, 1.23MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_45ce2df2ccc3472aa4477e54c45851c9"}},"9791a53106fe486ba62c910a9c96009a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"de7e2367cf624dcab91ad1e39acb114f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5843b0a5323a4e2e97cf8ff7b5d227f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"45ce2df2ccc3472aa4477e54c45851c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","source":["cd /content/drive/MyDrive/Thesis"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eiba090yII9p","executionInfo":{"status":"ok","timestamp":1644160487186,"user_tz":-60,"elapsed":8,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"46a017d7-1769-4e18-fdb2-6b22c5daeb7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Thesis\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kcgpu-Mj2Az0","executionInfo":{"status":"ok","timestamp":1644160505354,"user_tz":-60,"elapsed":18173,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"3807edb9-a61a-4be9-96e8-a97d8b710e53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tqdm==4.28.1\n","  Downloading tqdm-4.28.1-py2.py3-none-any.whl (45 kB)\n","\u001b[?25l\r\u001b[K     |███████▏                        | 10 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 20 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 30 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 40 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 45 kB 1.8 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (2.7.0)\n","Collecting datasets\n","  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\n","\u001b[K     |████████████████████████████████| 311 kB 6.5 MB/s \n","\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.10.0+cu111)\n","Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 104.3 MB/s \n","\u001b[?25hCollecting rouge-score\n","  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (3.2.5)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.23.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.1.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.10.0.2)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.1.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (13.0.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.13.3)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (2.7.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (2.7.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (2.7.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.6.3)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.43.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.19.5)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.17.3)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.37.1)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.1.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.3.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r requirements.txt (line 2)) (1.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (3.3.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (1.0.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (4.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (3.2.0)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 70.9 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 3)) (0.70.12.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 3)) (0.3.4)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 80.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 3)) (6.0.1)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 61.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.1 MB/s \n","\u001b[?25hCollecting datasets\n","  Downloading datasets-1.18.2-py3-none-any.whl (312 kB)\n","\u001b[K     |████████████████████████████████| 312 kB 65.6 MB/s \n","\u001b[?25h  Downloading datasets-1.18.1-py3-none-any.whl (311 kB)\n","\u001b[K     |████████████████████████████████| 311 kB 66.7 MB/s \n","\u001b[?25h  Downloading datasets-1.18.0-py3-none-any.whl (311 kB)\n","\u001b[K     |████████████████████████████████| 311 kB 57.8 MB/s \n","\u001b[?25h  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n","\u001b[K     |████████████████████████████████| 306 kB 72.2 MB/s \n","\u001b[?25h  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n","\u001b[K     |████████████████████████████████| 298 kB 44.5 MB/s \n","\u001b[?25h  Downloading datasets-1.16.0-py3-none-any.whl (298 kB)\n","\u001b[K     |████████████████████████████████| 298 kB 62.4 MB/s \n","\u001b[?25h  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n","\u001b[K     |████████████████████████████████| 290 kB 67.1 MB/s \n","\u001b[?25h  Downloading datasets-1.15.0-py3-none-any.whl (290 kB)\n","\u001b[K     |████████████████████████████████| 290 kB 74.4 MB/s \n","\u001b[?25hCollecting huggingface-hub<0.1.0,>=0.0.19\n","  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 4.1 MB/s \n","\u001b[?25hCollecting datasets\n","  Downloading datasets-1.14.0-py3-none-any.whl (290 kB)\n","\u001b[K     |████████████████████████████████| 290 kB 55.6 MB/s \n","\u001b[?25h  Downloading datasets-1.13.3-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 90.6 MB/s \n","\u001b[?25h  Downloading datasets-1.13.2-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 73.8 MB/s \n","\u001b[?25h  Downloading datasets-1.13.1-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 57.5 MB/s \n","\u001b[?25h  Downloading datasets-1.13.0-py3-none-any.whl (285 kB)\n","\u001b[K     |████████████████████████████████| 285 kB 57.1 MB/s \n","\u001b[?25h  Downloading datasets-1.12.1-py3-none-any.whl (270 kB)\n","\u001b[K     |████████████████████████████████| 270 kB 79.2 MB/s \n","\u001b[?25h  Downloading datasets-1.12.0-py3-none-any.whl (269 kB)\n","\u001b[K     |████████████████████████████████| 269 kB 90.4 MB/s \n","\u001b[?25h  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n","\u001b[K     |████████████████████████████████| 264 kB 36.0 MB/s \n","\u001b[?25h  Downloading datasets-1.10.2-py3-none-any.whl (542 kB)\n","\u001b[K     |████████████████████████████████| 542 kB 58.3 MB/s \n","\u001b[?25h  Downloading datasets-1.10.1-py3-none-any.whl (542 kB)\n","\u001b[K     |████████████████████████████████| 542 kB 55.1 MB/s \n","\u001b[?25h  Downloading datasets-1.10.0-py3-none-any.whl (542 kB)\n","\u001b[K     |████████████████████████████████| 542 kB 47.9 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 3)) (1.3.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets->-r requirements.txt (line 3)) (3.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets->-r requirements.txt (line 3)) (3.4.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets->-r requirements.txt (line 3)) (3.0.7)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirements.txt (line 4)) (1.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 6)) (2019.12.20)\n","Collecting pyyaml\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 57.5 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.16.1-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 44.6 MB/s \n","\u001b[?25h  Downloading transformers-4.16.0-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 64.8 MB/s \n","\u001b[?25h  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 55.1 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 32.8 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 52.6 MB/s \n","\u001b[?25h  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 52.5 MB/s \n","\u001b[?25h  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 67.4 MB/s \n","\u001b[?25h  Downloading transformers-4.12.4-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 64.1 MB/s \n","\u001b[?25h  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 81.7 MB/s \n","\u001b[?25h  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 65.3 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 69.3 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r requirements.txt (line 6)) (7.1.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (3.1.0)\n","Installing collected packages: tqdm, pyyaml, xxhash, tokenizers, sacremoses, huggingface-hub, fsspec, transformers, rouge-score, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.62.3\n","    Uninstalling tqdm-4.62.3:\n","      Successfully uninstalled tqdm-4.62.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.28.1 which is incompatible.\n","panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.28.1 which is incompatible.\n","fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.28.1 which is incompatible.\u001b[0m\n","Successfully installed datasets-1.10.0 fsspec-2022.1.0 huggingface-hub-0.0.19 pyyaml-6.0 rouge-score-0.0.4 sacremoses-0.0.47 tokenizers-0.10.3 tqdm-4.28.1 transformers-4.12.2 xxhash-2.0.2\n"]}]},{"cell_type":"code","source":["model_checkpoint = 'facebook/bart-base'\n"],"metadata":{"id":"hGFqccODaeIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tqdm -U\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":294},"id":"2-BzEqSq5aW-","executionInfo":{"status":"ok","timestamp":1643704122117,"user_tz":-60,"elapsed":4066,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"399642ee-c19e-458e-c3d1-a8bfd53d677a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.28.1)\n","Collecting tqdm\n","  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 3.0 MB/s \n","\u001b[?25hInstalling collected packages: tqdm\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.28.1\n","    Uninstalling tqdm-4.28.1:\n","      Successfully uninstalled tqdm-4.28.1\n","Successfully installed tqdm-4.62.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tqdm"]}}},"metadata":{}}]},{"cell_type":"code","source":["from datasets import load_metric\n"],"metadata":{"id":"pglc_wgIaky2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","    \n","    \n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"metadata":{"id":"VisOC8KZaxI3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"],"metadata":{"id":"IdRhq9sHa3xA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"/content/drive/MyDrive/Thesis/data/1024_length_data/train_pairs.csv\", index_col=0)\n","df"],"metadata":{"id":"c3FO11232ShQ","executionInfo":{"status":"ok","timestamp":1643552421173,"user_tz":-60,"elapsed":584,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"7031ef56-03c8-43c1-ff33-02218b0f9c5d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-3c14a117-0880-46d3-ab90-534ffa4715d9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>title_length</th>\n","      <th>abstract_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Natural Image Bases to Represent Neuroimaging ...</td>\n","      <td>Visual inspection of neuroimagery is susceptib...</td>\n","      <td>7</td>\n","      <td>132</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sluice Resolution without Hand-Crafted Feature...</td>\n","      <td>Sluice resolution in English is the problem of...</td>\n","      <td>9</td>\n","      <td>110</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Learning Translation Models from Monolingual C...</td>\n","      <td>Translation models often fail to generate good...</td>\n","      <td>7</td>\n","      <td>152</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentiment Adaptive End-to-End Dialog Systems</td>\n","      <td>End-to-end learning framework is useful for bu...</td>\n","      <td>5</td>\n","      <td>119</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>User-Friendly Text Prediction For Translators</td>\n","      <td>Text prediction is a form of interactive machi...</td>\n","      <td>5</td>\n","      <td>134</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21437</th>\n","      <td>Arabic Tokenization, Part-of-Speech Tagging an...</td>\n","      <td>We present an approach to using a morphologica...</td>\n","      <td>11</td>\n","      <td>58</td>\n","    </tr>\n","    <tr>\n","      <th>21438</th>\n","      <td>Using Semantically Motivated Estimates to Help...</td>\n","      <td>Research into the automatic acquisition of sub...</td>\n","      <td>8</td>\n","      <td>530</td>\n","    </tr>\n","    <tr>\n","      <th>21439</th>\n","      <td>A Mathematical Exploration of Why Language Mod...</td>\n","      <td>Autoregressive language models, pretrained usi...</td>\n","      <td>11</td>\n","      <td>194</td>\n","    </tr>\n","    <tr>\n","      <th>21440</th>\n","      <td>Do You Know That Florence Is Packed with Visit...</td>\n","      <td>When a speaker, Mary, asks \"Do you know that F...</td>\n","      <td>15</td>\n","      <td>174</td>\n","    </tr>\n","    <tr>\n","      <th>21441</th>\n","      <td>LDA Topic Model with Soft Assignment of Descri...</td>\n","      <td>The LDA topic model is being used to model cor...</td>\n","      <td>10</td>\n","      <td>198</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21442 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c14a117-0880-46d3-ab90-534ffa4715d9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3c14a117-0880-46d3-ab90-534ffa4715d9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3c14a117-0880-46d3-ab90-534ffa4715d9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                   title  ... abstract_length\n","0      Natural Image Bases to Represent Neuroimaging ...  ...             132\n","1      Sluice Resolution without Hand-Crafted Feature...  ...             110\n","2      Learning Translation Models from Monolingual C...  ...             152\n","3           Sentiment Adaptive End-to-End Dialog Systems  ...             119\n","4          User-Friendly Text Prediction For Translators  ...             134\n","...                                                  ...  ...             ...\n","21437  Arabic Tokenization, Part-of-Speech Tagging an...  ...              58\n","21438  Using Semantically Motivated Estimates to Help...  ...             530\n","21439  A Mathematical Exploration of Why Language Mod...  ...             194\n","21440  Do You Know That Florence Is Packed with Visit...  ...             174\n","21441  LDA Topic Model with Soft Assignment of Descri...  ...             198\n","\n","[21442 rows x 4 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df.reset_index(drop=True, inplace=True)"],"metadata":{"id":"Lm97OV9JNgx4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.drop(columns=[\"title_length\", \"abstract_length\", \"token_len\"])"],"metadata":{"id":"r5eGRlj3Po9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = df[:11864]\n","df_valid = df[11864:]"],"metadata":{"id":"mp4cQi3LQsPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset\n","from datasets import load_dataset, load_metric\n","train_dataset = Dataset.from_pandas(df_train)\n","valid_dataset = Dataset.from_pandas(df_valid)\n","metric = load_metric(\"rouge\")\n"],"metadata":{"id":"eLws3YI2NyQ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train"],"metadata":{"id":"zjr__mRBRPpW","executionInfo":{"status":"ok","timestamp":1643552423058,"user_tz":-60,"elapsed":16,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"60bb0bae-19a7-48d3-9ce2-0fda45bd681a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-3e77a8bc-b298-41c6-92ae-f780c87372c9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>abstract</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Natural Image Bases to Represent Neuroimaging ...</td>\n","      <td>Visual inspection of neuroimagery is susceptib...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sluice Resolution without Hand-Crafted Feature...</td>\n","      <td>Sluice resolution in English is the problem of...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentiment Adaptive End-to-End Dialog Systems</td>\n","      <td>End-to-end learning framework is useful for bu...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>User-Friendly Text Prediction For Translators</td>\n","      <td>Text prediction is a form of interactive machi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Aligning Sentences from Standard Wikipedia to ...</td>\n","      <td>This work improves monolingual sentence alignm...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11859</th>\n","      <td>Vine Parsing and Minimum Risk Reranking for Sp...</td>\n","      <td>We describe our entry in the CoNLL-X shared ta...</td>\n","    </tr>\n","    <tr>\n","      <th>11860</th>\n","      <td>From Characters to Time Intervals: New Paradig...</td>\n","      <td>This paper presents the first model for time n...</td>\n","    </tr>\n","    <tr>\n","      <th>11861</th>\n","      <td>Unsupervised Consonant-Vowel Prediction over H...</td>\n","      <td>In this paper, we present a solution to one as...</td>\n","    </tr>\n","    <tr>\n","      <th>11862</th>\n","      <td>Variational Autoencoder with Arbitrary Conditi...</td>\n","      <td>We propose a single neural probabilistic model...</td>\n","    </tr>\n","    <tr>\n","      <th>11863</th>\n","      <td>Complexity of Decentralized Control: Special C...</td>\n","      <td>The worst-case complexity of general decentral...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11864 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e77a8bc-b298-41c6-92ae-f780c87372c9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3e77a8bc-b298-41c6-92ae-f780c87372c9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3e77a8bc-b298-41c6-92ae-f780c87372c9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                   title                                           abstract\n","0      Natural Image Bases to Represent Neuroimaging ...  Visual inspection of neuroimagery is susceptib...\n","1      Sluice Resolution without Hand-Crafted Feature...  Sluice resolution in English is the problem of...\n","2           Sentiment Adaptive End-to-End Dialog Systems  End-to-end learning framework is useful for bu...\n","3          User-Friendly Text Prediction For Translators  Text prediction is a form of interactive machi...\n","4      Aligning Sentences from Standard Wikipedia to ...  This work improves monolingual sentence alignm...\n","...                                                  ...                                                ...\n","11859  Vine Parsing and Minimum Risk Reranking for Sp...  We describe our entry in the CoNLL-X shared ta...\n","11860  From Characters to Time Intervals: New Paradig...  This paper presents the first model for time n...\n","11861  Unsupervised Consonant-Vowel Prediction over H...  In this paper, we present a solution to one as...\n","11862  Variational Autoencoder with Arbitrary Conditi...  We propose a single neural probabilistic model...\n","11863  Complexity of Decentralized Control: Special C...  The worst-case complexity of general decentral...\n","\n","[11864 rows x 2 columns]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["max_input_length = 1024\n","max_target_length = 512\n","\n","def preprocess_function(examples):\n","    model_inputs = tokenizer(examples[\"abstract\"], max_length=max_input_length, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"title\"], max_length=max_target_length, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n"],"metadata":{"id":"KRyNcZ_hThOm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocess_function(valid_dataset[:2])\n"],"metadata":{"id":"oVj7bC9qZRLz","executionInfo":{"status":"ok","timestamp":1643552423059,"user_tz":-60,"elapsed":15,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"53a7f6d9-49d6-49b9-8bcb-5505668c4260"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[0, 1121, 2136, 1472, 2982, 3146, 1023, 9762, 6, 10, 467, 3881, 7, 3094, 5, 1472, 9, 10, 2136, 31, 37617, 1575, 4, 5454, 7926, 7, 745, 10, 239, 12, 12955, 2136, 1472, 2982, 3146, 1023, 9762, 467, 680, 5, 9600, 9, 27963, 414, 13, 42, 3685, 8, 9, 15924, 2051, 12, 6504, 7153, 1472, 41517, 4, 1216, 743, 10114, 5647, 31, 5, 754, 14, 5, 3685, 16, 145, 3032, 11, 13084, 31, 678, 2939, 9, 6885, 2982, 3146, 1023, 14133, 414, 4, 96, 42, 2225, 6, 52, 1701, 5, 1330, 3685, 9, 2136, 19850, 6, 147, 52, 2813, 7, 3094, 5, 4577, 19850, 9, 10, 2136, 31, 5377, 4, 166, 64, 304, 12980, 2777, 22997, 102, 25, 10, 739, 1787, 9, 8531, 16274, 414, 13, 42, 3685, 4, 166, 1455, 16964, 13, 15582, 5, 2136, 19850, 936, 8, 8085, 10, 1233, 3855, 81, 10, 18043, 467, 4, 166, 172, 311, 14, 5, 2136, 12, 48235, 467, 64, 28, 341, 7, 1477, 819, 15, 10, 30082, 20399, 179, 17985, 1253, 35019, 3685, 8, 64, 4296, 8, 12775, 3349, 4438, 5, 278, 9, 1984, 41762, 13, 10, 2136, 4, 2], [0, 170, 892, 5, 13879, 9, 16854, 11, 10, 1546, 12, 805, 691, 467, 6, 147, 2172, 32, 3665, 11, 10, 592, 1546, 8, 41, 12082, 6, 3700, 10, 544, 3696, 6, 64, 2712, 49, 691, 8, 712, 5, 1374, 1963, 4, 166, 34882, 10, 346, 9, 43448, 15796, 3611, 9, 42, 7208, 6, 11, 1989, 52, 311, 14, 10584, 5, 8066, 9, 41, 19329, 18110, 1860, 13, 5, 12082, 16, 26266, 12, 27527, 6, 190, 19, 455, 2655, 9, 5, 7482, 1546, 3184, 4, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[0, 44051, 12, 38239, 6310, 3146, 1023, 9762, 13, 14969, 41737, 2], [0, 133, 14219, 1571, 9, 14508, 23138, 11, 3658, 12, 20930, 8998, 5778, 2]]}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["train_dataset = train_dataset.map(preprocess_function, batched=True)\n","valid_dataset = valid_dataset.map(preprocess_function, batched=True)\n"],"metadata":{"id":"WsGePsUcSrkO","executionInfo":{"status":"ok","timestamp":1643552425419,"user_tz":-60,"elapsed":2372,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["6791cc54159d48dcb9349a271e7d2044","3e326190377d43989ee054a148ed9a0a","bf72310f347a417a8af4e87621513c0c","e273d1fca37941a6871b1735bb3b710a","f698e26dbf774bcbb2225edd5aaada35","8598fec3b6a3475fa488de1f800e7c4d","ad8c8c9507184b59a8f00c5df39158c5","c1f05b8249ac488294cd42907257afa9","e01c22ea2473403da217c4ad9169f172","eaf968c74d6f40b997255fcdb62e93a3","c12eb35ebbdd45c1a26aed7dcd599bff","b24072f8b1694bf6af0606c14660becc","2c0616784d2543dba7d43597f648d32d","fea52f0c9539457e851da1aeaf45cedd","f53f7a8102024889b9b4adb36d8bd5de","e2184d3b947548678b0e57e18ce99f79","c54475782ca54c788148eb9dcbe248af","d8dce2aa43e84f2eb7639abcf31cba7c","95a797672a2945ddba7cbf8f77fe61d7","64cbd7954f43400899d0866c3762ce9c","d5f6ac4161f94263a13a2fcfefb35421","fe7c0b3ca9a0443185f7a0aef77cc8e5"]},"outputId":"3fb74001-162f-4abb-a555-35cae507bc17"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6791cc54159d48dcb9349a271e7d2044","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/12 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b24072f8b1694bf6af0606c14660becc","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{}}]},{"cell_type":"code","source":["batch_size = 8\n","model_name = model_checkpoint.split(\"/\")[-1]\n","args = Seq2SeqTrainingArguments(\n","    f\"{model_name}-finetuned-lm_al_paper\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=3e-4,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=4,\n","    weight_decay=0.01,\n","    save_total_limit=2,\n","    num_train_epochs=3,\n","    predict_with_generate=True,\n","    fp16=True,\n","    push_to_hub=False,\n","    gradient_accumulation_steps=8,\n","    save_steps = 500,\n","    logging_steps = 185,\n",")"],"metadata":{"id":"btKZ3RhjZ4Vx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"],"metadata":{"id":"j6RYke5GbaYN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","\n","```\n","Examples:\n","    >>> predictions = [\"hello there\", \"general kenobi\"]\n","    >>> references = [\"hello there\", \"general kenobi\"]\n","    >>> bertscore = datasets.load_metric(\"bertscore\")\n","    >>> results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n","    >>> print([round(v, 2) for v in results[\"f1\"]])\n","    [1.0, 1.0]\n","  \n","```\n","\n"],"metadata":{"id":"dduVZjJZcLUa"}},{"cell_type":"code","source":["import nltk\n","import numpy as np\n","nltk.download('punkt')\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    # Rouge expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","    \n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    # Extract a few results\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","    \n","    # Add mean generated length\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    \n","    return {k: round(v, 4) for k, v in result.items()}"],"metadata":{"id":"cCYda7Z3bgUC","executionInfo":{"status":"ok","timestamp":1643552425873,"user_tz":-60,"elapsed":457,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"73613a5d-58e1-4192-af2d-bddca54f84c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"id":"l7PrIlIVfXtX","executionInfo":{"status":"ok","timestamp":1643552430704,"user_tz":-60,"elapsed":4834,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0dd1f62d-0f4e-4b33-833d-736f4fab7412"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using amp fp16 backend\n"]}]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"CimnB8COfle1","executionInfo":{"status":"ok","timestamp":1643553206476,"user_tz":-60,"elapsed":775778,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/","height":759},"outputId":"cd7ad449-8421-409a-fae9-1eb733ea3825"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: abstract, title.\n","***** Running training *****\n","  Num examples = 11864\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 555\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='555' max='555' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [555/555 12:54, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>2.806000</td>\n","      <td>2.092597</td>\n","      <td>44.036600</td>\n","      <td>24.640800</td>\n","      <td>39.571800</td>\n","      <td>39.593000</td>\n","      <td>13.657000</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>1.965900</td>\n","      <td>1.956018</td>\n","      <td>45.471500</td>\n","      <td>25.963300</td>\n","      <td>40.534800</td>\n","      <td>40.514300</td>\n","      <td>13.978000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.499900</td>\n","      <td>1.939256</td>\n","      <td>46.978300</td>\n","      <td>26.863500</td>\n","      <td>42.031900</td>\n","      <td>42.036900</td>\n","      <td>14.689000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: abstract, title.\n","***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 4\n","The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: abstract, title.\n","***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 4\n","Saving model checkpoint to bart-base-finetuned-lm_al_paper/checkpoint-500\n","Configuration saved in bart-base-finetuned-lm_al_paper/checkpoint-500/config.json\n","Model weights saved in bart-base-finetuned-lm_al_paper/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in bart-base-finetuned-lm_al_paper/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in bart-base-finetuned-lm_al_paper/checkpoint-500/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: abstract, title.\n","***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 4\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=555, training_loss=2.090629948796453, metrics={'train_runtime': 775.9142, 'train_samples_per_second': 45.871, 'train_steps_per_second': 0.715, 'total_flos': 4491766526607360.0, 'train_loss': 2.090629948796453, 'epoch': 3.0})"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["model.save_pretrained(\"./output/bart\")\n"],"metadata":{"id":"eXx-uoz8fuhf","executionInfo":{"status":"ok","timestamp":1643553208387,"user_tz":-60,"elapsed":1915,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ef1c3e3-852a-4caa-94b4-8ea034ce2846"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Configuration saved in ./output/bart/config.json\n","Model weights saved in ./output/bart/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/Thesis/output/bart\")\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":218,"referenced_widgets":["813ffc2c98e74337a9c1118dd964ddec","0939ac155f4e4a9a9c34428c9979a887","025828a218214eb2861e7754faf2ff1b","788759ae79e64d90b5dab2fbc11b3089","5fc94612a291473282ffa08a606c7280","f4b1002dcd3b47f187014c8ccda5b7cc","c55a06bc24a34a6fa51836f9257c7053","84e2b30f7bb44b86a3c61e054d58183f","3f7135f5d09b4442aa97dbff239d41f8","7f41847da54041628cdecf0a12e946d6","ce6677126c47422d95851b55571f0924","66093cf660e245278217bd930d702770","8469b1d9def7442e8a97603fd131be95","ae1256eb27cb4e359e3ce139a903453a","b81d89a4bfa84591afac04d65b764ccc","f7f51338d0df44768efda2586db54ed2","fcd750086b73440aacaf83f0a4cae88b","d5e2bcb3c9f44a39aeea0894b1a39bb3","a133ee2eb8d8497eb551b98948418026","9ba5218c702b43bab0a4d052228e6fc1","f94930b5f6324c33a86bfc19405b7968","3b6dee50f0134faebe511db712d9f25b","76da30d26deb4f0eb136ef0e6e36aa67","2a2ab8e71db944d9969e694c843a4743","e21a0564b2d540568dc07edef059328b","8efb7fbc96bb4090b60d0f64ba6c487b","7b838c6500bb4666b5beb226173c5792","fa5af04628d2481199fdbc7f1adeef75","9791a53106fe486ba62c910a9c96009a","de7e2367cf624dcab91ad1e39acb114f","5843b0a5323a4e2e97cf8ff7b5d227f8","45ce2df2ccc3472aa4477e54c45851c9"]},"id":"lYGz849ime6l","executionInfo":{"status":"ok","timestamp":1644160659452,"user_tz":-60,"elapsed":15706,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"a44012ce-cb80-4af6-bc35-11d0c8e179c7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"813ffc2c98e74337a9c1118dd964ddec","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=1688, style=ProgressStyle(description_width…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f7135f5d09b4442aa97dbff239d41f8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=898823, style=ProgressStyle(description_wid…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcd750086b73440aacaf83f0a4cae88b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=456318, style=ProgressStyle(description_wid…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e21a0564b2d540568dc07edef059328b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=1355863, style=ProgressStyle(description_wi…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","source":["import pandas as pd\n"],"metadata":{"id":"c3NmNvjfnevO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_samples = pd.read_csv(\"/content/drive/MyDrive/Thesis/data/1024_length_data/test_pairs.csv\", index_col=0)\n","test_samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"uda8rS7ES7Su","executionInfo":{"status":"ok","timestamp":1644160749389,"user_tz":-60,"elapsed":1152,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"4e7e8a2c-7b26-4973-9e28-5155d36e0969"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-4c84c594-7b7a-4e88-9b91-929a3e0385ea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>title_length</th>\n","      <th>abstract_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Learning Latent Semantic Annotations for Groun...</td>\n","      <td>Previous work on grounded language learning di...</td>\n","      <td>11</td>\n","      <td>121</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Partially Supervised Sense Disambiguation by L...</td>\n","      <td>Supervised and semi-supervised sense disambigu...</td>\n","      <td>13</td>\n","      <td>140</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hawkes Processes for Continuous Time Sequence ...</td>\n","      <td>Classification of temporal textual data sequen...</td>\n","      <td>15</td>\n","      <td>68</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A Unified Single Scan Algorithm for Japanese B...</td>\n","      <td>We describe an algorithm for Japanese analysis...</td>\n","      <td>13</td>\n","      <td>62</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Generating Coherent Event Schemas at Scale</td>\n","      <td>Chambers and Jurafsky (2009) demonstrated that...</td>\n","      <td>6</td>\n","      <td>127</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5356</th>\n","      <td>Bridging Information-Seeking Human Gaze and Ma...</td>\n","      <td>In this work, we analyze how human gaze during...</td>\n","      <td>8</td>\n","      <td>118</td>\n","    </tr>\n","    <tr>\n","      <th>5357</th>\n","      <td>Quantum-inspired Neural Network for Conversati...</td>\n","      <td>We provide a novel perspective on conversation...</td>\n","      <td>7</td>\n","      <td>116</td>\n","    </tr>\n","    <tr>\n","      <th>5358</th>\n","      <td>The BQ Corpus: A Large-scale Domain-specific C...</td>\n","      <td>This paper introduces the Bank Question (BQ) c...</td>\n","      <td>13</td>\n","      <td>174</td>\n","    </tr>\n","    <tr>\n","      <th>5359</th>\n","      <td>Doc2hash: Learning Discrete Latent variables f...</td>\n","      <td>Learning to hash via generative model has beco...</td>\n","      <td>8</td>\n","      <td>131</td>\n","    </tr>\n","    <tr>\n","      <th>5360</th>\n","      <td>Provable Benefits of Overparameterization in M...</td>\n","      <td>Deep networks are typically trained with many ...</td>\n","      <td>14</td>\n","      <td>228</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5361 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c84c594-7b7a-4e88-9b91-929a3e0385ea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4c84c594-7b7a-4e88-9b91-929a3e0385ea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4c84c594-7b7a-4e88-9b91-929a3e0385ea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                  title  ... abstract_length\n","0     Learning Latent Semantic Annotations for Groun...  ...             121\n","1     Partially Supervised Sense Disambiguation by L...  ...             140\n","2     Hawkes Processes for Continuous Time Sequence ...  ...              68\n","3     A Unified Single Scan Algorithm for Japanese B...  ...              62\n","4            Generating Coherent Event Schemas at Scale  ...             127\n","...                                                 ...  ...             ...\n","5356  Bridging Information-Seeking Human Gaze and Ma...  ...             118\n","5357  Quantum-inspired Neural Network for Conversati...  ...             116\n","5358  The BQ Corpus: A Large-scale Domain-specific C...  ...             174\n","5359  Doc2hash: Learning Discrete Latent variables f...  ...             131\n","5360  Provable Benefits of Overparameterization in M...  ...             228\n","\n","[5361 rows x 4 columns]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["abstracts = test_samples.abstract.to_list()\n","titles = test_samples.title.to_list()"],"metadata":{"id":"gJkJ7UsNUR8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.to(\"cuda\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDHNxyi3nrFY","executionInfo":{"status":"ok","timestamp":1644160798032,"user_tz":-60,"elapsed":348,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"3215f900-9cf7-45c5-d0e4-b6e71b23de1c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(50265, 768, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",")"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["def creat_eval_pairs(model, tokenizer, abstracts, titles):\n","  preds = []\n","  for abstract, title in zip(abstracts, titles):\n","    encoding = tokenizer.encode_plus(abstract, return_tensors = \"pt\")\n","    inputs = encoding[\"input_ids\"].to(\"cuda\")\n","    attention_masks = encoding[\"attention_mask\"].to(\"cuda\")\n","    title_ids = model.generate(\n","            input_ids = inputs,\n","            attention_mask = attention_masks,\n","            max_length = 30,\n","            num_beams = 5,\n","            num_return_sequences = 5,\n","            repetition_penalty=2.0, \n","            length_penalty=10.0,\n","            early_stopping = True,\n","            )\n","    result = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in title_ids]\n","    s=\"\"\n","    for t in result:\n","      s = s + \"<TITLE>\" + t\n","    preds.append(s)\n","    if len(preds) % 500 == 0:\n","      print(\"original title: \", title)\n","      print(\"generated title: \", preds[-1:])\n","  return preds, titles"],"metadata":{"id":"kt3IloOwZ_uY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds, titles = creat_eval_pairs(model, tokenizer, abstracts, titles)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKhygWb3bZMx","executionInfo":{"status":"ok","timestamp":1644165358168,"user_tz":-60,"elapsed":416116,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"1ac905e3-2db1-4df0-e5df-a994816e1bbc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["original title:  Paraphrase-Driven Learning for Open Question Answering\n","generated title:  ['<TITLE>Learning a Semantic Lexicon and Linear Ranking Function for Question Answering<TITLE>Learning Semantic Lexicons and Linear Ranking Functions for Question Answering<TITLE>Learning a Semantic Lexicon and Linear Ranking Function for Open-Domain Questions<TITLE>Learning Semantic Lexicon and Linear Ranking Functions for Question Answering<TITLE>Learning Semantic Lexicons for Question Answering']\n","original title:  Robustness and Generalization of Role Sets: PropBank vs. VerbNet\n","generated title:  ['<TITLE>Robustness and Generalization of PropBank and VerbNet Roles for Semantic Role Labeling<TITLE>Robustness and Generalization of Two Alternative Role Sets for Semantic Role Labeling<TITLE>Robustness and Generalization of Alternative Role Sets for Semantic Role Labeling<TITLE>Robustness and Generalization of PropBank Roles for Semantic Role Labeling<TITLE>Robustness and Generalization of Alternative Roles for Semantic Role Labeling']\n","original title:  Analyzing the Persuasive Effect of Style in News Editorial Argumentation\n","generated title:  ['<TITLE>The Effect of Style in News Editorials on Persuasion<TITLE>Exploring the Effect of Style in News Editorials<TITLE>Style and Persuasion in News Editorials<TITLE>Style and Persuasion of News Editorials<TITLE>The Effect of Style in News Editorials']\n","original title:  Noise-Robust Morphological Disambiguation for Dialectal Arabic\n","generated title:  ['<TITLE>Neural Morphological Tagging and Disambiguation for Dialectal Arabic<TITLE>Neural Morphological Tagging and Disambiguation of Dialectal Text<TITLE>Neural Morphological Tagging and Disambiguation for Dialectal Text<TITLE>A Neural Morphological Tagging and Disambiguation Model for Arabic<TITLE>Neural Morphological Tagging and Disambiguation for Arabic']\n","original title:  Improving Interactive Machine Translation via Mouse Actions\n","generated title:  ['<TITLE>Mouse Actions as an Efficient Interface between Phrase-Based MT and InteractivePredictive Engine<TITLE>Mouse Actions as an Efficient Interface between Phrase-Based MT and InteractivePredictive Systems<TITLE>Mouse Actions as an Efficient Interface between Phrase-Based MT System and Interactive Prediction Engine<TITLE>Mouse Actions as an Efficient Interface for InteractivePredictive Machine Translation<TITLE>Microwave: Interactive Prediction for Machine Translation']\n","original title:  SUPERT: Towards New Frontiers in Unsupervised Evaluation Metrics for Multi-Document Summarization\n","generated title:  ['<TITLE>Supervised Multi-Document Summarization Evaluation Metrics with Pseudo Reference Summaries<TITLE>Supervised Multi-Document Summarization Evaluation with Pseudo Reference Summaries and Rewards<TITLE>Supervised Multi-Document Summarization Evaluation with Pseudo Reference Summaries<TITLE>Supervised Multi-Document Summarization Evaluation Using Pseudo Reference Summaries<TITLE>Supervised Multi-Document Summarization Evaluation using Pseudo Reference Summaries']\n"]}]},{"cell_type":"code","source":["pred_target_pairs = pd.DataFrame(list(zip(preds, titles)), columns=['predictions', 'targets'])"],"metadata":{"id":"haa7O2kag0zL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_target_pairs.to_csv(\"/content/drive/MyDrive/Thesis/output/preds_targets_pairs/bart-base.csv\")"],"metadata":{"id":"o8ra-1D0hfmj"},"execution_count":null,"outputs":[]}]}