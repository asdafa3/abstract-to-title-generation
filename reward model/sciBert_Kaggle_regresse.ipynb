{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xALrBKkVYuYd"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git_root\n",
        "\n",
        "PROJECT_ROOT = None\n",
        "in_colab = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if in_colab:\n",
        "  print('Running on CoLab')\n",
        "  PROJECT_ROOT = \"/content/drive/MyDrive/DL4NLP/abstract-to-title-generation\"\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "else:\n",
        "  print('Running on local machine')\n",
        "  from git_root import git_root\n",
        "  PROJECT_ROOT = git_root()\n",
        "\n",
        "%cd {PROJECT_ROOT}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5bEY6Dydubt",
        "outputId": "1825b67a-7e8a-4a53-8454-a5fb990de100"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: git_root in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Running on CoLab\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/DL4NLP/abstract-to-title-generation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WguLovM5YuYk",
        "outputId": "3eeead18-71f9-44ff-e818-aa068b3aa8cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git_root\n",
            "  Downloading git_root-0.1-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: git-root\n",
            "Successfully installed git-root-0.1\n",
            "Running on CoLab\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/DL4NLP/abstract-to-title-generation\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
            "\u001b[K     |████████████████████████████████| 362 kB 12.8 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 40.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.3.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.64.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.11.0+cu113)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: git_root in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (0.1)\n",
            "Collecting dvc[gdrive]\n",
            "  Downloading dvc-2.10.2-py3-none-any.whl (401 kB)\n",
            "\u001b[K     |████████████████████████████████| 401 kB 65.1 MB/s \n",
            "\u001b[?25hCollecting rouge_score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (4.11.4)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 76.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (6.0.1)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.4 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 72.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (0.70.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (0.3.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r requirements.txt (line 1)) (4.1.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets->-r requirements.txt (line 1)) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 69.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 2)) (2022.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score->-r requirements.txt (line 12)) (1.1.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 61.3 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 77.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (2.0.12)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting zc.lockfile>=1.2.1\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting aiohttp-retry>=2.4.5\n",
            "  Downloading aiohttp_retry-2.4.8-py3-none-any.whl (7.8 kB)\n",
            "Collecting distro>=1.3.0\n",
            "  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\n",
            "Collecting toml>=0.10.1\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pathspec<0.10.0,>=0.9.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting funcy>=1.14\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
            "Collecting dpath<3,>=2.0.2\n",
            "  Downloading dpath-2.0.6-py3-none-any.whl (15 kB)\n",
            "Collecting pygtrie>=2.3.2\n",
            "  Downloading pygtrie-2.4.2.tar.gz (35 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=5.2.2 in /usr/local/lib/python3.7/dist-packages (from dvc[gdrive]->-r requirements.txt (line 11)) (5.7.1)\n",
            "Collecting ruamel.yaml>=0.17.11\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 65.4 MB/s \n",
            "\u001b[?25hCollecting shtab<2,>=1.3.4\n",
            "  Downloading shtab-1.5.5-py2.py3-none-any.whl (13 kB)\n",
            "Collecting scmrepo==0.0.19\n",
            "  Downloading scmrepo-0.0.19-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting configobj>=5.0.6\n",
            "  Downloading configobj-5.0.6.tar.gz (33 kB)\n",
            "Collecting flatten-dict<1,>=0.4.1\n",
            "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting python-benedict>=0.24.2\n",
            "  Downloading python_benedict-0.25.1-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 377 kB/s \n",
            "\u001b[?25hCollecting flufl.lock>=5\n",
            "  Downloading flufl.lock-7.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.7/dist-packages (from dvc[gdrive]->-r requirements.txt (line 11)) (2.6.3)\n",
            "Collecting voluptuous>=0.11.7\n",
            "  Downloading voluptuous-0.13.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from dvc[gdrive]->-r requirements.txt (line 11)) (1.4.4)\n",
            "Collecting grandalf==0.6\n",
            "  Downloading grandalf-0.6-py3-none-any.whl (31 kB)\n",
            "Collecting dictdiffer>=0.8.1\n",
            "  Downloading dictdiffer-0.9.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting diskcache>=5.2.1\n",
            "  Downloading diskcache-5.4.0-py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting dvclive>=0.7.3\n",
            "  Downloading dvclive-0.9.0-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pydot>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from dvc[gdrive]->-r requirements.txt (line 11)) (1.3.0)\n",
            "Collecting nanotime>=0.5.2\n",
            "  Downloading nanotime-0.5.2.tar.gz (3.2 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from dvc[gdrive]->-r requirements.txt (line 11)) (0.8.9)\n",
            "Collecting rich>=10.13.0\n",
            "  Downloading rich-12.4.4-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 69.1 MB/s \n",
            "\u001b[?25hCollecting dvc-render==0.0.5\n",
            "  Downloading dvc_render-0.0.5-py3-none-any.whl (15 kB)\n",
            "Collecting pydrive2[fsspec]>=1.10.1\n",
            "  Downloading PyDrive2-1.10.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from grandalf==0.6->dvc[gdrive]->-r requirements.txt (line 11)) (0.16.0)\n",
            "Collecting pygit2>=1.7.2\n",
            "  Downloading pygit2-1.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 55.9 MB/s \n",
            "\u001b[?25hCollecting gitpython>3\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 77.6 MB/s \n",
            "\u001b[?25hCollecting asyncssh<3,>=2.7.1\n",
            "  Downloading asyncssh-2.11.0-py3-none-any.whl (343 kB)\n",
            "\u001b[K     |████████████████████████████████| 343 kB 77.2 MB/s \n",
            "\u001b[?25hCollecting dulwich>=0.20.34\n",
            "  Downloading dulwich-0.20.43-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (552 kB)\n",
            "\u001b[K     |████████████████████████████████| 552 kB 62.9 MB/s \n",
            "\u001b[?25hCollecting cryptography>=3.1\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.1->asyncssh<3,>=2.7.1->scmrepo==0.0.19->dvc[gdrive]->-r requirements.txt (line 11)) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.1->asyncssh<3,>=2.7.1->scmrepo==0.0.19->dvc[gdrive]->-r requirements.txt (line 11)) (2.21)\n",
            "Collecting atpublic>=2.3\n",
            "  Downloading atpublic-3.0.1-py3-none-any.whl (4.8 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets->-r requirements.txt (line 1)) (3.8.0)\n",
            "Collecting pyOpenSSL>=19.1.0\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.5 in /usr/local/lib/python3.7/dist-packages (from pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (1.12.11)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.12.5->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.12.5->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.12.5->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.12.5->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (1.31.6)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.12.5->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (1.35.0)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.12.5->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (3.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.12.5->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (1.56.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.12.5->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.12.5->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.12.5->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.12.5->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->pydrive2[fsspec]>=1.10.1->dvc[gdrive]->-r requirements.txt (line 11)) (0.4.8)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from pygit2>=1.7.2->scmrepo==0.0.19->dvc[gdrive]->-r requirements.txt (line 11)) (1.5.2)\n",
            "Collecting requests>=2.19.0\n",
            "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting xmltodict<1.0.0,>=0.12.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: python-slugify<7.0.0,>=6.0.1 in /usr/local/lib/python3.7/dist-packages (from python-benedict>=0.24.2->dvc[gdrive]->-r requirements.txt (line 11)) (6.1.2)\n",
            "Collecting phonenumbers<9.0.0,>=8.12.0\n",
            "  Downloading phonenumbers-8.12.50-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 45.9 MB/s \n",
            "\u001b[?25hCollecting mailchecker<5.0.0,>=4.1.0\n",
            "  Downloading mailchecker-4.1.17.tar.gz (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 63.3 MB/s \n",
            "\u001b[?25hCollecting ftfy<7.0.0,>=6.0.0\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting python-fsutil<1.0.0,>=0.6.0\n",
            "  Downloading python_fsutil-0.6.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0.0,>=6.0.0->python-benedict>=0.24.2->dvc[gdrive]->-r requirements.txt (line 11)) (0.2.5)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify<7.0.0,>=6.0.1->python-benedict>=0.24.2->dvc[gdrive]->-r requirements.txt (line 11)) (1.3)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.13.0->dvc[gdrive]->-r requirements.txt (line 11)) (2.6.1)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 71.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: configobj, nanotime, pygtrie, mailchecker\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34547 sha256=d0452f7858259b9159bc8b1ac98cac6f296f12de7c747a575bfbdd43592d0b34\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/c4/19/13d74440f2a571841db6b6e0a273694327498884dafb9cf978\n",
            "  Building wheel for nanotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nanotime: filename=nanotime-0.5.2-py3-none-any.whl size=2441 sha256=a29db72b1d9dc003cf2de8d00ee93d433aeee7b6c585232523e85155aedecca4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/92/aa/456d462c908b4e210c3928f778d28f94049fc9e47af8b191c9\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygtrie: filename=pygtrie-2.4.2-py3-none-any.whl size=19063 sha256=0f4f4d426bd3015d42ee61c5a15a5414afc28e03bbdf6885bbead1b860ee9d2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/f8/ba/1d828b1603ea422686eb694253a43cb3a5901ea4696c1e0603\n",
            "  Building wheel for mailchecker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mailchecker: filename=mailchecker-4.1.17-py3-none-any.whl size=232921 sha256=20a15c15b46ebe4db35a209cb7ac9a0e76e2232a97bb1815f49da2f3b5847389\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/34/d5/21a0829a95aec844a36606f113b607b6ed82f7148cb3f4a5a9\n",
            "Successfully built configobj nanotime pygtrie mailchecker\n",
            "Installing collected packages: urllib3, smmap, requests, multidict, frozenlist, yarl, gitdb, funcy, cryptography, asynctest, async-timeout, aiosignal, xmltodict, toml, ruamel.yaml.clib, pyyaml, python-fsutil, pyOpenSSL, pygtrie, pygit2, psutil, phonenumbers, pathspec, mailchecker, gitpython, ftfy, fsspec, dvc-render, dulwich, commonmark, atpublic, asyncssh, aiohttp, zc.lockfile, voluptuous, shtab, shortuuid, scmrepo, ruamel.yaml, rich, python-benedict, pydrive2, nanotime, grandalf, flufl.lock, flatten-dict, dvclive, dpath, distro, diskcache, dictdiffer, configobj, colorama, aiohttp-retry, xxhash, tokenizers, responses, huggingface-hub, dvc, transformers, sentencepiece, rouge-score, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiohttp-retry-2.4.8 aiosignal-1.2.0 async-timeout-4.0.2 asyncssh-2.11.0 asynctest-0.13.0 atpublic-3.0.1 colorama-0.4.5 commonmark-0.9.1 configobj-5.0.6 cryptography-37.0.2 datasets-2.3.2 dictdiffer-0.9.0 diskcache-5.4.0 distro-1.7.0 dpath-2.0.6 dulwich-0.20.43 dvc-2.10.2 dvc-render-0.0.5 dvclive-0.9.0 flatten-dict-0.4.2 flufl.lock-7.0 frozenlist-1.3.0 fsspec-2022.5.0 ftfy-6.1.1 funcy-1.17 gitdb-4.0.9 gitpython-3.1.27 grandalf-0.6 huggingface-hub-0.8.1 mailchecker-4.1.17 multidict-6.0.2 nanotime-0.5.2 pathspec-0.9.0 phonenumbers-8.12.50 psutil-5.9.1 pyOpenSSL-22.0.0 pydrive2-1.10.1 pygit2-1.9.2 pygtrie-2.4.2 python-benedict-0.25.1 python-fsutil-0.6.1 pyyaml-6.0 requests-2.28.0 responses-0.18.0 rich-12.4.4 rouge-score-0.0.4 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 scmrepo-0.0.19 sentencepiece-0.1.96 shortuuid-1.0.9 shtab-1.5.5 smmap-5.0.0 tokenizers-0.12.1 toml-0.10.2 transformers-4.20.1 urllib3-1.25.11 voluptuous-0.13.1 xmltodict-0.13.0 xxhash-3.0.0 yarl-1.7.2 zc.lockfile-2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing md5 for a large file '/content/drive/MyDrive/DL4NLP/abstract-to-title-generation/.dvc/cache/9c/152208403a0dbde1d60f817cf9d6cb'. This is only done once.\n",
            " 12% 4/32 [00:00<00:02, 12.92files/s{'info': ''}]\n",
            "  0% 0.00/1.51G [00:00<?, ?B/s]\u001b[A\n",
            "  0% 0.00/1.51G [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            "  0% 1.00M/1.51G [00:00<08:59, 3.01MB/s{'info': ''}]\u001b[A\n",
            "  1% 11.0M/1.51G [00:00<00:50, 32.2MB/s{'info': ''}]\u001b[A\n",
            "  2% 30.0M/1.51G [00:00<00:19, 80.5MB/s{'info': ''}]\u001b[A\n",
            "  3% 49.0M/1.51G [00:00<00:13, 113MB/s{'info': ''}] \u001b[A\n",
            "  5% 70.0M/1.51G [00:00<00:10, 142MB/s{'info': ''}]\u001b[A\n",
            "  6% 89.0M/1.51G [00:00<00:09, 159MB/s{'info': ''}]\u001b[A\n",
            "  6% 90.0M/1.51G [00:01<00:19, 77.4MB/s{'info': ''}]\u001b[A\n",
            "  6% 92.0M/1.51G [00:01<00:27, 56.4MB/s{'info': ''}]\u001b[A\n",
            "  6% 95.0M/1.51G [00:01<00:31, 48.9MB/s{'info': ''}]\u001b[A\n",
            "  7% 107M/1.51G [00:01<00:22, 66.0MB/s{'info': ''}] \u001b[A\n",
            "  8% 127M/1.51G [00:01<00:14, 101MB/s{'info': ''}] \u001b[A\n",
            " 10% 162M/1.51G [00:01<00:08, 169MB/s{'info': ''}]\u001b[A\n",
            " 13% 197M/1.51G [00:01<00:06, 221MB/s{'info': ''}]\u001b[A\n",
            " 14% 218M/1.51G [00:01<00:06, 213MB/s{'info': ''}]\u001b[A\n",
            " 15% 235M/1.51G [00:02<00:06, 202MB/s{'info': ''}]\u001b[A\n",
            " 16% 242M/1.51G [00:02<00:08, 166MB/s{'info': ''}]\u001b[A\n",
            " 17% 259M/1.51G [00:02<00:08, 165MB/s{'info': ''}]\u001b[A\n",
            " 17% 271M/1.51G [00:02<00:08, 153MB/s{'info': ''}]\u001b[A\n",
            " 18% 282M/1.51G [00:02<00:09, 140MB/s{'info': ''}]\u001b[A\n",
            " 19% 301M/1.51G [00:02<00:08, 157MB/s{'info': ''}]\u001b[A\n",
            " 20% 312M/1.51G [00:02<00:09, 142MB/s{'info': ''}]\u001b[A\n",
            " 21% 327M/1.51G [00:02<00:08, 146MB/s{'info': ''}]\u001b[A\n",
            " 23% 358M/1.51G [00:02<00:06, 198MB/s{'info': ''}]\u001b[A\n",
            " 24% 370M/1.51G [00:02<00:07, 177MB/s{'info': ''}]\u001b[A\n",
            " 25% 387M/1.51G [00:03<00:06, 175MB/s{'info': ''}]\u001b[A\n",
            " 26% 406M/1.51G [00:03<00:06, 182MB/s{'info': ''}]\u001b[A\n",
            " 27% 414M/1.51G [00:03<00:08, 146MB/s{'info': ''}]\u001b[A\n",
            " 28% 428M/1.51G [00:03<00:09, 123MB/s{'info': ''}]\u001b[A\n",
            " 28% 429M/1.51G [00:03<00:17, 69.1MB/s{'info': ''}]\u001b[A\n",
            " 28% 430M/1.51G [00:04<00:47, 24.9MB/s{'info': ''}]\u001b[A\n",
            " 30% 463M/1.51G [00:04<00:18, 62.6MB/s{'info': ''}]\u001b[A\n",
            " 32% 498M/1.51G [00:04<00:10, 106MB/s{'info': ''}] \u001b[A\n",
            " 34% 532M/1.51G [00:04<00:07, 148MB/s{'info': ''}]\u001b[A\n",
            " 36% 563M/1.51G [00:04<00:05, 183MB/s{'info': ''}]\u001b[A\n",
            " 38% 595M/1.51G [00:04<00:04, 216MB/s{'info': ''}]\u001b[A\n",
            " 41% 630M/1.51G [00:05<00:03, 251MB/s{'info': ''}]\u001b[A\n",
            " 43% 666M/1.51G [00:05<00:03, 283MB/s{'info': ''}]\u001b[A\n",
            " 45% 690M/1.51G [00:05<00:03, 273MB/s{'info': ''}]\u001b[A\n",
            " 46% 708M/1.51G [00:05<00:03, 232MB/s{'info': ''}]\u001b[A\n",
            " 47% 722M/1.51G [00:05<00:04, 205MB/s{'info': ''}]\u001b[A\n",
            " 49% 753M/1.51G [00:05<00:03, 233MB/s{'info': ''}]\u001b[A\n",
            " 50% 768M/1.51G [00:05<00:03, 206MB/s{'info': ''}]\u001b[A\n",
            " 50% 782M/1.51G [00:05<00:04, 188MB/s{'info': ''}]\u001b[A\n",
            " 51% 795M/1.51G [00:05<00:04, 167MB/s{'info': ''}]\u001b[A\n",
            " 52% 800M/1.51G [00:06<00:06, 122MB/s{'info': ''}]\u001b[A\n",
            " 53% 814M/1.51G [00:06<00:06, 128MB/s{'info': ''}]\u001b[A\n",
            " 53% 828M/1.51G [00:06<00:06, 121MB/s{'info': ''}]\u001b[A\n",
            " 54% 833M/1.51G [00:06<00:07, 103MB/s{'info': ''}]\u001b[A\n",
            " 55% 845M/1.51G [00:06<00:06, 108MB/s{'info': ''}]\u001b[A\n",
            " 56% 871M/1.51G [00:06<00:04, 153MB/s{'info': ''}]\u001b[A\n",
            " 58% 898M/1.51G [00:06<00:03, 189MB/s{'info': ''}]\u001b[A\n",
            " 59% 918M/1.51G [00:06<00:03, 194MB/s{'info': ''}]\u001b[A\n",
            " 60% 934M/1.51G [00:06<00:03, 185MB/s{'info': ''}]\u001b[A\n",
            " 61% 952M/1.51G [00:06<00:03, 184MB/s{'info': ''}]\u001b[A\n",
            " 62% 965M/1.51G [00:07<00:03, 163MB/s{'info': ''}]\u001b[A\n",
            " 63% 979M/1.51G [00:07<00:04, 146MB/s{'info': ''}]\u001b[A\n",
            " 64% 999M/1.51G [00:07<00:03, 162MB/s{'info': ''}]\u001b[A\n",
            " 65% 0.99G/1.51G [00:07<00:03, 156MB/s{'info': ''}]\u001b[A\n",
            " 66% 1.01G/1.51G [00:07<00:03, 154MB/s{'info': ''}]\u001b[A\n",
            " 67% 1.01G/1.51G [00:07<00:05, 107MB/s{'info': ''}]\u001b[A\n",
            " 68% 1.03G/1.51G [00:07<00:04, 127MB/s{'info': ''}]\u001b[A\n",
            " 68% 1.03G/1.51G [00:07<00:04, 113MB/s{'info': ''}]\u001b[A\n",
            " 71% 1.07G/1.51G [00:07<00:02, 185MB/s{'info': ''}]\u001b[A\n",
            " 72% 1.09G/1.51G [00:08<00:02, 189MB/s{'info': ''}]\u001b[A\n",
            " 73% 1.11G/1.51G [00:08<00:02, 187MB/s{'info': ''}]\u001b[A\n",
            " 73% 1.11G/1.51G [00:08<00:04, 95.8MB/s{'info': ''}]\u001b[A\n",
            " 74% 1.12G/1.51G [00:08<00:05, 77.4MB/s{'info': ''}]\u001b[A\n",
            " 74% 1.12G/1.51G [00:09<00:11, 38.0MB/s{'info': ''}]\u001b[A\n",
            " 76% 1.15G/1.51G [00:09<00:04, 85.2MB/s{'info': ''}]\u001b[A\n",
            " 78% 1.18G/1.51G [00:09<00:02, 129MB/s{'info': ''}] \u001b[A\n",
            " 80% 1.21G/1.51G [00:09<00:01, 172MB/s{'info': ''}]\u001b[A\n",
            " 83% 1.25G/1.51G [00:09<00:01, 217MB/s{'info': ''}]\u001b[A\n",
            " 85% 1.28G/1.51G [00:09<00:01, 245MB/s{'info': ''}]\u001b[A\n",
            " 87% 1.31G/1.51G [00:09<00:00, 265MB/s{'info': ''}]\u001b[A\n",
            " 88% 1.33G/1.51G [00:09<00:00, 246MB/s{'info': ''}]\u001b[A\n",
            " 88% 1.34G/1.51G [00:09<00:01, 183MB/s{'info': ''}]\u001b[A\n",
            " 89% 1.34G/1.51G [00:10<00:02, 88.7MB/s{'info': ''}]\u001b[A\n",
            " 89% 1.35G/1.51G [00:10<00:01, 97.6MB/s{'info': ''}]\u001b[A\n",
            " 92% 1.39G/1.51G [00:10<00:00, 153MB/s{'info': ''}] \u001b[A\n",
            " 94% 1.42G/1.51G [00:10<00:00, 200MB/s{'info': ''}]\u001b[A\n",
            " 96% 1.45G/1.51G [00:10<00:00, 238MB/s{'info': ''}]\u001b[A\n",
            " 98% 1.48G/1.51G [00:10<00:00, 265MB/s{'info': ''}]\u001b[A\n",
            "Computing md5 for a large file '/content/drive/MyDrive/DL4NLP/abstract-to-title-generation/.dvc/cache/a6/08c46475737c0897d73638e07681e9'. This is only done once.\n",
            " 44% 14/32 [00:23<00:38,  2.16s/files{'info': ''}]\n",
            "  0% 0.00/1.51G [00:00<?, ?B/s]\u001b[A\n",
            "  0% 0.00/1.51G [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            "  0% 1.00M/1.51G [00:00<13:19, 2.03MB/s{'info': ''}]\u001b[A\n",
            "  1% 9.00M/1.51G [00:00<01:22, 19.5MB/s{'info': ''}]\u001b[A\n",
            "  2% 32.0M/1.51G [00:00<00:28, 55.2MB/s{'info': ''}]\u001b[A\n",
            "  3% 40.0M/1.51G [00:01<00:34, 45.4MB/s{'info': ''}]\u001b[A\n",
            "  4% 57.0M/1.51G [00:01<00:22, 68.9MB/s{'info': ''}]\u001b[A\n",
            "  5% 72.0M/1.51G [00:01<00:20, 75.4MB/s{'info': ''}]\u001b[A\n",
            "  5% 80.0M/1.51G [00:01<00:21, 72.3MB/s{'info': ''}]\u001b[A\n",
            "  6% 96.0M/1.51G [00:01<00:17, 86.5MB/s{'info': ''}]\u001b[A\n",
            "  7% 104M/1.51G [00:01<00:20, 74.7MB/s{'info': ''}] \u001b[A\n",
            "  7% 107M/1.51G [00:01<00:23, 65.0MB/s{'info': ''}]\u001b[A\n",
            "  8% 130M/1.51G [00:02<00:14, 106MB/s{'info': ''}] \u001b[A\n",
            "  9% 136M/1.51G [00:02<00:21, 69.7MB/s{'info': ''}]\u001b[A\n",
            " 10% 149M/1.51G [00:02<00:17, 82.4MB/s{'info': ''}]\u001b[A\n",
            " 11% 163M/1.51G [00:02<00:15, 96.9MB/s{'info': ''}]\u001b[A\n",
            " 11% 174M/1.51G [00:02<00:18, 79.3MB/s{'info': ''}]\u001b[A\n",
            " 11% 176M/1.51G [00:02<00:22, 63.8MB/s{'info': ''}]\u001b[A\n",
            " 12% 179M/1.51G [00:02<00:29, 48.4MB/s{'info': ''}]\u001b[A\n",
            " 12% 185M/1.51G [00:03<00:27, 51.2MB/s{'info': ''}]\u001b[A\n",
            " 14% 214M/1.51G [00:03<00:12, 109MB/s{'info': ''}] \u001b[A\n",
            " 15% 232M/1.51G [00:03<00:10, 127MB/s{'info': ''}]\u001b[A\n",
            " 17% 258M/1.51G [00:03<00:08, 163MB/s{'info': ''}]\u001b[A\n",
            " 18% 285M/1.51G [00:03<00:06, 196MB/s{'info': ''}]\u001b[A\n",
            " 19% 289M/1.51G [00:03<00:09, 146MB/s{'info': ''}]\u001b[A\n",
            " 20% 303M/1.51G [00:03<00:09, 142MB/s{'info': ''}]\u001b[A\n",
            " 20% 315M/1.51G [00:03<00:09, 134MB/s{'info': ''}]\u001b[A\n",
            " 21% 321M/1.51G [00:04<00:13, 93.9MB/s{'info': ''}]\u001b[A\n",
            " 22% 346M/1.51G [00:04<00:09, 134MB/s{'info': ''}] \u001b[A\n",
            " 23% 356M/1.51G [00:04<00:09, 126MB/s{'info': ''}]\u001b[A\n",
            " 23% 364M/1.51G [00:04<00:11, 113MB/s{'info': ''}]\u001b[A\n",
            " 25% 384M/1.51G [00:05<00:29, 41.2MB/s{'info': ''}]\u001b[A\n",
            " 25% 395M/1.51G [00:05<00:24, 48.7MB/s{'info': ''}]\u001b[A\n",
            " 27% 416M/1.51G [00:05<00:20, 58.9MB/s{'info': ''}]\u001b[A\n",
            " 27% 417M/1.51G [00:05<00:27, 43.4MB/s{'info': ''}]\u001b[A\n",
            " 27% 421M/1.51G [00:06<00:27, 42.8MB/s{'info': ''}]\u001b[A\n",
            " 29% 447M/1.51G [00:06<00:14, 79.1MB/s{'info': ''}]\u001b[A\n",
            " 30% 459M/1.51G [00:06<00:13, 85.5MB/s{'info': ''}]\u001b[A\n",
            " 30% 460M/1.51G [00:06<00:16, 69.4MB/s{'info': ''}]\u001b[A\n",
            " 31% 481M/1.51G [00:06<00:10, 102MB/s{'info': ''}] \u001b[A\n",
            " 32% 498M/1.51G [00:06<00:09, 113MB/s{'info': ''}]\u001b[A\n",
            " 32% 501M/1.51G [00:06<00:12, 89.7MB/s{'info': ''}]\u001b[A\n",
            " 34% 520M/1.51G [00:06<00:09, 114MB/s{'info': ''}] \u001b[A\n",
            " 34% 532M/1.51G [00:06<00:09, 112MB/s{'info': ''}]\u001b[A\n",
            " 35% 544M/1.51G [00:07<00:12, 86.8MB/s{'info': ''}]\u001b[A\n",
            " 35% 546M/1.51G [00:07<00:18, 57.7MB/s{'info': ''}]\u001b[A\n",
            " 36% 553M/1.51G [00:07<00:18, 56.6MB/s{'info': ''}]\u001b[A\n",
            " 37% 571M/1.51G [00:07<00:12, 84.0MB/s{'info': ''}]\u001b[A\n",
            " 37% 578M/1.51G [00:07<00:12, 81.0MB/s{'info': ''}]\u001b[A\n",
            " 38% 592M/1.51G [00:07<00:10, 92.9MB/s{'info': ''}]\u001b[A\n",
            " 38% 596M/1.51G [00:07<00:12, 78.8MB/s{'info': ''}]\u001b[A\n",
            " 39% 608M/1.51G [00:08<00:15, 63.8MB/s{'info': ''}]\u001b[A\n",
            " 39% 610M/1.51G [00:08<00:19, 50.0MB/s{'info': ''}]\u001b[A\n",
            " 41% 640M/1.51G [00:08<00:09, 104MB/s{'info': ''}] \u001b[A\n",
            " 42% 648M/1.51G [00:08<00:10, 88.0MB/s{'info': ''}]\u001b[A\n",
            " 42% 656M/1.51G [00:08<00:16, 56.0MB/s{'info': ''}]\u001b[A\n",
            " 43% 669M/1.51G [00:09<00:13, 69.5MB/s{'info': ''}]\u001b[A\n",
            " 44% 687M/1.51G [00:09<00:21, 41.4MB/s{'info': ''}]\u001b[A\n",
            " 45% 699M/1.51G [00:09<00:17, 50.3MB/s{'info': ''}]\u001b[A\n",
            " 46% 717M/1.51G [00:10<00:12, 68.9MB/s{'info': ''}]\u001b[A\n",
            " 46% 720M/1.51G [00:10<00:17, 50.6MB/s{'info': ''}]\u001b[A\n",
            " 47% 721M/1.51G [00:10<00:31, 27.5MB/s{'info': ''}]\u001b[A\n",
            " 47% 722M/1.51G [00:11<00:45, 19.0MB/s{'info': ''}]\u001b[A\n",
            " 49% 756M/1.51G [00:11<00:14, 57.7MB/s{'info': ''}]\u001b[A\n",
            " 51% 790M/1.51G [00:11<00:08, 99.6MB/s{'info': ''}]\u001b[A\n",
            " 53% 822M/1.51G [00:11<00:05, 139MB/s{'info': ''}] \u001b[A\n",
            " 55% 857M/1.51G [00:11<00:03, 182MB/s{'info': ''}]\u001b[A\n",
            " 58% 892M/1.51G [00:11<00:03, 220MB/s{'info': ''}]\u001b[A\n",
            " 60% 925M/1.51G [00:11<00:02, 249MB/s{'info': ''}]\u001b[A\n",
            " 61% 943M/1.51G [00:11<00:03, 187MB/s{'info': ''}]\u001b[A\n",
            " 61% 949M/1.51G [00:12<00:04, 147MB/s{'info': ''}]\u001b[A\n",
            " 62% 963M/1.51G [00:12<00:04, 145MB/s{'info': ''}]\u001b[A\n",
            " 63% 974M/1.51G [00:12<00:04, 138MB/s{'info': ''}]\u001b[A\n",
            " 63% 981M/1.51G [00:12<00:05, 106MB/s{'info': ''}]\u001b[A\n",
            " 65% 0.99G/1.51G [00:12<00:03, 153MB/s{'info': ''}]\u001b[A\n",
            " 67% 1.02G/1.51G [00:12<00:02, 205MB/s{'info': ''}]\u001b[A\n",
            " 68% 1.02G/1.51G [00:12<00:04, 117MB/s{'info': ''}]\u001b[A\n",
            " 70% 1.06G/1.51G [00:13<00:04, 109MB/s{'info': ''}]\u001b[A\n",
            " 70% 1.06G/1.51G [00:13<00:05, 91.5MB/s{'info': ''}]\u001b[A\n",
            " 70% 1.06G/1.51G [00:13<00:06, 71.7MB/s{'info': ''}]\u001b[A\n",
            " 70% 1.06G/1.51G [00:14<00:17, 28.5MB/s{'info': ''}]\u001b[A\n",
            " 70% 1.06G/1.51G [00:14<00:20, 23.8MB/s{'info': ''}]\u001b[A\n",
            " 71% 1.08G/1.51G [00:14<00:09, 46.9MB/s{'info': ''}]\u001b[A\n",
            " 74% 1.12G/1.51G [00:14<00:04, 97.4MB/s{'info': ''}]\u001b[A\n",
            " 76% 1.14G/1.51G [00:14<00:02, 137MB/s{'info': ''}] \u001b[A\n",
            " 78% 1.18G/1.51G [00:14<00:01, 187MB/s{'info': ''}]\u001b[A\n",
            " 80% 1.22G/1.51G [00:14<00:01, 235MB/s{'info': ''}]\u001b[A\n",
            " 83% 1.25G/1.51G [00:14<00:01, 271MB/s{'info': ''}]\u001b[A\n",
            " 85% 1.28G/1.51G [00:15<00:00, 284MB/s{'info': ''}]\u001b[A\n",
            " 86% 1.29G/1.51G [00:15<00:00, 240MB/s{'info': ''}]\u001b[A\n",
            " 87% 1.32G/1.51G [00:15<00:00, 239MB/s{'info': ''}]\u001b[A\n",
            " 89% 1.34G/1.51G [00:15<00:00, 240MB/s{'info': ''}]\u001b[A\n",
            " 89% 1.35G/1.51G [00:15<00:00, 201MB/s{'info': ''}]\u001b[A\n",
            " 90% 1.36G/1.51G [00:15<00:01, 154MB/s{'info': ''}]\u001b[A\n",
            " 90% 1.36G/1.51G [00:15<00:01, 122MB/s{'info': ''}]\u001b[A\n",
            " 90% 1.37G/1.51G [00:15<00:01, 98.8MB/s{'info': ''}]\u001b[A\n",
            " 91% 1.37G/1.51G [00:15<00:01, 77.8MB/s{'info': ''}]\u001b[A\n",
            " 91% 1.38G/1.51G [00:16<00:01, 81.1MB/s{'info': ''}]\u001b[A\n",
            " 92% 1.39G/1.51G [00:16<00:01, 70.3MB/s{'info': ''}]\u001b[A\n",
            " 92% 1.39G/1.51G [00:16<00:01, 66.6MB/s{'info': ''}]\u001b[A\n",
            " 92% 1.40G/1.51G [00:16<00:01, 66.5MB/s{'info': ''}]\u001b[A\n",
            " 93% 1.41G/1.51G [00:16<00:01, 67.1MB/s{'info': ''}]\u001b[A\n",
            " 93% 1.41G/1.51G [00:16<00:01, 66.8MB/s{'info': ''}]\u001b[A\n",
            " 94% 1.42G/1.51G [00:16<00:01, 53.9MB/s{'info': ''}]\u001b[A\n",
            " 95% 1.43G/1.51G [00:16<00:01, 64.3MB/s{'info': ''}]\u001b[A\n",
            " 95% 1.44G/1.51G [00:17<00:01, 52.5MB/s{'info': ''}]\u001b[A\n",
            " 96% 1.45G/1.51G [00:17<00:00, 70.7MB/s{'info': ''}]\u001b[A\n",
            " 97% 1.46G/1.51G [00:17<00:00, 67.3MB/s{'info': ''}]\u001b[A\n",
            " 98% 1.48G/1.51G [00:17<00:00, 84.2MB/s{'info': ''}]\u001b[A\n",
            " 98% 1.49G/1.51G [00:17<00:00, 93.7MB/s{'info': ''}]\u001b[A\n",
            " 99% 1.49G/1.51G [00:18<00:00, 34.4MB/s{'info': ''}]\u001b[A\n",
            "Computing md5 for a large file '/content/drive/MyDrive/DL4NLP/abstract-to-title-generation/.dvc/cache/f2/e9b50bbc0e07e059b3d3344b2e9a3a'. This is only done once.\n",
            " 56% 18/32 [00:44<00:43,  3.07s/files{'info': ''}]\n",
            "  0% 0.00/2.12G [00:00<?, ?B/s]\u001b[A\n",
            "  0% 0.00/2.12G [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            "  0% 1.00M/2.12G [00:00<16:52, 2.25MB/s{'info': ''}]\u001b[A\n",
            "  0% 5.00M/2.12G [00:00<04:41, 8.07MB/s{'info': ''}]\u001b[A\n",
            "  1% 21.0M/2.12G [00:00<00:59, 38.2MB/s{'info': ''}]\u001b[A\n",
            "  1% 32.0M/2.12G [00:01<00:45, 49.1MB/s{'info': ''}]\u001b[A\n",
            "  2% 47.0M/2.12G [00:01<00:30, 72.2MB/s{'info': ''}]\u001b[A\n",
            "  3% 58.0M/2.12G [00:01<00:27, 81.6MB/s{'info': ''}]\u001b[A\n",
            "  3% 66.0M/2.12G [00:01<00:26, 81.9MB/s{'info': ''}]\u001b[A\n",
            "  4% 81.0M/2.12G [00:01<00:21, 100MB/s{'info': ''}] \u001b[A\n",
            "  4% 97.0M/2.12G [00:01<00:24, 89.7MB/s{'info': ''}]\u001b[A\n",
            "  5% 101M/2.12G [00:01<00:31, 68.3MB/s{'info': ''}] \u001b[A\n",
            "  6% 127M/2.12G [00:01<00:19, 108MB/s{'info': ''}] \u001b[A\n",
            "  6% 136M/2.12G [00:02<00:30, 71.2MB/s{'info': ''}]\u001b[A\n",
            "  7% 143M/2.12G [00:02<00:30, 70.1MB/s{'info': ''}]\u001b[A\n",
            "  7% 154M/2.12G [00:02<00:26, 78.7MB/s{'info': ''}]\u001b[A\n",
            "  7% 163M/2.12G [00:02<00:28, 74.7MB/s{'info': ''}]\u001b[A\n",
            "  9% 189M/2.12G [00:02<00:17, 117MB/s{'info': ''}] \u001b[A\n",
            "  9% 204M/2.12G [00:02<00:16, 124MB/s{'info': ''}]\u001b[A\n",
            " 10% 223M/2.12G [00:02<00:14, 141MB/s{'info': ''}]\u001b[A\n",
            " 11% 234M/2.12G [00:03<00:15, 132MB/s{'info': ''}]\u001b[A\n",
            " 11% 239M/2.12G [00:03<00:18, 110MB/s{'info': ''}]\u001b[A\n",
            " 11% 241M/2.12G [00:03<00:36, 55.1MB/s{'info': ''}]\u001b[A\n",
            " 11% 242M/2.12G [00:03<00:58, 34.4MB/s{'info': ''}]\u001b[A\n",
            " 13% 274M/2.12G [00:03<00:22, 87.5MB/s{'info': ''}]\u001b[A\n",
            " 14% 308M/2.12G [00:03<00:13, 141MB/s{'info': ''}] \u001b[A\n",
            " 16% 343M/2.12G [00:03<00:10, 190MB/s{'info': ''}]\u001b[A\n",
            " 17% 372M/2.12G [00:04<00:08, 217MB/s{'info': ''}]\u001b[A\n",
            " 18% 396M/2.12G [00:04<00:08, 224MB/s{'info': ''}]\u001b[A\n",
            " 19% 404M/2.12G [00:04<00:10, 170MB/s{'info': ''}]\u001b[A\n",
            " 19% 408M/2.12G [00:04<00:13, 134MB/s{'info': ''}]\u001b[A\n",
            " 19% 420M/2.12G [00:04<00:13, 132MB/s{'info': ''}]\u001b[A\n",
            " 20% 428M/2.12G [00:04<00:21, 84.3MB/s{'info': ''}]\u001b[A\n",
            " 20% 430M/2.12G [00:04<00:29, 62.0MB/s{'info': ''}]\u001b[A\n",
            " 20% 444M/2.12G [00:05<00:22, 79.3MB/s{'info': ''}]\u001b[A\n",
            " 21% 447M/2.12G [00:05<00:31, 57.0MB/s{'info': ''}]\u001b[A\n",
            " 22% 469M/2.12G [00:05<00:18, 94.3MB/s{'info': ''}]\u001b[A\n",
            " 23% 505M/2.12G [00:05<00:10, 160MB/s{'info': ''}] \u001b[A\n",
            " 25% 535M/2.12G [00:05<00:08, 197MB/s{'info': ''}]\u001b[A\n",
            " 26% 572M/2.12G [00:05<00:06, 245MB/s{'info': ''}]\u001b[A\n",
            " 28% 605M/2.12G [00:05<00:06, 272MB/s{'info': ''}]\u001b[A\n",
            " 29% 635M/2.12G [00:05<00:05, 282MB/s{'info': ''}]\u001b[A\n",
            " 30% 656M/2.12G [00:05<00:06, 259MB/s{'info': ''}]\u001b[A\n",
            " 31% 665M/2.12G [00:06<00:07, 211MB/s{'info': ''}]\u001b[A\n",
            " 31% 672M/2.12G [00:06<00:11, 135MB/s{'info': ''}]\u001b[A\n",
            " 31% 680M/2.12G [00:06<00:15, 104MB/s{'info': ''}]\u001b[A\n",
            " 32% 687M/2.12G [00:06<00:16, 95.6MB/s{'info': ''}]\u001b[A\n",
            " 32% 695M/2.12G [00:06<00:16, 91.3MB/s{'info': ''}]\u001b[A\n",
            " 32% 702M/2.12G [00:06<00:19, 78.6MB/s{'info': ''}]\u001b[A\n",
            " 33% 721M/2.12G [00:06<00:14, 106MB/s{'info': ''}] \u001b[A\n",
            " 35% 752M/2.12G [00:07<00:09, 153MB/s{'info': ''}]\u001b[A\n",
            " 35% 760M/2.12G [00:07<00:15, 94.3MB/s{'info': ''}]\u001b[A\n",
            " 36% 775M/2.12G [00:07<00:13, 107MB/s{'info': ''}] \u001b[A\n",
            " 36% 784M/2.12G [00:07<00:19, 75.7MB/s{'info': ''}]\u001b[A\n",
            " 36% 788M/2.12G [00:08<00:31, 45.7MB/s{'info': ''}]\u001b[A\n",
            " 36% 789M/2.12G [00:08<01:01, 23.7MB/s{'info': ''}]\u001b[A\n",
            " 38% 825M/2.12G [00:08<00:22, 63.6MB/s{'info': ''}]\u001b[A\n",
            " 39% 849M/2.12G [00:08<00:15, 87.0MB/s{'info': ''}]\u001b[A\n",
            " 39% 858M/2.12G [00:08<00:15, 87.1MB/s{'info': ''}]\u001b[A\n",
            " 40% 880M/2.12G [00:09<00:12, 112MB/s{'info': ''}] \u001b[A\n",
            " 41% 889M/2.12G [00:09<00:12, 107MB/s{'info': ''}]\u001b[A\n",
            " 41% 894M/2.12G [00:09<00:14, 93.9MB/s{'info': ''}]\u001b[A\n",
            " 41% 901M/2.12G [00:09<00:15, 86.6MB/s{'info': ''}]\u001b[A\n",
            " 42% 908M/2.12G [00:09<00:16, 83.0MB/s{'info': ''}]\u001b[A\n",
            " 43% 938M/2.12G [00:09<00:09, 143MB/s{'info': ''}] \u001b[A\n",
            " 45% 972M/2.12G [00:09<00:06, 199MB/s{'info': ''}]\u001b[A\n",
            " 46% 0.98G/2.12G [00:09<00:05, 242MB/s{'info': ''}]\u001b[A\n",
            " 47% 1.00G/2.12G [00:09<00:06, 198MB/s{'info': ''}]\u001b[A\n",
            " 48% 1.02G/2.12G [00:10<00:06, 194MB/s{'info': ''}]\u001b[A\n",
            " 49% 1.04G/2.12G [00:10<00:05, 197MB/s{'info': ''}]\u001b[A\n",
            " 49% 1.05G/2.12G [00:10<00:06, 184MB/s{'info': ''}]\u001b[A\n",
            " 51% 1.09G/2.12G [00:10<00:04, 238MB/s{'info': ''}]\u001b[A\n",
            " 52% 1.10G/2.12G [00:10<00:05, 207MB/s{'info': ''}]\u001b[A\n",
            " 52% 1.10G/2.12G [00:10<00:08, 134MB/s{'info': ''}]\u001b[A\n",
            " 52% 1.11G/2.12G [00:10<00:08, 130MB/s{'info': ''}]\u001b[A\n",
            " 53% 1.13G/2.12G [00:10<00:07, 133MB/s{'info': ''}]\u001b[A\n",
            " 54% 1.14G/2.12G [00:10<00:07, 137MB/s{'info': ''}]\u001b[A\n",
            " 54% 1.15G/2.12G [00:11<00:08, 129MB/s{'info': ''}]\u001b[A\n",
            " 55% 1.16G/2.12G [00:11<00:08, 118MB/s{'info': ''}]\u001b[A\n",
            " 55% 1.17G/2.12G [00:11<00:15, 68.4MB/s{'info': ''}]\u001b[A\n",
            " 55% 1.17G/2.12G [00:11<00:17, 57.2MB/s{'info': ''}]\u001b[A\n",
            " 55% 1.17G/2.12G [00:11<00:21, 47.9MB/s{'info': ''}]\u001b[A\n",
            " 57% 1.20G/2.12G [00:11<00:09, 107MB/s{'info': ''}] \u001b[A\n",
            " 57% 1.21G/2.12G [00:11<00:10, 96.9MB/s{'info': ''}]\u001b[A\n",
            " 57% 1.21G/2.12G [00:12<00:12, 77.4MB/s{'info': ''}]\u001b[A\n",
            " 57% 1.22G/2.12G [00:12<00:20, 47.5MB/s{'info': ''}]\u001b[A\n",
            " 58% 1.22G/2.12G [00:12<00:19, 48.5MB/s{'info': ''}]\u001b[A\n",
            " 59% 1.25G/2.12G [00:12<00:08, 111MB/s{'info': ''}] \u001b[A\n",
            " 61% 1.29G/2.12G [00:12<00:05, 168MB/s{'info': ''}]\u001b[A\n",
            " 62% 1.32G/2.12G [00:12<00:04, 216MB/s{'info': ''}]\u001b[A\n",
            " 64% 1.35G/2.12G [00:12<00:03, 250MB/s{'info': ''}]\u001b[A\n",
            " 65% 1.39G/2.12G [00:12<00:02, 285MB/s{'info': ''}]\u001b[A\n",
            " 67% 1.41G/2.12G [00:12<00:02, 288MB/s{'info': ''}]\u001b[A\n",
            " 68% 1.45G/2.12G [00:13<00:02, 302MB/s{'info': ''}]\u001b[A\n",
            " 69% 1.46G/2.12G [00:13<00:02, 244MB/s{'info': ''}]\u001b[A\n",
            " 70% 1.48G/2.12G [00:13<00:02, 243MB/s{'info': ''}]\u001b[A\n",
            " 70% 1.50G/2.12G [00:13<00:03, 215MB/s{'info': ''}]\u001b[A\n",
            " 71% 1.50G/2.12G [00:13<00:03, 176MB/s{'info': ''}]\u001b[A\n",
            " 71% 1.51G/2.12G [00:13<00:04, 133MB/s{'info': ''}]\u001b[A\n",
            " 72% 1.52G/2.12G [00:13<00:05, 119MB/s{'info': ''}]\u001b[A\n",
            " 72% 1.53G/2.12G [00:13<00:08, 77.5MB/s{'info': ''}]\u001b[A\n",
            " 72% 1.53G/2.12G [00:14<00:09, 64.7MB/s{'info': ''}]\u001b[A\n",
            " 72% 1.53G/2.12G [00:14<00:10, 60.8MB/s{'info': ''}]\u001b[A\n",
            " 72% 1.54G/2.12G [00:14<00:14, 44.3MB/s{'info': ''}]\u001b[A\n",
            " 74% 1.57G/2.12G [00:14<00:05, 117MB/s{'info': ''}] \u001b[A\n",
            " 75% 1.60G/2.12G [00:14<00:03, 171MB/s{'info': ''}]\u001b[A\n",
            " 77% 1.63G/2.12G [00:14<00:02, 223MB/s{'info': ''}]\u001b[A\n",
            " 78% 1.66G/2.12G [00:14<00:02, 244MB/s{'info': ''}]\u001b[A\n",
            " 79% 1.68G/2.12G [00:14<00:02, 233MB/s{'info': ''}]\u001b[A\n",
            " 80% 1.69G/2.12G [00:14<00:02, 195MB/s{'info': ''}]\u001b[A\n",
            " 80% 1.70G/2.12G [00:15<00:03, 139MB/s{'info': ''}]\u001b[A\n",
            " 80% 1.71G/2.12G [00:15<00:03, 139MB/s{'info': ''}]\u001b[A\n",
            " 81% 1.72G/2.12G [00:15<00:03, 133MB/s{'info': ''}]\u001b[A\n",
            " 82% 1.74G/2.12G [00:15<00:03, 123MB/s{'info': ''}]\u001b[A\n",
            " 82% 1.75G/2.12G [00:15<00:03, 113MB/s{'info': ''}]\u001b[A\n",
            " 82% 1.75G/2.12G [00:15<00:04, 89.7MB/s{'info': ''}]\u001b[A\n",
            " 83% 1.76G/2.12G [00:15<00:03, 104MB/s{'info': ''}] \u001b[A\n",
            " 84% 1.78G/2.12G [00:16<00:04, 82.1MB/s{'info': ''}]\u001b[A\n",
            " 85% 1.81G/2.12G [00:16<00:02, 131MB/s{'info': ''}] \u001b[A\n",
            " 87% 1.84G/2.12G [00:16<00:01, 188MB/s{'info': ''}]\u001b[A\n",
            " 88% 1.87G/2.12G [00:16<00:01, 221MB/s{'info': ''}]\u001b[A\n",
            " 90% 1.91G/2.12G [00:16<00:00, 250MB/s{'info': ''}]\u001b[A\n",
            " 91% 1.93G/2.12G [00:16<00:00, 248MB/s{'info': ''}]\u001b[A\n",
            " 91% 1.93G/2.12G [00:16<00:01, 186MB/s{'info': ''}]\u001b[A\n",
            " 92% 1.94G/2.12G [00:16<00:01, 161MB/s{'info': ''}]\u001b[A\n",
            " 92% 1.95G/2.12G [00:16<00:01, 126MB/s{'info': ''}]\u001b[A\n",
            " 93% 1.97G/2.12G [00:17<00:01, 145MB/s{'info': ''}]\u001b[A\n",
            " 93% 1.98G/2.12G [00:17<00:01, 144MB/s{'info': ''}]\u001b[A\n",
            " 94% 1.99G/2.12G [00:17<00:01, 135MB/s{'info': ''}]\u001b[A\n",
            " 94% 2.00G/2.12G [00:17<00:01, 123MB/s{'info': ''}]\u001b[A\n",
            " 94% 2.00G/2.12G [00:17<00:01, 95.4MB/s{'info': ''}]\u001b[A\n",
            " 95% 2.02G/2.12G [00:17<00:00, 134MB/s{'info': ''}] \u001b[A\n",
            " 97% 2.06G/2.12G [00:17<00:00, 198MB/s{'info': ''}]\u001b[A\n",
            " 98% 2.09G/2.12G [00:17<00:00, 243MB/s{'info': ''}]\u001b[A\n",
            "100% 2.12G/2.12G [00:17<00:00, 266MB/s{'info': ''}]\u001b[A\n",
            "Checkout:   0% 0/21 [00:00<?, ?file/s{'info': ''}]\n",
            "!\u001b[A\n",
            "Computing file/dir hashes (only done once)          |0.00 [00:00,      ?md5/s]\u001b[A\n",
            "Computing file/dir hashes (only done once)          |1.00 [00:00,   5.39md5/s]\u001b[A\n",
            "Computing file/dir hashes (only done once)          |2.00 [00:00,   4.88md5/s]\u001b[A\n",
            "                                                                              \u001b[A\n",
            "7ff85c3d81a2c87225af33fee2c13c.dir:   0% 0.00/207 [00:00<?, ?B/s]\u001b[A\n",
            "7ff85c3d81a2c87225af33fee2c13c.dir:   0% 0.00/207 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            "7ff85c3d81a2c87225af33fee2c13c.dir:   0% 0.00/207 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            " 10% 2/21 [00:00<00:05,  3.22file/s{'info': ' /content/drive/MyDrive/DL4NLP/abstract-to-title-generation/data/annotated |'}]\n",
            "!\u001b[A\n",
            "Computing file/dir hashes (only done once)          |0.00 [00:00,      ?md5/s]\u001b[A\n",
            "Computing file/dir hashes (only done once)          |1.00 [00:00,   3.87md5/s]\u001b[A\n",
            "Computing file/dir hashes (only done once)          |2.00 [00:02,   1.41s/md5]\u001b[A\n",
            "                                                                              \u001b[A\n",
            "e34871bf342788e72b9e7906c82751.dir:   0% 0.00/148 [00:00<?, ?B/s]\u001b[A\n",
            "e34871bf342788e72b9e7906c82751.dir:   0% 0.00/148 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            "e34871bf342788e72b9e7906c82751.dir:   0% 0.00/148 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            " 19% 4/21 [00:03<00:14,  1.15file/s{'info': ' /content/drive/MyDrive/DL4NLP/abstract-to-title-generation/model/T5 |'}]      \n",
            "!\u001b[A\n",
            "Computing file/dir hashes (only done once)          |0.00 [00:00,      ?md5/s]\u001b[A\n",
            "Computing file/dir hashes (only done once)          |1.00 [00:00,   4.48md5/s]\u001b[A\n",
            "Computing file/dir hashes (only done once)          |2.00 [00:04,   2.36s/md5]\u001b[A\n",
            "                                                                              \u001b[A\n",
            "e15b8604517e9a03e8ba9be6b0ef4e.dir:   0% 0.00/148 [00:00<?, ?B/s]\u001b[A\n",
            "e15b8604517e9a03e8ba9be6b0ef4e.dir:   0% 0.00/148 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            "e15b8604517e9a03e8ba9be6b0ef4e.dir:   0% 0.00/148 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            " 29% 6/21 [00:07<00:21,  1.42s/file{'info': ' /content/drive/MyDrive/DL4NLP/abstract-to-title-generation/model/GPT2 |'}]\n",
            "!\u001b[A\n",
            "Computing file/dir hashes (only done once)          |0.00 [00:00,      ?md5/s]\u001b[A\n",
            "                                                                                                                        \n",
            "\u001b[AComputing md5 for a large file '/content/drive/MyDrive/DL4NLP/abstract-to-title-generation/model/BART-XSum/pytorch_model.bin'. This is only done once.\n",
            " 29% 6/21 [00:07<00:21,  1.42s/file{'info': ' /content/drive/MyDrive/DL4NLP/abstract-to-title-generation/model/GPT2 |'}]\n",
            "Computing file/dir hashes (only done once)          |1.00 [00:00,   4.04md5/s]\u001b[A\n",
            "\n",
            "  0% 0.00/1.51G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "  0% 0.00/1.51G [00:00<?, ?B/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  0% 4.00M/1.51G [00:00<01:27, 18.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  1% 12.0M/1.51G [00:00<00:37, 42.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  1% 14.0M/1.51G [00:00<01:03, 25.4MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  1% 15.0M/1.51G [00:01<03:09, 8.49MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  1% 16.0M/1.51G [00:01<03:06, 8.61MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  3% 47.0M/1.51G [00:01<00:27, 57.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  5% 80.0M/1.51G [00:01<00:14, 110MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            "  7% 112M/1.51G [00:01<00:09, 155MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            "  9% 143M/1.51G [00:01<00:07, 192MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 11% 178M/1.51G [00:01<00:06, 235MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 13% 201M/1.51G [00:01<00:06, 227MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 14% 216M/1.51G [00:02<00:06, 206MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 15% 231M/1.51G [00:02<00:07, 191MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 16% 243M/1.51G [00:02<00:07, 171MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 16% 250M/1.51G [00:02<00:12, 107MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 17% 259M/1.51G [00:02<00:13, 102MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 17% 265M/1.51G [00:02<00:19, 70.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 17% 268M/1.51G [00:03<00:27, 48.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 19% 301M/1.51G [00:03<00:12, 105MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 21% 333M/1.51G [00:03<00:08, 153MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 23% 363M/1.51G [00:03<00:06, 190MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 26% 398M/1.51G [00:03<00:05, 233MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 28% 430M/1.51G [00:03<00:04, 259MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 30% 459M/1.51G [00:03<00:04, 266MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 30% 467M/1.51G [00:03<00:05, 215MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 30% 471M/1.51G [00:03<00:07, 149MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 30% 472M/1.51G [00:04<00:16, 67.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 31% 473M/1.51G [00:04<00:27, 41.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 31% 481M/1.51G [00:04<00:23, 47.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 32% 492M/1.51G [00:04<00:18, 59.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 34% 524M/1.51G [00:04<00:09, 116MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 36% 557M/1.51G [00:04<00:06, 168MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 38% 591M/1.51G [00:05<00:04, 214MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 40% 622M/1.51G [00:05<00:04, 243MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 42% 655M/1.51G [00:05<00:03, 270MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 44% 688M/1.51G [00:05<00:03, 289MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 46% 718M/1.51G [00:05<00:02, 296MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 48% 740M/1.51G [00:05<00:03, 274MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 48% 748M/1.51G [00:05<00:04, 191MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 50% 776M/1.51G [00:05<00:03, 217MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 51% 788M/1.51G [00:06<00:05, 157MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 51% 792M/1.51G [00:06<00:06, 127MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 51% 796M/1.51G [00:06<00:07, 104MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 51% 798M/1.51G [00:06<00:10, 76.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 52% 804M/1.51G [00:06<00:12, 61.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 52% 805M/1.51G [00:06<00:20, 37.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 52% 806M/1.51G [00:06<00:26, 29.3MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 52% 807M/1.51G [00:07<00:33, 23.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 52% 808M/1.51G [00:07<00:43, 18.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 52% 809M/1.51G [00:07<00:49, 15.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 54% 839M/1.51G [00:07<00:09, 82.3MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 55% 851M/1.51G [00:07<00:07, 92.4MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 56% 871M/1.51G [00:07<00:05, 122MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 58% 896M/1.51G [00:07<00:04, 159MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 59% 921M/1.51G [00:07<00:03, 185MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 61% 949M/1.51G [00:07<00:02, 216MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 62% 961M/1.51G [00:08<00:03, 185MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 63% 970M/1.51G [00:08<00:03, 157MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 63% 977M/1.51G [00:08<00:05, 111MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 63% 978M/1.51G [00:08<00:07, 84.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 64% 992M/1.51G [00:08<00:05, 100MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 66% 0.99G/1.51G [00:08<00:03, 143MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 67% 1.02G/1.51G [00:08<00:02, 184MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 69% 1.05G/1.51G [00:08<00:02, 211MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 71% 1.07G/1.51G [00:08<00:02, 225MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 72% 1.09G/1.51G [00:09<00:02, 212MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 72% 1.10G/1.51G [00:09<00:02, 173MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 74% 1.12G/1.51G [00:09<00:02, 185MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 75% 1.13G/1.51G [00:09<00:02, 165MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 75% 1.13G/1.51G [00:09<00:04, 86.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 75% 1.14G/1.51G [00:09<00:04, 92.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 76% 1.14G/1.51G [00:09<00:06, 61.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 76% 1.14G/1.51G [00:10<00:15, 26.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 76% 1.15G/1.51G [00:10<00:23, 17.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 77% 1.17G/1.51G [00:10<00:08, 45.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 79% 1.20G/1.51G [00:11<00:03, 93.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 81% 1.23G/1.51G [00:11<00:02, 129MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 83% 1.26G/1.51G [00:11<00:01, 174MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 85% 1.29G/1.51G [00:11<00:01, 212MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 87% 1.32G/1.51G [00:11<00:00, 238MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 89% 1.35G/1.51G [00:11<00:00, 232MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 89% 1.35G/1.51G [00:11<00:01, 100MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 90% 1.36G/1.51G [00:12<00:01, 91.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 92% 1.39G/1.51G [00:12<00:00, 144MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 94% 1.42G/1.51G [00:12<00:00, 178MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 96% 1.45G/1.51G [00:12<00:00, 216MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 98% 1.48G/1.51G [00:12<00:00, 250MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "100% 1.51G/1.51G [00:12<00:00, 265MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "Computing file/dir hashes (only done once)          |2.00 [00:13,   7.64s/md5]\u001b[A\n",
            "                                                                              \u001b[A\n",
            "ca4e70571a46a8cd5b14cebf93cc30.dir:   0% 0.00/148 [00:00<?, ?B/s]\u001b[A\n",
            "ca4e70571a46a8cd5b14cebf93cc30.dir:   0% 0.00/148 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            "ca4e70571a46a8cd5b14cebf93cc30.dir:   0% 0.00/148 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            " 38% 8/21 [00:20<00:45,  3.47s/file{'info': ' /content/drive/MyDrive/DL4NLP/abstract-to-title-generation/model/BART-XSum |'}]\n",
            "!\u001b[A\n",
            "                                                                                                                             \n",
            "\u001b[AComputing md5 for a large file '/content/drive/MyDrive/DL4NLP/abstract-to-title-generation/model/BART-CNN/pytorch_model.bin'. This is only done once.\n",
            " 38% 8/21 [00:20<00:45,  3.47s/file{'info': ' /content/drive/MyDrive/DL4NLP/abstract-to-title-generation/model/BART-XSum |'}]\n",
            "Computing file/dir hashes (only done once)          |0.00 [00:00,      ?md5/s]\u001b[A\n",
            "\n",
            "  0% 0.00/1.51G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "  0% 0.00/1.51G [00:00<?, ?B/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  0% 5.00M/1.51G [00:00<01:22, 19.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  1% 18.0M/1.51G [00:00<00:26, 60.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  2% 37.0M/1.51G [00:00<00:14, 106MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            "  3% 49.0M/1.51G [00:00<00:14, 111MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  4% 64.0M/1.51G [00:00<00:12, 120MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  5% 70.0M/1.51G [00:00<00:15, 98.4MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  5% 76.0M/1.51G [00:00<00:18, 84.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  5% 77.0M/1.51G [00:01<00:25, 60.4MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  5% 83.0M/1.51G [00:01<00:25, 60.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  6% 86.0M/1.51G [00:01<00:30, 50.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  6% 93.0M/1.51G [00:01<00:27, 55.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  6% 94.0M/1.51G [00:01<00:39, 38.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  8% 118M/1.51G [00:01<00:15, 95.6MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 10% 148M/1.51G [00:01<00:09, 155MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 11% 177M/1.51G [00:01<00:07, 196MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 14% 210M/1.51G [00:01<00:05, 237MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 15% 225M/1.51G [00:02<00:06, 209MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 15% 234M/1.51G [00:02<00:07, 173MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 16% 245M/1.51G [00:02<00:08, 155MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 17% 268M/1.51G [00:02<00:07, 177MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 17% 270M/1.51G [00:02<00:10, 126MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 17% 271M/1.51G [00:02<00:18, 71.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 18% 272M/1.51G [00:02<00:27, 49.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 18% 273M/1.51G [00:03<00:48, 27.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 20% 305M/1.51G [00:03<00:15, 83.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 22% 337M/1.51G [00:03<00:09, 135MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 24% 367M/1.51G [00:03<00:07, 175MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 26% 400M/1.51G [00:03<00:05, 216MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 28% 434M/1.51G [00:03<00:04, 251MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 30% 466M/1.51G [00:03<00:04, 273MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 32% 494M/1.51G [00:03<00:04, 277MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 33% 506M/1.51G [00:03<00:04, 225MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 33% 518M/1.51G [00:04<00:05, 196MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 35% 535M/1.51G [00:04<00:06, 172MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 35% 536M/1.51G [00:04<00:12, 87.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 35% 537M/1.51G [00:04<00:21, 50.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 36% 557M/1.51G [00:04<00:14, 73.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 37% 577M/1.51G [00:05<00:10, 95.4MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 39% 607M/1.51G [00:05<00:07, 140MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 41% 639M/1.51G [00:05<00:05, 184MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 43% 672M/1.51G [00:05<00:04, 223MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 46% 706M/1.51G [00:05<00:03, 257MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 48% 742M/1.51G [00:05<00:02, 288MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 50% 771M/1.51G [00:05<00:02, 286MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 50% 776M/1.51G [00:05<00:05, 139MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 50% 778M/1.51G [00:06<00:10, 77.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 51% 784M/1.51G [00:06<00:10, 75.4MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 52% 808M/1.51G [00:06<00:08, 95.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 53% 816M/1.51G [00:06<00:08, 93.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 54% 840M/1.51G [00:06<00:07, 99.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 55% 852M/1.51G [00:07<00:07, 99.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 56% 872M/1.51G [00:07<00:06, 109MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 57% 880M/1.51G [00:07<00:07, 99.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 58% 894M/1.51G [00:07<00:06, 109MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 58% 904M/1.51G [00:07<00:07, 86.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 60% 926M/1.51G [00:07<00:05, 118MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 60% 928M/1.51G [00:07<00:06, 94.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 60% 930M/1.51G [00:07<00:09, 69.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 61% 949M/1.51G [00:08<00:06, 102MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 62% 960M/1.51G [00:08<00:06, 102MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 62% 968M/1.51G [00:08<00:06, 94.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 63% 976M/1.51G [00:08<00:07, 75.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 63% 979M/1.51G [00:08<00:10, 54.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 65% 0.98G/1.51G [00:08<00:06, 94.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 65% 0.98G/1.51G [00:08<00:07, 77.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 66% 1.00G/1.51G [00:08<00:05, 97.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 67% 1.01G/1.51G [00:09<00:04, 118MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 68% 1.02G/1.51G [00:09<00:07, 72.4MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 68% 1.04G/1.51G [00:09<00:06, 81.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 69% 1.05G/1.51G [00:09<00:05, 88.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 71% 1.07G/1.51G [00:10<00:10, 46.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 72% 1.09G/1.51G [00:10<00:07, 59.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 74% 1.12G/1.51G [00:10<00:04, 95.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 74% 1.12G/1.51G [00:10<00:05, 73.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 75% 1.13G/1.51G [00:11<00:09, 41.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 75% 1.14G/1.51G [00:11<00:09, 43.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 76% 1.16G/1.51G [00:11<00:05, 64.4MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 77% 1.16G/1.51G [00:11<00:06, 57.3MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 77% 1.17G/1.51G [00:12<00:06, 54.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 78% 1.18G/1.51G [00:12<00:05, 69.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 79% 1.19G/1.51G [00:12<00:04, 71.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 79% 1.20G/1.51G [00:12<00:05, 67.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 80% 1.21G/1.51G [00:12<00:03, 89.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 81% 1.23G/1.51G [00:12<00:04, 62.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 81% 1.23G/1.51G [00:13<00:05, 58.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 83% 1.25G/1.51G [00:13<00:02, 96.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 83% 1.26G/1.51G [00:13<00:03, 72.4MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 85% 1.28G/1.51G [00:13<00:02, 113MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 86% 1.30G/1.51G [00:13<00:03, 65.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 87% 1.31G/1.51G [00:14<00:03, 57.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 88% 1.33G/1.51G [00:14<00:02, 73.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 89% 1.35G/1.51G [00:14<00:01, 94.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 90% 1.37G/1.51G [00:14<00:01, 107MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 91% 1.38G/1.51G [00:14<00:01, 79.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 91% 1.38G/1.51G [00:15<00:02, 51.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 91% 1.38G/1.51G [00:15<00:03, 43.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 93% 1.41G/1.51G [00:15<00:01, 103MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 94% 1.42G/1.51G [00:15<00:01, 99.3MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 95% 1.44G/1.51G [00:15<00:00, 134MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 97% 1.46G/1.51G [00:15<00:00, 138MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 98% 1.48G/1.51G [00:15<00:00, 143MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 99% 1.49G/1.51G [00:15<00:00, 135MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 99% 1.50G/1.51G [00:16<00:00, 117MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "Computing file/dir hashes (only done once)          |1.00 [00:16,   16.3s/md5]\u001b[A\n",
            "Computing file/dir hashes (only done once)          |2.00 [00:16,   6.84s/md5]\u001b[A\n",
            "                                                                              \u001b[A\n",
            "40d83206bbedf13326333bb63cbbc9.dir:   0% 0.00/148 [00:00<?, ?B/s]\u001b[A\n",
            "40d83206bbedf13326333bb63cbbc9.dir:   0% 0.00/148 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            "40d83206bbedf13326333bb63cbbc9.dir:   0% 0.00/148 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            " 48% 10/21 [00:37<00:57,  5.20s/file{'info': ' /content/drive/MyDrive/DL4NLP/abstract-to-title-generation/model/BART-CNN |'}]\n",
            "!\u001b[A\n",
            "Computing file/dir hashes (only done once)          |0.00 [00:00,      ?md5/s]\u001b[A\n",
            "                                                                                                                             \n",
            "\u001b[AComputing md5 for a large file '/content/drive/MyDrive/DL4NLP/abstract-to-title-generation/model/PEGASUS-XSum/pytorch_model.bin'. This is only done once.\n",
            " 48% 10/21 [00:37<00:57,  5.20s/file{'info': ' /content/drive/MyDrive/DL4NLP/abstract-to-title-generation/model/BART-CNN |'}]\n",
            "Computing file/dir hashes (only done once)          |1.00 [00:00,   5.47md5/s]\u001b[A\n",
            "\n",
            "  0% 0.00/2.12G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "  0% 0.00/2.12G [00:00<?, ?B/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  0% 1.00M/2.12G [00:00<10:55, 3.47MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  0% 6.00M/2.12G [00:00<01:59, 19.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  1% 18.0M/2.12G [00:00<00:48, 46.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  1% 19.0M/2.12G [00:01<02:36, 14.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  1% 20.0M/2.12G [00:01<03:22, 11.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  2% 50.0M/2.12G [00:01<00:42, 52.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  4% 84.0M/2.12G [00:01<00:21, 102MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            "  5% 116M/2.12G [00:01<00:14, 146MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            "  7% 147M/2.12G [00:01<00:11, 184MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "  8% 181M/2.12G [00:01<00:09, 223MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 10% 210M/2.12G [00:02<00:08, 238MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 10% 220M/2.12G [00:02<00:13, 153MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 10% 221M/2.12G [00:02<00:27, 74.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 11% 241M/2.12G [00:02<00:21, 95.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 12% 259M/2.12G [00:02<00:17, 113MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 13% 282M/2.12G [00:03<00:14, 137MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 14% 307M/2.12G [00:03<00:11, 164MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 16% 340M/2.12G [00:03<00:09, 208MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 17% 359M/2.12G [00:03<00:09, 204MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 18% 382M/2.12G [00:03<00:08, 213MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 19% 407M/2.12G [00:03<00:08, 224MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 20% 432M/2.12G [00:03<00:07, 234MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 21% 455M/2.12G [00:03<00:07, 232MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 22% 474M/2.12G [00:03<00:08, 219MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 23% 503M/2.12G [00:03<00:07, 240MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 24% 512M/2.12G [00:04<00:08, 198MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 24% 519M/2.12G [00:04<00:10, 160MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 24% 528M/2.12G [00:04<00:12, 141MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 25% 552M/2.12G [00:04<00:09, 172MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 26% 571M/2.12G [00:04<00:09, 178MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 27% 590M/2.12G [00:04<00:09, 181MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 28% 600M/2.12G [00:04<00:15, 107MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 28% 605M/2.12G [00:04<00:17, 92.3MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 29% 632M/2.12G [00:05<00:16, 99.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 29% 639M/2.12G [00:05<00:24, 64.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 30% 660M/2.12G [00:05<00:18, 87.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 30% 661M/2.12G [00:05<00:22, 70.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 31% 677M/2.12G [00:05<00:17, 88.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 32% 703M/2.12G [00:06<00:14, 103MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 33% 722M/2.12G [00:06<00:13, 115MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 34% 744M/2.12G [00:06<00:10, 138MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 35% 762M/2.12G [00:06<00:12, 120MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 36% 784M/2.12G [00:06<00:10, 140MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 37% 798M/2.12G [00:06<00:10, 141MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 37% 814M/2.12G [00:06<00:09, 144MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 37% 815M/2.12G [00:07<00:17, 79.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 38% 816M/2.12G [00:07<00:26, 53.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 38% 830M/2.12G [00:07<00:19, 71.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 39% 857M/2.12G [00:07<00:14, 97.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 40% 877M/2.12G [00:07<00:11, 115MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 41% 902M/2.12G [00:07<00:09, 147MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 43% 934M/2.12G [00:07<00:06, 191MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 44% 966M/2.12G [00:08<00:05, 227MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 45% 968M/2.12G [00:08<00:08, 158MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 45% 974M/2.12G [00:09<00:32, 38.3MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 45% 988M/2.12G [00:09<00:25, 48.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 46% 0.98G/2.12G [00:09<00:18, 65.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 47% 1.00G/2.12G [00:09<00:15, 78.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 48% 1.03G/2.12G [00:09<00:09, 121MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 49% 1.03G/2.12G [00:09<00:14, 81.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 49% 1.04G/2.12G [00:10<00:16, 70.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 50% 1.06G/2.12G [00:10<00:10, 104MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 50% 1.07G/2.12G [00:10<00:11, 97.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 51% 1.09G/2.12G [00:10<00:08, 126MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 52% 1.10G/2.12G [00:10<00:09, 116MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 52% 1.10G/2.12G [00:10<00:14, 77.1MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 53% 1.12G/2.12G [00:10<00:10, 101MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 54% 1.14G/2.12G [00:10<00:07, 141MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 54% 1.15G/2.12G [00:10<00:07, 132MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 55% 1.17G/2.12G [00:11<00:06, 150MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 56% 1.19G/2.12G [00:11<00:07, 137MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 56% 1.19G/2.12G [00:11<00:09, 102MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 56% 1.19G/2.12G [00:11<00:13, 75.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 56% 1.20G/2.12G [00:11<00:15, 65.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 57% 1.20G/2.12G [00:11<00:16, 61.3MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 57% 1.22G/2.12G [00:11<00:10, 94.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 59% 1.25G/2.12G [00:11<00:06, 148MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 59% 1.26G/2.12G [00:12<00:07, 128MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 60% 1.27G/2.12G [00:12<00:06, 141MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 60% 1.28G/2.12G [00:12<00:12, 70.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 60% 1.28G/2.12G [00:13<00:32, 27.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 62% 1.32G/2.12G [00:13<00:13, 63.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 63% 1.35G/2.12G [00:13<00:08, 102MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 65% 1.38G/2.12G [00:13<00:05, 135MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 66% 1.41G/2.12G [00:13<00:04, 178MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 68% 1.44G/2.12G [00:13<00:03, 214MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 70% 1.48G/2.12G [00:13<00:02, 246MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 71% 1.51G/2.12G [00:13<00:02, 261MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 72% 1.54G/2.12G [00:14<00:02, 281MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 73% 1.55G/2.12G [00:14<00:02, 211MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 73% 1.55G/2.12G [00:14<00:05, 106MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 73% 1.55G/2.12G [00:15<00:14, 42.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 74% 1.58G/2.12G [00:15<00:08, 70.5MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 76% 1.61G/2.12G [00:15<00:05, 110MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 77% 1.64G/2.12G [00:15<00:03, 146MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 79% 1.67G/2.12G [00:15<00:02, 181MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 80% 1.70G/2.12G [00:15<00:02, 217MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 82% 1.73G/2.12G [00:15<00:01, 244MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 83% 1.77G/2.12G [00:15<00:01, 279MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 85% 1.79G/2.12G [00:15<00:01, 274MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 85% 1.80G/2.12G [00:16<00:01, 221MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 86% 1.83G/2.12G [00:16<00:01, 253MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 87% 1.86G/2.12G [00:16<00:01, 246MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 88% 1.88G/2.12G [00:16<00:01, 237MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 89% 1.90G/2.12G [00:16<00:01, 233MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 90% 1.91G/2.12G [00:16<00:01, 205MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 90% 1.92G/2.12G [00:16<00:01, 152MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 91% 1.92G/2.12G [00:16<00:01, 128MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 91% 1.93G/2.12G [00:16<00:02, 93.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 92% 1.95G/2.12G [00:17<00:01, 111MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 92% 1.95G/2.12G [00:17<00:02, 90.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 93% 1.96G/2.12G [00:17<00:01, 98.4MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 93% 1.98G/2.12G [00:17<00:02, 76.0MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 94% 1.99G/2.12G [00:17<00:02, 53.3MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 94% 2.00G/2.12G [00:18<00:02, 59.6MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 95% 2.01G/2.12G [00:18<00:01, 69.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 95% 2.02G/2.12G [00:18<00:01, 81.2MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 95% 2.02G/2.12G [00:18<00:01, 63.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 95% 2.03G/2.12G [00:18<00:02, 48.8MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 95% 2.03G/2.12G [00:18<00:02, 39.7MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 96% 2.03G/2.12G [00:18<00:02, 41.9MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 96% 2.05G/2.12G [00:18<00:01, 67.4MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            " 98% 2.07G/2.12G [00:18<00:00, 123MB/s{'info': ''}] \u001b[A\u001b[A\n",
            "\n",
            " 99% 2.10G/2.12G [00:19<00:00, 165MB/s{'info': ''}]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "Computing file/dir hashes (only done once)          |2.00 [00:19,   11.5s/md5]\u001b[A\n",
            "                                                                              \u001b[A\n",
            "97b4fb6099b1112907f12e43462b46.dir:   0% 0.00/148 [00:00<?, ?B/s]\u001b[A\n",
            "97b4fb6099b1112907f12e43462b46.dir:   0% 0.00/148 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            "97b4fb6099b1112907f12e43462b46.dir:   0% 0.00/148 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            " 57% 12/21 [00:56<01:01,  6.78s/file{'info': ' /content/drive/MyDrive/DL4NLP/abstract-to-title-generation/model/PEGASUS-XSum |'}]\n",
            "!\u001b[A\n",
            "Computing file/dir hashes (only done once)          |0.00 [00:00,      ?md5/s]\u001b[A\n",
            "Computing file/dir hashes (only done once)          |1.00 [00:01,   1.05s/md5]\u001b[A\n",
            "Computing file/dir hashes (only done once)          |2.00 [00:01,   1.13md5/s]\u001b[A\n",
            "                                                                              \u001b[A\n",
            "1c3f219a60e3ba3b58cc402fed0c29.dir:   0% 0.00/188 [00:00<?, ?B/s]\u001b[A\n",
            "1c3f219a60e3ba3b58cc402fed0c29.dir:   0% 0.00/188 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            "1c3f219a60e3ba3b58cc402fed0c29.dir:   0% 0.00/188 [00:00<?, ?B/s{'info': ''}]\u001b[A\n",
            " 67% 14/21 [00:58<00:34,  4.87s/file{'info': ' /content/drive/MyDrive/DL4NLP/abstract-to-title-generation/data/raw |'}]          \n",
            "!\u001b[A\n",
            "Computing file/dir hashes (only done once)          |0.00 [00:00,      ?md5/s]\u001b[A\n",
            "Computing file/dir hashes (only done once)          |1.00 [00:00,   1.68md5/s]\u001b[A\n",
            "Computing file/dir hashes (only done once)          |2.00 [00:01,   1.24md5/s]\u001b[A\n",
            "\u001b[31mERROR\u001b[39m: unexpected error - [Errno 95] Operation not supported: '/content/drive/MyDrive/DL4NLP/abstract-to-title-generation/data/filtered/Kopie von train_pairs.gform'\n",
            "\n",
            "\u001b[33mHaving any troubles?\u001b[39m Hit us up at \u001b[34mhttps://dvc.org/support\u001b[39m, we are always happy to help!\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# install requirements\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# pull data only pulls changed data\n",
        "!dvc pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cellView": "form",
        "id": "9WuBmWnZqysV",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import datasets\n",
        "from datasets import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import trange\n",
        "from scipy import stats\n",
        "from transformers import BertModel, BertPreTrainedModel, AutoConfig, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prsgC8BwYuYr"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cellView": "form",
        "id": "nit7GMLqFRQ4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# index map, which used to indicate annotated abstract-title pairs.\n",
        "map80 = [[3, 2, 4, 6, 0, 5],\n",
        " [1, 5, 6, 3, 0, 4],\n",
        " [3, 2, 6, 1, 0, 4],\n",
        " [2, 1, 6, 5, 4, 0],\n",
        " [0, 3, 6, 5, 2, 4],\n",
        " [4, 3, 1, 2, 0, 6],\n",
        " [6, 1, 0, 4, 5, 3],\n",
        " [6, 0, 5, 1, 3, 2],\n",
        " [0, 3, 4, 1, 2, 5],\n",
        " [0, 3, 2, 6, 5, 4],\n",
        " [4, 3, 0, 5, 1, 6],\n",
        " [0, 1, 4, 6, 5, 2],\n",
        " [4, 0, 5, 1, 2, 6],\n",
        " [6, 2, 5, 0, 3, 1],\n",
        " [0, 1, 6, 4, 2, 5],\n",
        " [4, 6, 0, 3, 1, 5],\n",
        " [3, 1, 5, 4, 0, 2],\n",
        " [3, 5, 0, 2, 1, 6],\n",
        " [0, 6, 1, 2, 4, 3],\n",
        " [2, 4, 5, 1, 0, 6],\n",
        " [5, 3, 1, 2, 0, 4],\n",
        " [3, 6, 2, 4, 5, 0],\n",
        " [0, 5, 6, 3, 1, 2],\n",
        " [0, 3, 5, 6, 1, 4],\n",
        " [0, 4, 2, 5, 3, 1],\n",
        " [2, 3, 4, 0, 5, 1],\n",
        " [1, 2, 4, 0, 5, 6],\n",
        " [3, 5, 4, 1, 6, 0],\n",
        " [4, 6, 0, 1, 5, 2],\n",
        " [5, 0, 3, 1, 4, 6],\n",
        " [3, 6, 2, 5, 4, 0],\n",
        " [2, 3, 6, 5, 0, 4],\n",
        " [4, 0, 6, 3, 5, 1],\n",
        " [0, 2, 3, 5, 1, 6],\n",
        " [2, 1, 5, 0, 6, 3],\n",
        " [0, 6, 5, 1, 4, 2],\n",
        " [4, 5, 0, 2, 6, 1],\n",
        " [4, 2, 5, 6, 3, 0],\n",
        " [5, 3, 2, 4, 0, 1],\n",
        " [3, 5, 4, 2, 6, 0],\n",
        " [1, 2, 4, 3, 5, 0],\n",
        " [2, 3, 6, 1, 4, 0],\n",
        " [6, 3, 4, 0, 1, 2],\n",
        " [4, 0, 5, 1, 2, 3],\n",
        " [3, 4, 1, 0, 2, 6],\n",
        " [4, 0, 1, 3, 6, 2],\n",
        " [0, 5, 4, 6, 2, 3],\n",
        " [0, 1, 2, 6, 5, 3],\n",
        " [5, 3, 0, 4, 1, 6],\n",
        " [5, 4, 1, 0, 2, 6],\n",
        " [6, 4, 1, 5, 3, 0],\n",
        " [4, 0, 5, 3, 2, 6],\n",
        " [4, 0, 1, 5, 6, 2],\n",
        " [6, 0, 4, 5, 3, 2],\n",
        " [6, 0, 2, 1, 4, 3],\n",
        " [3, 2, 4, 1, 0, 5],\n",
        " [4, 2, 0, 5, 1, 3],\n",
        " [0, 2, 6, 3, 5, 4],\n",
        " [4, 1, 6, 0, 2, 5],\n",
        " [6, 4, 2, 1, 3, 0],\n",
        " [2, 5, 3, 4, 0, 1],\n",
        " [6, 4, 1, 0, 3, 5],\n",
        " [0, 2, 6, 1, 4, 5],\n",
        " [6, 5, 4, 3, 0, 2],\n",
        " [3, 2, 4, 6, 5, 0],\n",
        " [2, 1, 4, 3, 0, 5],\n",
        " [1, 6, 2, 3, 0, 5],\n",
        " [2, 5, 0, 6, 4, 3],\n",
        " [3, 2, 0, 4, 1, 6],\n",
        " [0, 3, 2, 4, 6, 1],\n",
        " [0, 5, 2, 3, 1, 4],\n",
        " [6, 4, 0, 2, 5, 1],\n",
        " [6, 0, 3, 5, 1, 4],\n",
        " [0, 5, 3, 4, 2, 6],\n",
        " [5, 3, 2, 0, 4, 1],\n",
        " [1, 4, 3, 5, 0, 6],\n",
        " [6, 2, 5, 3, 0, 4],\n",
        " [0, 5, 3, 6, 2, 1],\n",
        " [2, 0, 4, 6, 5, 1],\n",
        " [0, 4, 2, 1, 3, 5]]\n",
        "\n",
        "selected_index = [153, 154, 156, 159, 161, 164, 165, 167, 168, 172, 174 ,175, 176, 177, 180, 185, 186, 189, 191, 197, 206, 207, 208, 211, 216, 218, 221, 223, 225, 227, 228, 238, 239, 241, 243, 244, 248, 250, 259, 260, 262, 269, 270, 271 ,275, 287, 288, 291, 294, 299]\n",
        "\n",
        "map50= [[1, 0, 3, 4, 6, 5],\n",
        " [2, 1, 3, 0, 4, 6],\n",
        " [2, 3, 4, 1, 6, 0],\n",
        " [1, 0, 6, 5, 2, 3],\n",
        " [0, 1, 5, 3, 4, 6],\n",
        " [3, 2, 1, 5, 0, 4],\n",
        " [1, 0, 6, 5, 4, 2],\n",
        " [0, 4, 2, 6, 1, 3],\n",
        " [0, 3, 6, 1, 2, 5],\n",
        " [6, 2, 1, 4, 0, 3],\n",
        " [5, 0, 4, 2, 6, 3],\n",
        " [1, 0, 4, 3, 5, 2],\n",
        " [4, 0, 5, 6, 2, 3],\n",
        " [6, 1, 0, 4, 3, 5],\n",
        " [5, 6, 0, 3, 1, 2],\n",
        " [2, 5, 3, 4, 0, 6],\n",
        " [0, 2, 6, 5, 4, 1],\n",
        " [0, 3, 2, 1, 4, 6],\n",
        " [2, 5, 1, 6, 0, 4],\n",
        " [2, 5, 3, 1, 4, 0],\n",
        " [3, 4, 1, 6, 2, 0],\n",
        " [6, 3, 2, 1, 0, 5],\n",
        " [0, 6, 5, 1, 2, 4],\n",
        " [0, 6, 1, 3, 5, 4],\n",
        " [3, 2, 5, 1, 4, 0],\n",
        " [3, 4, 0, 5, 1, 6],\n",
        " [2, 5, 4, 0, 6, 1],\n",
        " [4, 2, 1, 6, 0, 3],\n",
        " [2, 4, 5, 6, 0, 3],\n",
        " [0, 5, 6, 2, 3, 1],\n",
        " [0, 5, 4, 3, 1, 2],\n",
        " [4, 1, 6, 5, 2, 0],\n",
        " [5, 3, 1, 0, 2, 6],\n",
        " [1, 5, 2, 4, 3, 0],\n",
        " [2, 1, 0, 3, 4, 5],\n",
        " [2, 0, 4, 5, 6, 3],\n",
        " [2, 5, 4, 1, 6, 0],\n",
        " [0, 5, 2, 1, 6, 4],\n",
        " [0, 5, 2, 4, 3, 1],\n",
        " [5, 2, 6, 1, 0, 3],\n",
        " [0, 2, 3, 6, 4, 5],\n",
        " [4, 5, 6, 2, 3, 0],\n",
        " [6, 2, 5, 4, 1, 0],\n",
        " [2, 6, 0, 1, 3, 5],\n",
        " [0, 1, 4, 5, 6, 2],\n",
        " [5, 1, 4, 6, 0, 3],\n",
        " [6, 0, 5, 4, 2, 1],\n",
        " [6, 4, 1, 0, 3, 2],\n",
        " [5, 0, 2, 3, 4, 6],\n",
        " [2, 3, 0, 1, 6, 5]]\n",
        "\n",
        "map_model = [['bart_xsum', 'bart_cnn', 't5', 'pegasus_xsum', 'original', 'gpt2'],\n",
        " ['bart_base', 'gpt2', 'pegasus_xsum', 'bart_xsum', 'original', 't5'],\n",
        " ['bart_xsum', 'bart_cnn', 'pegasus_xsum', 'bart_base', 'original', 't5'],\n",
        " ['bart_cnn', 'bart_base', 'pegasus_xsum', 'gpt2', 't5', 'original'],\n",
        " ['original', 'bart_xsum', 'pegasus_xsum', 'gpt2', 'bart_cnn', 't5'],\n",
        " ['t5', 'bart_xsum', 'bart_base', 'bart_cnn', 'original', 'pegasus_xsum'],\n",
        " ['pegasus_xsum', 'bart_base', 'original', 't5', 'gpt2', 'bart_xsum'],\n",
        " ['pegasus_xsum', 'original', 'gpt2', 'bart_base', 'bart_xsum', 'bart_cnn'],\n",
        " ['original', 'bart_xsum', 't5', 'bart_base', 'bart_cnn', 'gpt2'],\n",
        " ['original', 'bart_xsum', 'bart_cnn', 'pegasus_xsum', 'gpt2', 't5'],\n",
        " ['t5', 'bart_xsum', 'original', 'gpt2', 'bart_base', 'pegasus_xsum'],\n",
        " ['original', 'bart_base', 't5', 'pegasus_xsum', 'gpt2', 'bart_cnn'],\n",
        " ['t5', 'original', 'gpt2', 'bart_base', 'bart_cnn', 'pegasus_xsum'],\n",
        " ['pegasus_xsum', 'bart_cnn', 'gpt2', 'original', 'bart_xsum', 'bart_base'],\n",
        " ['original', 'bart_base', 'pegasus_xsum', 't5', 'bart_cnn', 'gpt2'],\n",
        " ['t5', 'pegasus_xsum', 'original', 'bart_xsum', 'bart_base', 'gpt2'],\n",
        " ['bart_xsum', 'bart_base', 'gpt2', 't5', 'original', 'bart_cnn'],\n",
        " ['bart_xsum', 'gpt2', 'original', 'bart_cnn', 'bart_base', 'pegasus_xsum'],\n",
        " ['original', 'pegasus_xsum', 'bart_base', 'bart_cnn', 't5', 'bart_xsum'],\n",
        " ['bart_cnn', 't5', 'gpt2', 'bart_base', 'original', 'pegasus_xsum'],\n",
        " ['gpt2', 'bart_xsum', 'bart_base', 'bart_cnn', 'original', 't5'],\n",
        " ['bart_xsum', 'pegasus_xsum', 'bart_cnn', 't5', 'gpt2', 'original'],\n",
        " ['original', 'gpt2', 'pegasus_xsum', 'bart_xsum', 'bart_base', 'bart_cnn'],\n",
        " ['original', 'bart_xsum', 'gpt2', 'pegasus_xsum', 'bart_base', 't5'],\n",
        " ['original', 't5', 'bart_cnn', 'gpt2', 'bart_xsum', 'bart_base'],\n",
        " ['bart_cnn', 'bart_xsum', 't5', 'original', 'gpt2', 'bart_base'],\n",
        " ['bart_base', 'bart_cnn', 't5', 'original', 'gpt2', 'pegasus_xsum'],\n",
        " ['bart_xsum', 'gpt2', 't5', 'bart_base', 'pegasus_xsum', 'original'],\n",
        " ['t5', 'pegasus_xsum', 'original', 'bart_base', 'gpt2', 'bart_cnn'],\n",
        " ['gpt2', 'original', 'bart_xsum', 'bart_base', 't5', 'pegasus_xsum'],\n",
        " ['bart_xsum', 'pegasus_xsum', 'bart_cnn', 'gpt2', 't5', 'original'],\n",
        " ['bart_cnn', 'bart_xsum', 'pegasus_xsum', 'gpt2', 'original', 't5'],\n",
        " ['t5', 'original', 'pegasus_xsum', 'bart_xsum', 'gpt2', 'bart_base'],\n",
        " ['original', 'bart_cnn', 'bart_xsum', 'gpt2', 'bart_base', 'pegasus_xsum'],\n",
        " ['bart_cnn', 'bart_base', 'gpt2', 'original', 'pegasus_xsum', 'bart_xsum'],\n",
        " ['original', 'pegasus_xsum', 'gpt2', 'bart_base', 't5', 'bart_cnn'],\n",
        " ['t5', 'gpt2', 'original', 'bart_cnn', 'pegasus_xsum', 'bart_base'],\n",
        " ['t5', 'bart_cnn', 'gpt2', 'pegasus_xsum', 'bart_xsum', 'original'],\n",
        " ['gpt2', 'bart_xsum', 'bart_cnn', 't5', 'original', 'bart_base'],\n",
        " ['bart_xsum', 'gpt2', 't5', 'bart_cnn', 'pegasus_xsum', 'original'],\n",
        " ['bart_base', 'bart_cnn', 't5', 'bart_xsum', 'gpt2', 'original'],\n",
        " ['bart_cnn', 'bart_xsum', 'pegasus_xsum', 'bart_base', 't5', 'original'],\n",
        " ['pegasus_xsum', 'bart_xsum', 't5', 'original', 'bart_base', 'bart_cnn'],\n",
        " ['t5', 'original', 'gpt2', 'bart_base', 'bart_cnn', 'bart_xsum'],\n",
        " ['bart_xsum', 't5', 'bart_base', 'original', 'bart_cnn', 'pegasus_xsum'],\n",
        " ['t5', 'original', 'bart_base', 'bart_xsum', 'pegasus_xsum', 'bart_cnn'],\n",
        " ['original', 'gpt2', 't5', 'pegasus_xsum', 'bart_cnn', 'bart_xsum'],\n",
        " ['original', 'bart_base', 'bart_cnn', 'pegasus_xsum', 'gpt2', 'bart_xsum'],\n",
        " ['gpt2', 'bart_xsum', 'original', 't5', 'bart_base', 'pegasus_xsum'],\n",
        " ['gpt2', 't5', 'bart_base', 'original', 'bart_cnn', 'pegasus_xsum'],\n",
        " ['bart_base', 'original', 'bart_xsum', 't5', 'pegasus_xsum', 'gpt2'],\n",
        " ['bart_cnn', 'bart_base', 'bart_xsum', 'original', 't5', 'pegasus_xsum'],\n",
        " ['bart_cnn', 'bart_xsum', 't5', 'bart_base', 'pegasus_xsum', 'original'],\n",
        " ['bart_base', 'original', 'pegasus_xsum', 'gpt2', 'bart_cnn', 'bart_xsum'],\n",
        " ['original', 'bart_base', 'gpt2', 'bart_xsum', 't5', 'pegasus_xsum'],\n",
        " ['bart_xsum', 'bart_cnn', 'bart_base', 'gpt2', 'original', 't5'],\n",
        " ['bart_base', 'original', 'pegasus_xsum', 'gpt2', 't5', 'bart_cnn'],\n",
        " ['original', 't5', 'bart_cnn', 'pegasus_xsum', 'bart_base', 'bart_xsum'],\n",
        " ['original', 'bart_xsum', 'pegasus_xsum', 'bart_base', 'bart_cnn', 'gpt2'],\n",
        " ['pegasus_xsum', 'bart_cnn', 'bart_base', 't5', 'original', 'bart_xsum'],\n",
        " ['gpt2', 'original', 't5', 'bart_cnn', 'pegasus_xsum', 'bart_xsum'],\n",
        " ['bart_base', 'original', 't5', 'bart_xsum', 'gpt2', 'bart_cnn'],\n",
        " ['t5', 'original', 'gpt2', 'pegasus_xsum', 'bart_cnn', 'bart_xsum'],\n",
        " ['pegasus_xsum', 'bart_base', 'original', 't5', 'bart_xsum', 'gpt2'],\n",
        " ['gpt2', 'pegasus_xsum', 'original', 'bart_xsum', 'bart_base', 'bart_cnn'],\n",
        " ['bart_cnn', 'gpt2', 'bart_xsum', 't5', 'original', 'pegasus_xsum'],\n",
        " ['original', 'bart_cnn', 'pegasus_xsum', 'gpt2', 't5', 'bart_base'],\n",
        " ['original', 'bart_xsum', 'bart_cnn', 'bart_base', 't5', 'pegasus_xsum'],\n",
        " ['bart_cnn', 'gpt2', 'bart_base', 'pegasus_xsum', 'original', 't5'],\n",
        " ['bart_cnn', 'gpt2', 'bart_xsum', 'bart_base', 't5', 'original'],\n",
        " ['bart_xsum', 't5', 'bart_base', 'pegasus_xsum', 'bart_cnn', 'original'],\n",
        " ['pegasus_xsum', 'bart_xsum', 'bart_cnn', 'bart_base', 'original', 'gpt2'],\n",
        " ['original', 'pegasus_xsum', 'gpt2', 'bart_base', 'bart_cnn', 't5'],\n",
        " ['original', 'pegasus_xsum', 'bart_base', 'bart_xsum', 'gpt2', 't5'],\n",
        " ['bart_xsum', 'bart_cnn', 'gpt2', 'bart_base', 't5', 'original'],\n",
        " ['bart_xsum', 't5', 'original', 'gpt2', 'bart_base', 'pegasus_xsum'],\n",
        " ['bart_cnn', 'gpt2', 't5', 'original', 'pegasus_xsum', 'bart_base'],\n",
        " ['t5', 'bart_cnn', 'bart_base', 'pegasus_xsum', 'original', 'bart_xsum'],\n",
        " ['bart_cnn', 't5', 'gpt2', 'pegasus_xsum', 'original', 'bart_xsum'],\n",
        " ['original', 'gpt2', 'pegasus_xsum', 'bart_cnn', 'bart_xsum', 'bart_base'],\n",
        " ['original', 'gpt2', 't5', 'bart_xsum', 'bart_base', 'bart_cnn'],\n",
        " ['t5', 'bart_base', 'pegasus_xsum', 'gpt2', 'bart_cnn', 'original'],\n",
        " ['gpt2', 'bart_xsum', 'bart_base', 'original', 'bart_cnn', 'pegasus_xsum'],\n",
        " ['bart_base', 'gpt2', 'bart_cnn', 't5', 'bart_xsum', 'original'],\n",
        " ['bart_cnn', 'bart_base', 'original', 'bart_xsum', 't5', 'gpt2'],\n",
        " ['bart_cnn', 'original', 't5', 'gpt2', 'pegasus_xsum', 'bart_xsum'],\n",
        " ['bart_cnn', 'gpt2', 't5', 'bart_base', 'pegasus_xsum', 'original'],\n",
        " ['original', 'gpt2', 'bart_cnn', 'bart_base', 'pegasus_xsum', 't5'],\n",
        " ['original', 'gpt2', 'bart_cnn', 't5', 'bart_xsum', 'bart_base'],\n",
        " ['gpt2', 'bart_cnn', 'pegasus_xsum', 'bart_base', 'original', 'bart_xsum'],\n",
        " ['original', 'bart_cnn', 'bart_xsum', 'pegasus_xsum', 't5', 'gpt2'],\n",
        " ['t5', 'gpt2', 'pegasus_xsum', 'bart_cnn', 'bart_xsum', 'original'],\n",
        " ['pegasus_xsum', 'bart_cnn', 'gpt2', 't5', 'bart_base', 'original'],\n",
        " ['bart_cnn', 'pegasus_xsum', 'original', 'bart_base', 'bart_xsum', 'gpt2'],\n",
        " ['original', 'bart_base', 't5', 'gpt2', 'pegasus_xsum', 'bart_cnn'],\n",
        " ['gpt2', 'bart_base', 't5', 'pegasus_xsum', 'original', 'bart_xsum'],\n",
        " ['pegasus_xsum', 'original', 'gpt2', 't5', 'bart_cnn', 'bart_base'],\n",
        " ['pegasus_xsum', 't5', 'bart_base', 'original', 'bart_xsum', 'bart_cnn'],\n",
        " ['gpt2', 'original', 'bart_cnn', 'bart_xsum', 't5', 'pegasus_xsum'],\n",
        " ['bart_cnn', 'bart_xsum', 'original', 'bart_base', 'pegasus_xsum', 'gpt2'],\n",
        " ['bart_base', 'original', 'bart_xsum', 't5', 'pegasus_xsum', 'gpt2'],\n",
        " ['bart_cnn', 'bart_base', 'bart_xsum', 'original', 't5', 'pegasus_xsum'],\n",
        " ['bart_cnn', 'bart_xsum', 't5', 'bart_base', 'pegasus_xsum', 'original'],\n",
        " ['bart_base', 'original', 'pegasus_xsum', 'gpt2', 'bart_cnn', 'bart_xsum'],\n",
        " ['original', 'bart_base', 'gpt2', 'bart_xsum', 't5', 'pegasus_xsum'],\n",
        " ['bart_xsum', 'bart_cnn', 'bart_base', 'gpt2', 'original', 't5'],\n",
        " ['bart_base', 'original', 'pegasus_xsum', 'gpt2', 't5', 'bart_cnn'],\n",
        " ['original', 't5', 'bart_cnn', 'pegasus_xsum', 'bart_base', 'bart_xsum'],\n",
        " ['original', 'bart_xsum', 'pegasus_xsum', 'bart_base', 'bart_cnn', 'gpt2'],\n",
        " ['pegasus_xsum', 'bart_cnn', 'bart_base', 't5', 'original', 'bart_xsum'],\n",
        " ['gpt2', 'original', 't5', 'bart_cnn', 'pegasus_xsum', 'bart_xsum'],\n",
        " ['bart_base', 'original', 't5', 'bart_xsum', 'gpt2', 'bart_cnn'],\n",
        " ['t5', 'original', 'gpt2', 'pegasus_xsum', 'bart_cnn', 'bart_xsum'],\n",
        " ['pegasus_xsum', 'bart_base', 'original', 't5', 'bart_xsum', 'gpt2'],\n",
        " ['gpt2', 'pegasus_xsum', 'original', 'bart_xsum', 'bart_base', 'bart_cnn'],\n",
        " ['bart_cnn', 'gpt2', 'bart_xsum', 't5', 'original', 'pegasus_xsum'],\n",
        " ['original', 'bart_cnn', 'pegasus_xsum', 'gpt2', 't5', 'bart_base'],\n",
        " ['original', 'bart_xsum', 'bart_cnn', 'bart_base', 't5', 'pegasus_xsum'],\n",
        " ['bart_cnn', 'gpt2', 'bart_base', 'pegasus_xsum', 'original', 't5'],\n",
        " ['bart_cnn', 'gpt2', 'bart_xsum', 'bart_base', 't5', 'original'],\n",
        " ['bart_xsum', 't5', 'bart_base', 'pegasus_xsum', 'bart_cnn', 'original'],\n",
        " ['pegasus_xsum', 'bart_xsum', 'bart_cnn', 'bart_base', 'original', 'gpt2'],\n",
        " ['original', 'pegasus_xsum', 'gpt2', 'bart_base', 'bart_cnn', 't5'],\n",
        " ['original', 'pegasus_xsum', 'bart_base', 'bart_xsum', 'gpt2', 't5'],\n",
        " ['bart_xsum', 'bart_cnn', 'gpt2', 'bart_base', 't5', 'original'],\n",
        " ['bart_xsum', 't5', 'original', 'gpt2', 'bart_base', 'pegasus_xsum'],\n",
        " ['bart_cnn', 'gpt2', 't5', 'original', 'pegasus_xsum', 'bart_base'],\n",
        " ['t5', 'bart_cnn', 'bart_base', 'pegasus_xsum', 'original', 'bart_xsum'],\n",
        " ['bart_cnn', 't5', 'gpt2', 'pegasus_xsum', 'original', 'bart_xsum'],\n",
        " ['original', 'gpt2', 'pegasus_xsum', 'bart_cnn', 'bart_xsum', 'bart_base'],\n",
        " ['original', 'gpt2', 't5', 'bart_xsum', 'bart_base', 'bart_cnn'],\n",
        " ['t5', 'bart_base', 'pegasus_xsum', 'gpt2', 'bart_cnn', 'original'],\n",
        " ['gpt2', 'bart_xsum', 'bart_base', 'original', 'bart_cnn', 'pegasus_xsum'],\n",
        " ['bart_base', 'gpt2', 'bart_cnn', 't5', 'bart_xsum', 'original'],\n",
        " ['bart_cnn', 'bart_base', 'original', 'bart_xsum', 't5', 'gpt2'],\n",
        " ['bart_cnn', 'original', 't5', 'gpt2', 'pegasus_xsum', 'bart_xsum'],\n",
        " ['bart_cnn', 'gpt2', 't5', 'bart_base', 'pegasus_xsum', 'original'],\n",
        " ['original', 'gpt2', 'bart_cnn', 'bart_base', 'pegasus_xsum', 't5'],\n",
        " ['original', 'gpt2', 'bart_cnn', 't5', 'bart_xsum', 'bart_base'],\n",
        " ['gpt2', 'bart_cnn', 'pegasus_xsum', 'bart_base', 'original', 'bart_xsum'],\n",
        " ['original', 'bart_cnn', 'bart_xsum', 'pegasus_xsum', 't5', 'gpt2'],\n",
        " ['t5', 'gpt2', 'pegasus_xsum', 'bart_cnn', 'bart_xsum', 'original'],\n",
        " ['pegasus_xsum', 'bart_cnn', 'gpt2', 't5', 'bart_base', 'original'],\n",
        " ['bart_cnn', 'pegasus_xsum', 'original', 'bart_base', 'bart_xsum', 'gpt2'],\n",
        " ['original', 'bart_base', 't5', 'gpt2', 'pegasus_xsum', 'bart_cnn'],\n",
        " ['gpt2', 'bart_base', 't5', 'pegasus_xsum', 'original', 'bart_xsum'],\n",
        " ['pegasus_xsum', 'original', 'gpt2', 't5', 'bart_cnn', 'bart_base'],\n",
        " ['pegasus_xsum', 't5', 'bart_base', 'original', 'bart_xsum', 'bart_cnn'],\n",
        " ['gpt2', 'original', 'bart_cnn', 'bart_xsum', 't5', 'pegasus_xsum'],\n",
        " ['bart_cnn', 'bart_xsum', 'original', 'bart_base', 'pegasus_xsum', 'gpt2']]\n",
        "\n",
        "\n",
        "def displaysmaples(samples):\n",
        "  i = 0\n",
        "  titles = samples.title.to_list()\n",
        "  abstract = samples.abstract.to_list()\n",
        "  bart_base = samples.bart_base.to_list()\n",
        "  bart_cnn = samples.bart_cnn.to_list()\n",
        "  bart_xsum = samples.bart_xsum.to_list()\n",
        "  t5_small = samples.t5_small.to_list()\n",
        "  gpt2 = samples.gpt2.to_list()\n",
        "  pegasus_xsum = samples.pegasus_xsum.to_list()\n",
        "\n",
        "  for t, a, t1, t2, t3, t4, t5, t6 in zip(titles, abstract, bart_base, bart_cnn, bart_xsum, t5_small, gpt2, pegasus_xsum):\n",
        "    print(\"original title: \", t)\n",
        "    print(\"abstract: \", a)\n",
        "    print(\"from bart_base: \")\n",
        "    gt1 = t1.split(\"<TITLE>\")[1:]\n",
        "    for gt in gt1:\n",
        "      print(gt)\n",
        "    print(\"\\n\")\n",
        "    print(\"from bart_cnn: \")\n",
        "    gt1 = t2.split(\"<TITLE>\")[1:]\n",
        "    for gt in gt1:\n",
        "      print(gt)\n",
        "    print(\"\\n\")\n",
        "    print(\"from bart_xsum: \")\n",
        "    gt1 = t3.split(\"<TITLE>\")[1:]\n",
        "    for gt in gt1:\n",
        "      print(gt)\n",
        "    print(\"\\n\")\n",
        "    print(\"from t5_small: \")\n",
        "    gt1 = t4.split(\"<TITLE>\")[1:]\n",
        "    for gt in gt1:\n",
        "      print(gt)\n",
        "    print(\"\\n\")\n",
        "    print(\"from gpt2: \")\n",
        "    gt1 = t5.split(\"<TITLE>\")[1:]\n",
        "    for gt in gt1:\n",
        "      print(gt)\n",
        "    print(\"\\n\")\n",
        "    print(\"from pegasus_xsum: \")\n",
        "    gt1 = t6.split(\"<TITLE>\")[1:]\n",
        "    for gt in gt1:\n",
        "      print(gt)\n",
        "    print(\"\\n\")\n",
        "    i = i + 1\n",
        "\n",
        "    if i >= 20:\n",
        "      break\n",
        "\n",
        "# index von Optionen der human evaluation, 20 - 99 samples und 100-150(von index 0 bis 49)\n",
        "# [4, 3, 5, 2, 0, 1] bedeutet\n",
        "#1.op aus t5_samall,\n",
        "#2.op aus bart_xsum,\n",
        "#3.op aus gpt2,\n",
        "#4.op aus bart_cnn,\n",
        "#5.op original,\n",
        "#6.op aus bart_base,\n",
        "\n",
        "def getindex():\n",
        "  result = []\n",
        "  for i in range(80):\n",
        "    col = np.arange(1,7)\n",
        "    np.random.shuffle(col)\n",
        "    col = col.tolist()[:-1]\n",
        "    col.append(0)\n",
        "    np.random.shuffle(col)\n",
        "    result.append(col)\n",
        "  return result\n",
        "\n",
        "\n",
        "def sampler(samples, map20, start, end):\n",
        "  i = start\n",
        "  titles = samples.title.to_list()[start: end]\n",
        "  abstract = samples.abstract.to_list()[start: end]\n",
        "  bart_base = samples.bart_base.to_list()[start: end]\n",
        "  bart_cnn = samples.bart_cnn.to_list()[start: end]\n",
        "  bart_xsum = samples.bart_xsum.to_list()[start: end]\n",
        "  t5_small = samples.t5_small.to_list()[start: end]\n",
        "  gpt2 = samples.gpt2.to_list()[start: end]\n",
        "  pegasus_xsum = samples.pegasus_xsum.to_list()[start: end]\n",
        "\n",
        "  tmap = []\n",
        "  for t, a, t1, t2, t3, t4, t5, t6 in zip(titles, abstract, bart_base, bart_cnn, bart_xsum, t5_small, gpt2, pegasus_xsum):\n",
        "    gt1 = t1.split(\"<TITLE>\")[1:][0]\n",
        "    gt2 = t2.split(\"<TITLE>\")[1:][0]\n",
        "    gt3 = t3.split(\"<TITLE>\")[1:][0]\n",
        "    gt4 = t4.split(\"<TITLE>\")[1:][0]\n",
        "    gt5 = t5.split(\"<TITLE>\")[1:][0]\n",
        "    gt6 = t6.split(\"<TITLE>\")[1:][0]\n",
        "    col = [t, gt1, gt2, gt3, gt4, gt5, gt6]\n",
        "    rcol = [col[map20[i][j]] for j in range(6)]\n",
        "    rcol.append(a)\n",
        "    tmap.append(rcol)\n",
        "    i = i + 1\n",
        "\n",
        "  return tmap\n",
        "def map2model(ls):\n",
        "  r = []\n",
        "  for i in ls:\n",
        "    if i == 0:\n",
        "      r.append(\"original\")\n",
        "    if i == 1:\n",
        "      r.append(\"bart_base\")\n",
        "    if i == 2:\n",
        "      r.append(\"bart_cnn\")\n",
        "    if i == 3:\n",
        "      r.append(\"bart_xsum\")\n",
        "    if i == 4:\n",
        "      r.append(\"t5\")\n",
        "    if i == 5:\n",
        "      r.append(\"gpt2\")\n",
        "    if i == 6:\n",
        "      r.append(\"pegasus_xsum\")\n",
        "  return r\n",
        "\n",
        "def map2index(ls):\n",
        "  r = []\n",
        "  for i in ls:\n",
        "    if i == \"original\":\n",
        "      r.append(0)\n",
        "    if i == \"bart_base\":\n",
        "      r.append(1)\n",
        "    if i == \"bart_cnn\":\n",
        "      r.append(2)\n",
        "    if i == \"bart_xsum\":\n",
        "      r.append(3)\n",
        "    if i == \"t5\":\n",
        "      r.append(4)\n",
        "    if i == \"gpt2\":\n",
        "      r.append(5)\n",
        "    if i == \"pegasus_xsum\":\n",
        "      r.append(6)\n",
        "  return r\n",
        "\n",
        "def map2modelAM(ls):\n",
        "  r = []\n",
        "  for i in ls:\n",
        "    if i == 0:\n",
        "      r.append(\"bart_base\")\n",
        "    if i == 1:\n",
        "      r.append(\"bart_cnn\")\n",
        "    if i == 2:\n",
        "      r.append(\"bart_xsum\")\n",
        "    if i == 3:\n",
        "      r.append(\"t5\")\n",
        "    if i == 4:\n",
        "      r.append(\"gpt2\")\n",
        "    if i == 5:\n",
        "      r.append(\"pegasus_xsum\")\n",
        "  return r\n",
        "\n",
        "\n",
        "# index von Optionen der human evaluation, 150 - 200 samples\n",
        "# [4, 3, 5, 2, 0, 1] bedeutet\n",
        "#1.op aus t5_samall,\n",
        "#2.op aus bart_xsum,\n",
        "#3.op aus gpt2,\n",
        "#4.op aus bart_cnn,\n",
        "#5.op original,\n",
        "#6.op aus bart_base,\n",
        "\n",
        "def getindex():\n",
        "  result = []\n",
        "  for i in range(50):\n",
        "    col = np.arange(1,7)\n",
        "    np.random.shuffle(col)\n",
        "    col = col.tolist()[:-1]\n",
        "    col.append(0)\n",
        "    np.random.shuffle(col)\n",
        "    result.append(col)\n",
        "  return result\n",
        "\n",
        "#map für Teinehmer\n",
        "\n",
        "def getTmap():\n",
        "  i = 0\n",
        "  b = False\n",
        "  map30 = []\n",
        "  counters = np.zeros(20).tolist()\n",
        "  while not b:\n",
        "    personMap = np.arange(20)\n",
        "    np.random.shuffle(personMap)\n",
        "    personMap = personMap[:10]\n",
        "    i0 = personMap[0]\n",
        "    i1 = personMap[1]\n",
        "\n",
        "    if (counters[i0] < 3) and (counters[i1] < 3):\n",
        "      counters[i0] = counters[i0] + 1\n",
        "      counters[i1] = counters[i1] + 1\n",
        "      map30.append(personMap)\n",
        "    tb = True\n",
        "    for t in counters:\n",
        "      tb = tb and (t == 3)\n",
        "    b = tb\n",
        "    if b == True:\n",
        "      print(\"terminiert at:\", counters)\n",
        "  return map30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0woEoArFGmq8",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "---\n",
        "\n",
        "# **Fine Tuning**\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "cellView": "form",
        "id": "GQnEmWjNsJJK",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class Excerpt_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, maxlen, tokenizer):\n",
        "        #Store the contents of the file in a pandas dataframe\n",
        "        self.df = data.reset_index()\n",
        "        #Initialize the tokenizer for the desired transformer model\n",
        "        self.tokenizer = tokenizer\n",
        "        #Maximum length of the tokens list to keep all the sequences of fixed size\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #Select the sentence and label at the specified index in the data frame\n",
        "        excerpt = self.df.loc[index, 'excerpt']\n",
        "        try:\n",
        "            target = self.df.loc[index, 'target']\n",
        "        except:\n",
        "            target = 0.0\n",
        "        #identifier = self.df.loc[index, 'id']\n",
        "        #Preprocess the text to be suitable for the transformer\n",
        "        tokens = self.tokenizer.tokenize(excerpt)\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))]\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]']\n",
        "        #Obtain the indices of the tokens in the BERT Vocabulary\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        input_ids = torch.tensor(input_ids)\n",
        "        #Obtain the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
        "        attention_mask = (input_ids != 0).long()\n",
        "\n",
        "        target = torch.tensor([target], dtype=torch.float32)\n",
        "\n",
        "        return input_ids, attention_mask, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SmOlriORubv4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "'''\n",
        "class BertRegresser(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        #The output layer that takes the [CLS] representation and gives an output\n",
        "        self.cls_layer1 = nn.Linear(config.hidden_size,128)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.ff1 = nn.Linear(128,128)\n",
        "        self.tanh1 = nn.Tanh()\n",
        "        self.ff2 = nn.Linear(128,1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        #Feed the input to Bert model to obtain contextualized representations\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        #Obtain the representations of [CLS] heads\n",
        "        logits = outputs.last_hidden_state[:,0,:]\n",
        "        output = self.cls_layer1(logits)\n",
        "        output = self.relu1(output)\n",
        "        output = self.ff1(output)\n",
        "        output = self.tanh1(output)\n",
        "        output = self.ff2(output)\n",
        "        return output\n",
        "'''\n",
        "class BertRegresser(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        #The output layer that takes the [CLS] representation and gives an output\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Dropout(p['dropout']),\n",
        "            nn.Linear(768, 1))\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        #Feed the input to Bert model to obtain contextualized representations\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        #Obtain the representations of [CLS] heads\n",
        "        logits = outputs[1]\n",
        "        output = self.regressor(logits)\n",
        "\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v936RtNkYuZk"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "J7sZxb6Frmpj",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def setup_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.backends.cudnn.deteministic = True\n",
        "\n",
        "## Model Configurations\n",
        "p = {\n",
        "    'max_len': 512,\n",
        "    'batch_size': 6,\n",
        "    'lr' : 4.063769241800226e-05,\n",
        "    'epochs': 12,\n",
        "    'dropout': 0.5,\n",
        "    'num_threads' : 1,\n",
        "    #'model_name' : 'allenai/scibert_scivocab_uncased',\n",
        "    'model_name' : 'bert-base-uncased',\n",
        "    'do_train' : True,\n",
        "    'random_seed': 24\n",
        "}\n",
        "\n",
        "setup_seed(p['random_seed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dGvKcMnwJ4G",
        "outputId": "f5da679e-1fce-4beb-a034-0059514f0dbd",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertRegresser: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertRegresser from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertRegresser from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertRegresser were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['regressor.1.weight', 'regressor.1.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.pooler.dense.weight torch.Size([768, 768])\n",
            "bert.pooler.dense.bias torch.Size([768])\n",
            "regressor.1.weight torch.Size([1, 768])\n",
            "regressor.1.bias torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, criterion, dataloader, device):\n",
        "    model.eval()\n",
        "    mean_acc, mean_loss, count = 0, 0, 0\n",
        "    preds = []\n",
        "    lst_label = []\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, target in (dataloader):\n",
        "\n",
        "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
        "            output = model(input_ids, attention_mask)\n",
        "            preds += output\n",
        "            lst_label += target\n",
        "            mean_loss += criterion(output, target.type_as(output)).item()\n",
        "#             mean_err += get_rmse(output, target)\n",
        "            count += 1\n",
        "        predss = np.array([x.cpu().data.numpy().tolist() for x in preds]).squeeze()\n",
        "        lst_labels = np.array([x.cpu().data.numpy().tolist() for x in lst_label]).squeeze()\n",
        "        corr = stats.spearmanr(predss, lst_labels)\n",
        "    return corr[0] #mean_loss/count\n",
        "\n",
        "def train(model, criterion, optimizer, train_loader, val_loader, epochs, device):\n",
        "    best_acc = 0\n",
        "    for epoch in trange(epochs, desc=\"Epoch\"):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for i, (input_ids, attention_mask, target) in enumerate(iterable=train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
        "\n",
        "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(output, target.type_as(output))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        print(f\"Training loss is {train_loss/len(train_loader)}\")\n",
        "        val_loss = evaluate(model=model, criterion=criterion, dataloader=val_loader, device=device)\n",
        "        print(\"Epoch {} complete! Correlations : {}\".format(epoch, val_loss))\n",
        "\n",
        "\n",
        "## Configuration loaded from AutoConfig\n",
        "aconfig = AutoConfig.from_pretrained(p['model_name'])\n",
        "## Tokenizer loaded from AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(p['model_name'])\n",
        "## Creating the model from the desired transformer model\n",
        "model = BertRegresser.from_pretrained(p['model_name'], config=aconfig)\n",
        "\n",
        "\n",
        "#frezze all layers except regression head\n",
        "'''\n",
        "unfreeze_layers  = ['bert.pooler', 'cls_layer1.', 'ff1.', 'ff2']\n",
        "\n",
        "for name, params in model.named_parameters():\n",
        "  params.requires_grad = False\n",
        "  for ele in unfreeze_layers:\n",
        "    if ele in name:\n",
        "      params.requires_grad = True\n",
        "      break\n",
        "\n",
        "for name, params in model.named_parameters():\n",
        "  if params.requires_grad:\n",
        "    print(name, params.size())\n",
        "'''\n",
        "\n",
        "unfreeze_layers = ['bert.pooler', 'regressor.1']\n",
        "for name, params in model.named_parameters():\n",
        "  params.requires_grad = False\n",
        "  for ele in unfreeze_layers:\n",
        "    if ele in name:\n",
        "      params.requires_grad = True\n",
        "      break\n",
        "\n",
        "for name, params in model.named_parameters():\n",
        "  if params.requires_grad:\n",
        "    print(name, params.size())\n",
        "\n",
        "## GPU or CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "## Putting model to device\n",
        "model = model.to(device)\n",
        "## Takes as the input the logits of the positive class and computes the binary cross-entropy\n",
        "# criterion = nn.BCEWithLogitsLoss()\n",
        "criterion = nn.MSELoss()\n",
        "## Optimizer\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=p['lr'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_OUT_DIR = f'{PROJECT_ROOT}/output/sciBert_Kaggle'\n",
        "\n",
        "#for s in p.values():\n",
        "#  MODEL_OUT_DIR += '_' + str(s).replace('/', '_', 1)\n",
        "\n",
        "#print(MODEL_OUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3PdNb9OpDUq",
        "outputId": "bc94d1c5-1276-4cdd-ad37-ced32f497ddc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DL4NLP/abstract-to-title-generation/output/sciBert_Kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "cellView": "form",
        "id": "9lrD5eHbFIKk",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "DATA_DIR = f'{PROJECT_ROOT}/data/annotated'\n",
        "text_map = pd.read_csv(f'{DATA_DIR}/140_annotations_pairs.csv', index_col=0)\n",
        "scores = pd.read_csv(f'{DATA_DIR}/140_humanannotation_withoutunannotated.csv', index_col=0)\n",
        "\n",
        "abstract_df =text_map[['abstract']]\n",
        "title_df = text_map[['title', 'bart_base', 'bart_cnn', 'bart_xsum', 't5_small', 'gpt2', 'pegasus_xsum']]\n",
        "abstract_np = abstract_df.to_numpy()\n",
        "scores_np = scores.to_numpy()\n",
        "title_np = title_df.to_numpy()\n",
        "idx_map = [map2index(row) for row in map_model[:140]]\n",
        "title_np_picked = np.array([np.take(row1, np.sort(row2)) for row1, row2 in zip(title_np, idx_map)])\n",
        "score_np_picked = np.array([np.take(row1, np.sort(row2)) for row1, row2 in zip(scores_np, idx_map)])\n",
        "\n",
        "pairs_np_picked = np.concatenate([abstract_np, title_np_picked,score_np_picked], axis=1)\n",
        "pairs_np_picked_shuffled = np.random.permutation(pairs_np_picked)\n",
        "\n",
        "abstracs = pairs_np_picked_shuffled[:,:1]\n",
        "titles = pairs_np_picked_shuffled[:,1:7]\n",
        "scores = pairs_np_picked_shuffled[:,7:].astype(float)\n",
        "scores = np.around(scores, 4)\n",
        "\n",
        "lst = []\n",
        "\n",
        "for ab, row1, row2 in zip(abstracs, titles, scores):\n",
        "  assert len(row1) == len(row2)\n",
        "  assert len(row1) == 6\n",
        "  for t, s in zip(row1, row2):\n",
        "\n",
        "    if np.isnan(s):\n",
        "      print('found nan score')\n",
        "    if t=='':\n",
        "      print('found empty title')\n",
        "    lst.append([ab[0] + '[SEP]' + t, s])\n",
        "df = pd.DataFrame(np.array(lst))\n",
        "\n",
        "df.columns = ['excerpt', 'target']\n",
        "#dataframe = dataframe.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "dftrain = df[:600].reset_index(drop=True)\n",
        "dfdev = df[600:660].reset_index(drop=True)\n",
        "dftest = df[660:].reset_index(drop=True)\n",
        "\n",
        "OUT_DIR = f'{MODEL_OUT_DIR}/robust_test'\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "dftrain.to_csv(f'{OUT_DIR}/sciBert_shuffled_train.csv')\n",
        "dfdev.to_csv(f'{OUT_DIR}/sciBert_shuffled_dev.csv')\n",
        "dftest.to_csv(f'{OUT_DIR}/sciBert_shuffled_test.csv')\n",
        "\n",
        "dftrain = pd.read_csv(f'{OUT_DIR}/sciBert_shuffled_train.csv', index_col=0)\n",
        "dfdev = pd.read_csv(f'{OUT_DIR}/sciBert_shuffled_dev.csv', index_col=0)\n",
        "dftest = pd.read_csv(f'{OUT_DIR}/sciBert_shuffled_test.csv', index_col=0)\n",
        "\n",
        "\n",
        "## Training Dataset\n",
        "train_set = Excerpt_Dataset(data=dftrain, maxlen=p['max_len'], tokenizer=tokenizer)\n",
        "dev_set = Excerpt_Dataset(data=dfdev, maxlen=p['max_len'], tokenizer=tokenizer)\n",
        "test_set = Excerpt_Dataset(data=dftest, maxlen=p['max_len'], tokenizer=tokenizer)\n",
        "\n",
        "## Data Loaders\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=p['batch_size'], num_workers=p['num_threads'], shuffle=True)\n",
        "dev_loader = DataLoader(dataset=dev_set, batch_size=p['batch_size'], num_workers=p['num_threads'], shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=p['batch_size'], num_workers=p['num_threads'], shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "qMee8sQz2NV5",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "a7d3e9d1-2485-44c4-f344-39f45ae55397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:   0%|          | 0/12 [00:10<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-79584f16ec1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   )\n",
            "\u001b[0;32m<ipython-input-41-51ad1fdb7c31>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, val_loader, epochs, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training loss is {train_loss/len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if p['do_train']:\n",
        "  train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=dev_loader,\n",
        "    epochs = p['epochs'],\n",
        "    device = device\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wg9AtLg-axHn",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "#torch.save(model.state_dict(), MODEL_OUT_DIR + '.model')\n",
        "\n",
        "#load model\n",
        "model_state, optimizer_state = torch.load(os.path.join('../output/sciBert_Kaggle/ray_results/runner_2022-04-29_16-44-10/runner_980f0_00002_2_lr=4.0638e-05_2022-04-29_17-04-24/checkpoint_000017', \"checkpoint\"))\n",
        "model.load_state_dict(model_state)\n",
        "\n",
        "#model.load_state_dict(torch.load(\"../output/sciBert_Kaggle/sciBert.model\"))\n",
        "#model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iATEEkP7Narl",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@title prediction function\n",
        "def predict(model, dataloader, device):\n",
        "    predicted_label = []\n",
        "    actual_label = []\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, target in (dataloader):\n",
        "            \n",
        "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
        "            output = model(input_ids, attention_mask)\n",
        "                        \n",
        "            predicted_label += output\n",
        "            actual_label += target\n",
        "            \n",
        "    return predicted_label, actual_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_iKX2VOG7ti",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "---\n",
        "\n",
        "# **Display Correlation**\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN5JZ9ElGABX",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "output,GS_label = predict(model, train_loader, device)\n",
        "cpu_output = np.array([x.cpu().data.numpy() for x in output]).squeeze()\n",
        "cpu_target = np.array([x.cpu().data.numpy() for x in GS_label]).squeeze()\n",
        "stats.spearmanr(cpu_output, cpu_target)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEV-es5KpREu",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dev_output,dev_GS_label = predict(model, dev_loader, device)\n",
        "cpu_dev_output = np.array([x.cpu().data.numpy() for x in dev_output]).squeeze()\n",
        "cpu_dev_target = np.array([x.cpu().data.numpy() for x in dev_GS_label]).squeeze()\n",
        "stats.spearmanr(cpu_dev_output, cpu_dev_target)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcFR76sa53F7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "test_output,test_GS_label = predict(model, test_loader, device)\n",
        "cpu_test_output = np.array([x.cpu().data.numpy() for x in test_output]).squeeze()\n",
        "cpu_test_target = np.array([x.cpu().data.numpy() for x in test_GS_label]).squeeze()\n",
        "stats.spearmanr(cpu_test_output, cpu_test_target)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfX7ty-34BEo",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dev_output,dev_GS_label = predict(model, dev_loader, device)\n",
        "cpu_dev_output = np.array([x.cpu().data.numpy() for x in dev_output]).squeeze()\n",
        "cpu_dev_target = np.array([x.cpu().data.numpy() for x in dev_GS_label]).squeeze()\n",
        "stats.spearmanr(cpu_dev_output, cpu_dev_target)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l70-oVBm8oP7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "test_output,test_GS_label = predict(model, test_loader, device)\n",
        "cpu_test_output = np.array([x.cpu().data.numpy() for x in test_output]).squeeze()\n",
        "cpu_test_target = np.array([x.cpu().data.numpy() for x in test_GS_label]).squeeze()\n",
        "stats.spearmanr(cpu_test_output, cpu_test_target)[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Kopie von sciBert_Kaggle_regresse.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}