{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Kopie von GPT2_huggingface_trainer.ipynb","provenance":[{"file_id":"1nFbchY04AY8MQqFHzDk6ywed6CLUy6ge","timestamp":1643736200041},{"file_id":"1HJjGJSGzgcgrE_dD9nCE0uOwl5EWlL_6","timestamp":1643706796285},{"file_id":"1DlV2tsDOx5o4ZQRKCAWsxHcUYcURFRHm","timestamp":1643234729469}],"machine_shape":"hm","collapsed_sections":[],"mount_file_id":"10iqJnPBp3B4NU5a_cU5r_K4KEcST4dj2","authorship_tag":"ABX9TyNfO/5/xgHUrxPPl/SZkPQ0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a55e227dcb4a4ac1b97317a4d1e57733":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6d13f004509b40199e3bdec00dd9864f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_86cc52e25f7849d9adca7f22949658af","IPY_MODEL_390b828279f043e2a161dd405c627157","IPY_MODEL_167325d635e947e2bbcc729005cd40b4"]}},"6d13f004509b40199e3bdec00dd9864f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86cc52e25f7849d9adca7f22949658af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fae53267f5b74cdfbb92ee09eadff0dd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c622b967e464419b9a5c6d828a721a41"}},"390b828279f043e2a161dd405c627157":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_724e347b1961463fbd880155b7190c65","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2170,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2170,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9794883e9d347bbada6a2aeb0989606"}},"167325d635e947e2bbcc729005cd40b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b7dc4e04219e4b0b9e8232a2a0ae5a1a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.61k/? [00:00&lt;00:00, 224kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c30675c1839241a4871f4d4cc04a1cd3"}},"fae53267f5b74cdfbb92ee09eadff0dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c622b967e464419b9a5c6d828a721a41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"724e347b1961463fbd880155b7190c65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a9794883e9d347bbada6a2aeb0989606":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b7dc4e04219e4b0b9e8232a2a0ae5a1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c30675c1839241a4871f4d4cc04a1cd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef908fcf41464847a55c9f88ad44cac5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_19edf6adf1d741eaace38b56b14e57bc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d51684deb59b4502a4810c31ec1cc0ed","IPY_MODEL_ece67577acfa4921a22d812d5ada1623","IPY_MODEL_0619e57f5e4b4495aeb6318bfaba8306"]}},"19edf6adf1d741eaace38b56b14e57bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d51684deb59b4502a4810c31ec1cc0ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_44bb06c334bb4c5697a4c93ee195c58f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd8d5e163fb643029b5d796511593826"}},"ece67577acfa4921a22d812d5ada1623":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_27305b1d036744928a382e6c5c7f9ff4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":12,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":12,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04915733901a469899cd78f2e3ec863f"}},"0619e57f5e4b4495aeb6318bfaba8306":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fbb8197a0c20450da73a3a4ecf1d2704","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 12/12 [00:14&lt;00:00,  1.11s/ba]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c262c533a3df4810b3ba58c7d539f7d5"}},"44bb06c334bb4c5697a4c93ee195c58f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dd8d5e163fb643029b5d796511593826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27305b1d036744928a382e6c5c7f9ff4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"04915733901a469899cd78f2e3ec863f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fbb8197a0c20450da73a3a4ecf1d2704":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c262c533a3df4810b3ba58c7d539f7d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b6307a220c7441ba9bf89c42804cc151":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_25d44e332fcb4316922899138bfae223","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b7785f8d411d4213a4d4be7b9bb51412","IPY_MODEL_7da7da2ae89c432dbde36c4ea57544c7","IPY_MODEL_5ade8f4f7a5e4ef6ae752620c43ac93e"]}},"25d44e332fcb4316922899138bfae223":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b7785f8d411d4213a4d4be7b9bb51412":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_37d4d459d7a84a429d68aee69fe2012b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a45982aec004b3cb9af7faf6d8d6bf8"}},"7da7da2ae89c432dbde36c4ea57544c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bdf76c158ec54a5680a637dd9e2847cb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1fae384d75741609727de190adc7693"}},"5ade8f4f7a5e4ef6ae752620c43ac93e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6a7df07f0ee04d7c9a9479fd9d85b1de","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  6.60ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be71cd04cf984923b24f257827790ceb"}},"37d4d459d7a84a429d68aee69fe2012b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3a45982aec004b3cb9af7faf6d8d6bf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdf76c158ec54a5680a637dd9e2847cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d1fae384d75741609727de190adc7693":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a7df07f0ee04d7c9a9479fd9d85b1de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"be71cd04cf984923b24f257827790ceb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","source":["cd /content/drive/MyDrive/Thesis"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eiba090yII9p","executionInfo":{"status":"ok","timestamp":1644179780716,"user_tz":-60,"elapsed":6,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"e78e129c-10ea-4fff-f4a2-65fca7ea9817"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Thesis\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kcgpu-Mj2Az0","executionInfo":{"status":"ok","timestamp":1644179803767,"user_tz":-60,"elapsed":23054,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"b4c01a82-8638-4864-a5ae-617a2a334341"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tqdm==4.28.1\n","  Downloading tqdm-4.28.1-py2.py3-none-any.whl (45 kB)\n","\u001b[?25l\r\u001b[K     |███████▏                        | 10 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 20 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 40 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 45 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (2.7.0)\n","Collecting datasets\n","  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 31.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 112 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 133 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 163 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 225 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 245 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 256 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 266 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 276 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 296 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 311 kB 9.3 MB/s \n","\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.10.0+cu111)\n","Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 63.9 MB/s \n","\u001b[?25hCollecting rouge-score\n","  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (3.2.5)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.1.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.13.3)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (2.7.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.1.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.1.2)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.3.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.23.1)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.37.1)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.43.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.10.0.2)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (2.7.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.17.3)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (2.7.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (13.0.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.6.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r requirements.txt (line 2)) (1.5.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (57.4.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (0.6.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (2.23.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (4.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->-r requirements.txt (line 2)) (3.2.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 3)) (1.3.5)\n","Collecting datasets\n","  Downloading datasets-1.18.2-py3-none-any.whl (312 kB)\n","\u001b[K     |████████████████████████████████| 312 kB 51.8 MB/s \n","\u001b[?25h  Downloading datasets-1.18.1-py3-none-any.whl (311 kB)\n","\u001b[K     |████████████████████████████████| 311 kB 57.7 MB/s \n","\u001b[?25h  Downloading datasets-1.18.0-py3-none-any.whl (311 kB)\n","\u001b[K     |████████████████████████████████| 311 kB 56.4 MB/s \n","\u001b[?25h  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n","\u001b[K     |████████████████████████████████| 306 kB 50.9 MB/s \n","\u001b[?25h  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n","\u001b[K     |████████████████████████████████| 298 kB 53.4 MB/s \n","\u001b[?25h  Downloading datasets-1.16.0-py3-none-any.whl (298 kB)\n","\u001b[K     |████████████████████████████████| 298 kB 53.8 MB/s \n","\u001b[?25h  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n","\u001b[K     |████████████████████████████████| 290 kB 66.6 MB/s \n","\u001b[?25h  Downloading datasets-1.15.0-py3-none-any.whl (290 kB)\n","\u001b[K     |████████████████████████████████| 290 kB 62.5 MB/s \n","\u001b[?25h  Downloading datasets-1.14.0-py3-none-any.whl (290 kB)\n","\u001b[K     |████████████████████████████████| 290 kB 63.2 MB/s \n","\u001b[?25h  Downloading datasets-1.13.3-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 58.8 MB/s \n","\u001b[?25h  Downloading datasets-1.13.2-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 57.9 MB/s \n","\u001b[?25h  Downloading datasets-1.13.1-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 60.7 MB/s \n","\u001b[?25h  Downloading datasets-1.13.0-py3-none-any.whl (285 kB)\n","\u001b[K     |████████████████████████████████| 285 kB 63.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 3)) (21.3)\n","  Downloading datasets-1.12.1-py3-none-any.whl (270 kB)\n","\u001b[K     |████████████████████████████████| 270 kB 50.3 MB/s \n","\u001b[?25h  Downloading datasets-1.12.0-py3-none-any.whl (269 kB)\n","\u001b[K     |████████████████████████████████| 269 kB 34.9 MB/s \n","\u001b[?25h  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n","\u001b[K     |████████████████████████████████| 264 kB 41.8 MB/s \n","\u001b[?25hCollecting fsspec>=2021.05.0\n","  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 40.4 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 3)) (0.70.12.2)\n","Collecting datasets\n","  Downloading datasets-1.10.2-py3-none-any.whl (542 kB)\n","\u001b[K     |████████████████████████████████| 542 kB 38.1 MB/s \n","\u001b[?25h  Downloading datasets-1.10.1-py3-none-any.whl (542 kB)\n","\u001b[K     |████████████████████████████████| 542 kB 1.2 MB/s \n","\u001b[?25h  Downloading datasets-1.10.0-py3-none-any.whl (542 kB)\n","\u001b[K     |████████████████████████████████| 542 kB 36.6 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 3)) (0.3.4)\n","Collecting huggingface-hub<0.1.0\n","  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 3)) (6.0.1)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 62.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets->-r requirements.txt (line 3)) (3.4.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets->-r requirements.txt (line 3)) (3.13)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets->-r requirements.txt (line 3)) (3.0.7)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirements.txt (line 4)) (1.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 6)) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 46.9 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[K     |████████████████████████████████| 6.8 MB 37.7 MB/s \n","\u001b[?25hCollecting pyyaml\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 56.3 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.16.1-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 33.2 MB/s \n","\u001b[?25h  Downloading transformers-4.16.0-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 60.2 MB/s \n","\u001b[?25h  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 48.3 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 35.4 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 27.0 MB/s \n","\u001b[?25h  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 38.0 MB/s \n","\u001b[?25h  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 49.4 MB/s \n","\u001b[?25h  Downloading transformers-4.12.4-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 46.8 MB/s \n","\u001b[?25h  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 45.6 MB/s \n","\u001b[?25h  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 32.7 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2018.9)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r requirements.txt (line 6)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (3.1.0)\n","Installing collected packages: tqdm, pyyaml, xxhash, tokenizers, sacremoses, huggingface-hub, fsspec, transformers, rouge-score, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.62.3\n","    Uninstalling tqdm-4.62.3:\n","      Successfully uninstalled tqdm-4.62.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.28.1 which is incompatible.\n","panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.28.1 which is incompatible.\n","fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.28.1 which is incompatible.\u001b[0m\n","Successfully installed datasets-1.10.0 fsspec-2022.1.0 huggingface-hub-0.0.19 pyyaml-6.0 rouge-score-0.0.4 sacremoses-0.0.47 tokenizers-0.10.3 tqdm-4.28.1 transformers-4.12.2 xxhash-2.0.2\n"]}]},{"cell_type":"code","source":["model_checkpoint = \"gpt2\"\n"],"metadata":{"id":"hGFqccODaeIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tqdm -U\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-BzEqSq5aW-","executionInfo":{"status":"ok","timestamp":1644179808280,"user_tz":-60,"elapsed":4517,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"c90c139a-1458-4862-95ab-daef560f5f54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.28.1)\n","Collecting tqdm\n","  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 2.7 MB/s \n","\u001b[?25hInstalling collected packages: tqdm\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.28.1\n","    Uninstalling tqdm-4.28.1:\n","      Successfully uninstalled tqdm-4.28.1\n","Successfully installed tqdm-4.62.3\n"]}]},{"cell_type":"code","source":["from datasets import load_metric\n"],"metadata":{"id":"pglc_wgIaky2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import GPT2LMHeadModel, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n","\n","model = GPT2LMHeadModel.from_pretrained(model_checkpoint)"],"metadata":{"id":"IdRhq9sHa3xA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import GPT2Tokenizer\n","    \n","def load_tokenizer():\n","    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","    special_tokens = {'bos_token':'<|startoftext|>','eos_token':'<|endoftext|>','pad_token':'<pad>','additional_special_tokens':['<TITLE>']} \n","    tokenizer.add_special_tokens(special_tokens)\n","    return tokenizer\n","\n","tokenizer = load_tokenizer()\n","model.resize_token_embeddings(len(tokenizer))"],"metadata":{"id":"VisOC8KZaxI3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644179851685,"user_tz":-60,"elapsed":939,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"53bf0ae6-22d5-4f74-e8a9-d1949cb6b3de"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(50260, 768)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"/content/drive/MyDrive/Thesis/data/1024_length_data/train_pairs.csv\", index_col=0)\n","df"],"metadata":{"id":"c3FO11232ShQ","executionInfo":{"status":"ok","timestamp":1643825471118,"user_tz":-60,"elapsed":1931,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"37e657ab-9426-4dd7-f9bd-9bca6cde477f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-8413fd8f-dfbf-4314-9c3e-b0135659832c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>title_length</th>\n","      <th>abstract_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Natural Image Bases to Represent Neuroimaging ...</td>\n","      <td>Visual inspection of neuroimagery is susceptib...</td>\n","      <td>7</td>\n","      <td>132</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sluice Resolution without Hand-Crafted Feature...</td>\n","      <td>Sluice resolution in English is the problem of...</td>\n","      <td>9</td>\n","      <td>110</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Learning Translation Models from Monolingual C...</td>\n","      <td>Translation models often fail to generate good...</td>\n","      <td>7</td>\n","      <td>152</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentiment Adaptive End-to-End Dialog Systems</td>\n","      <td>End-to-end learning framework is useful for bu...</td>\n","      <td>5</td>\n","      <td>119</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>User-Friendly Text Prediction For Translators</td>\n","      <td>Text prediction is a form of interactive machi...</td>\n","      <td>5</td>\n","      <td>134</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21437</th>\n","      <td>Arabic Tokenization, Part-of-Speech Tagging an...</td>\n","      <td>We present an approach to using a morphologica...</td>\n","      <td>11</td>\n","      <td>58</td>\n","    </tr>\n","    <tr>\n","      <th>21438</th>\n","      <td>Using Semantically Motivated Estimates to Help...</td>\n","      <td>Research into the automatic acquisition of sub...</td>\n","      <td>8</td>\n","      <td>530</td>\n","    </tr>\n","    <tr>\n","      <th>21439</th>\n","      <td>A Mathematical Exploration of Why Language Mod...</td>\n","      <td>Autoregressive language models, pretrained usi...</td>\n","      <td>11</td>\n","      <td>194</td>\n","    </tr>\n","    <tr>\n","      <th>21440</th>\n","      <td>Do You Know That Florence Is Packed with Visit...</td>\n","      <td>When a speaker, Mary, asks \"Do you know that F...</td>\n","      <td>15</td>\n","      <td>174</td>\n","    </tr>\n","    <tr>\n","      <th>21441</th>\n","      <td>LDA Topic Model with Soft Assignment of Descri...</td>\n","      <td>The LDA topic model is being used to model cor...</td>\n","      <td>10</td>\n","      <td>198</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21442 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8413fd8f-dfbf-4314-9c3e-b0135659832c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8413fd8f-dfbf-4314-9c3e-b0135659832c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8413fd8f-dfbf-4314-9c3e-b0135659832c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                   title  ... abstract_length\n","0      Natural Image Bases to Represent Neuroimaging ...  ...             132\n","1      Sluice Resolution without Hand-Crafted Feature...  ...             110\n","2      Learning Translation Models from Monolingual C...  ...             152\n","3           Sentiment Adaptive End-to-End Dialog Systems  ...             119\n","4          User-Friendly Text Prediction For Translators  ...             134\n","...                                                  ...  ...             ...\n","21437  Arabic Tokenization, Part-of-Speech Tagging an...  ...              58\n","21438  Using Semantically Motivated Estimates to Help...  ...             530\n","21439  A Mathematical Exploration of Why Language Mod...  ...             194\n","21440  Do You Know That Florence Is Packed with Visit...  ...             174\n","21441  LDA Topic Model with Soft Assignment of Descri...  ...             198\n","\n","[21442 rows x 4 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df.reset_index(drop=True, inplace=True)"],"metadata":{"id":"Lm97OV9JNgx4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_csv(\"/content/drive/MyDrive/Thesis/data/1024_length_data/1024_characters_pairs.csv\")"],"metadata":{"id":"322voA16C-v5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.drop(columns=[\"title_length\", \"abstract_length\", \"token_len\"])"],"metadata":{"id":"r5eGRlj3Po9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = df[:11864]\n","df_valid = df[11864:11964]"],"metadata":{"id":"mp4cQi3LQsPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_input(df):\n","  inputs = []\n","  for a,t in zip(df.abstract.to_list(), df.title.to_list()):\n","    input = a + \"<TITLE>\" + t + \"<|endoftext|>\"\n","    inputs.append(input)\n","  df[\"input\"] = inputs\n","  return df"],"metadata":{"id":"mgDJE1oHguQr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = add_input(df_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvnZ09LCi3wd","executionInfo":{"status":"ok","timestamp":1643825472427,"user_tz":-60,"elapsed":14,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"21a7cfe3-0587-4a58-9e88-17b17c76fd7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}]},{"cell_type":"code","source":["df_valid = add_input(df_valid)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yED-v28XkRzD","executionInfo":{"status":"ok","timestamp":1643825472428,"user_tz":-60,"elapsed":10,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"30e8ae54-9f9f-40a4-8cbc-e2aaf9003386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}]},{"cell_type":"code","source":["df_train = df_train.drop(columns=[\"title\", \"abstract\"])\n","df_valid = df_valid.drop(columns=[\"title\", \"abstract\"])"],"metadata":{"id":"b7pseHvIlrOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset\n","from datasets import load_dataset, load_metric\n","train_dataset = Dataset.from_pandas(df_train)\n","valid_dataset = Dataset.from_pandas(df_valid)\n","metric = load_metric(\"rouge\")\n"],"metadata":{"id":"eLws3YI2NyQ5","executionInfo":{"status":"ok","timestamp":1643825474661,"user_tz":-60,"elapsed":2240,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["a55e227dcb4a4ac1b97317a4d1e57733","6d13f004509b40199e3bdec00dd9864f","86cc52e25f7849d9adca7f22949658af","390b828279f043e2a161dd405c627157","167325d635e947e2bbcc729005cd40b4","fae53267f5b74cdfbb92ee09eadff0dd","c622b967e464419b9a5c6d828a721a41","724e347b1961463fbd880155b7190c65","a9794883e9d347bbada6a2aeb0989606","b7dc4e04219e4b0b9e8232a2a0ae5a1a","c30675c1839241a4871f4d4cc04a1cd3"]},"outputId":"d70897e8-a6f2-485b-ba62-3268232dfa83"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a55e227dcb4a4ac1b97317a4d1e57733","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","source":["max_input_length = 620\n","def preprocess_function(examples):\n","    model_inputs = tokenizer(examples[\"input\"], padding=\"max_length\", max_length=max_input_length, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    labels = model_inputs\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n"],"metadata":{"id":"KRyNcZ_hThOm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = train_dataset.map(preprocess_function, batched=True)\n","valid_dataset = valid_dataset.map(preprocess_function, batched=True)\n"],"metadata":{"id":"WsGePsUcSrkO","executionInfo":{"status":"ok","timestamp":1643825491723,"user_tz":-60,"elapsed":17066,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["ef908fcf41464847a55c9f88ad44cac5","19edf6adf1d741eaace38b56b14e57bc","d51684deb59b4502a4810c31ec1cc0ed","ece67577acfa4921a22d812d5ada1623","0619e57f5e4b4495aeb6318bfaba8306","44bb06c334bb4c5697a4c93ee195c58f","dd8d5e163fb643029b5d796511593826","27305b1d036744928a382e6c5c7f9ff4","04915733901a469899cd78f2e3ec863f","fbb8197a0c20450da73a3a4ecf1d2704","c262c533a3df4810b3ba58c7d539f7d5","b6307a220c7441ba9bf89c42804cc151","25d44e332fcb4316922899138bfae223","b7785f8d411d4213a4d4be7b9bb51412","7da7da2ae89c432dbde36c4ea57544c7","5ade8f4f7a5e4ef6ae752620c43ac93e","37d4d459d7a84a429d68aee69fe2012b","3a45982aec004b3cb9af7faf6d8d6bf8","bdf76c158ec54a5680a637dd9e2847cb","d1fae384d75741609727de190adc7693","6a7df07f0ee04d7c9a9479fd9d85b1de","be71cd04cf984923b24f257827790ceb"]},"outputId":"62afbb13-2ca3-49db-f470-391eeb8a71fe"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef908fcf41464847a55c9f88ad44cac5","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/12 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6307a220c7441ba9bf89c42804cc151","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{}}]},{"cell_type":"code","source":["from operator import indexOf\n","def get_max_len(train_dataset, valid_dataset, max_global_input_len):\n","  for i in train_dataset:\n","    t = indexOf(i[\"input_ids\"], tokenizer.eos_token_id) + 1\n","    if t > max_global_input_len:\n","      max_global_input_len = t\n","\n","  for i in valid_dataset:\n","    t = indexOf(i[\"input_ids\"], tokenizer.eos_token_id) + 1\n","    if t > max_global_input_len:\n","      max_global_input_len = t\n","  return max_global_input_len\n","\n","max_global_input_len = get_max_len(train_dataset, valid_dataset, 0)"],"metadata":{"id":"wEXjOtx89-bd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 2\n","model_name = model_checkpoint.split(\"/\")[-1]\n","args = TrainingArguments(\n","    \"output/gpt2/\" + f\"{model_name}-finetuned-lm_al_paper\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=3e-4,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=1,\n","    weight_decay=0.01,\n","    save_total_limit=2,\n","    num_train_epochs=3,\n","    fp16=True,\n","    push_to_hub=False,\n","    gradient_accumulation_steps=8,\n","    save_steps = 200,\n","    logging_steps = 185,\n",")"],"metadata":{"id":"btKZ3RhjZ4Vx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n"],"metadata":{"id":"j6RYke5GbaYN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","\n","```\n","Examples:\n","    >>> predictions = [\"hello there\", \"general kenobi\"]\n","    >>> references = [\"hello there\", \"general kenobi\"]\n","    >>> bertscore = datasets.load_metric(\"bertscore\")\n","    >>> results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n","    >>> print([round(v, 2) for v in results[\"f1\"]])\n","    [1.0, 1.0]\n","  \n","```\n","\n"],"metadata":{"id":"dduVZjJZcLUa"}},{"cell_type":"code","source":["import nltk\n","import numpy as np\n","nltk.download('punkt')\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    # Rouge expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","    \n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    # Extract a few results\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","    \n","    # Add mean generated length\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    \n","    return {k: round(v, 4) for k, v in result.items()}"],"metadata":{"id":"cCYda7Z3bgUC","executionInfo":{"status":"ok","timestamp":1643825500869,"user_tz":-60,"elapsed":885,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"94740278-eacb-4e4a-a740-e9a4e22ed413"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n",")"],"metadata":{"id":"l7PrIlIVfXtX","executionInfo":{"status":"ok","timestamp":1643825505730,"user_tz":-60,"elapsed":4864,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"61ad3854-801a-40eb-f4be-939777b34586"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using amp fp16 backend\n"]}]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"h5drfK06qeI4","executionInfo":{"status":"ok","timestamp":1643829853510,"user_tz":-60,"elapsed":4347800,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"ebbb3b96-5616-4a77-846b-f130cff54e64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: input.\n","***** Running training *****\n","  Num examples = 11864\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 2223\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2223' max='2223' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2223/2223 1:12:24, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>3.169100</td>\n","      <td>3.008055</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>2.846800</td>\n","      <td>2.927294</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.624400</td>\n","      <td>2.920357</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-200\n","Configuration saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-200/config.json\n","Model weights saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-200/pytorch_model.bin\n","tokenizer config file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-200/special_tokens_map.json\n","added tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-200/added_tokens.json\n","Saving model checkpoint to output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-400\n","Configuration saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-400/config.json\n","Model weights saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-400/pytorch_model.bin\n","tokenizer config file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-400/tokenizer_config.json\n","Special tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-400/special_tokens_map.json\n","added tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-400/added_tokens.json\n","Saving model checkpoint to output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-600\n","Configuration saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-600/config.json\n","Model weights saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-600/pytorch_model.bin\n","tokenizer config file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-600/special_tokens_map.json\n","added tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-600/added_tokens.json\n","Deleting older checkpoint [output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-200] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: input.\n","***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 1\n","Saving model checkpoint to output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-800\n","Configuration saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-800/config.json\n","Model weights saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-800/pytorch_model.bin\n","tokenizer config file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-800/tokenizer_config.json\n","Special tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-800/special_tokens_map.json\n","added tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-800/added_tokens.json\n","Deleting older checkpoint [output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-400] due to args.save_total_limit\n","Saving model checkpoint to output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1000\n","Configuration saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1000/config.json\n","Model weights saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1000/special_tokens_map.json\n","added tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1000/added_tokens.json\n","Deleting older checkpoint [output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-600] due to args.save_total_limit\n","Saving model checkpoint to output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1200\n","Configuration saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1200/config.json\n","Model weights saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1200/pytorch_model.bin\n","tokenizer config file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1200/tokenizer_config.json\n","Special tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1200/special_tokens_map.json\n","added tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1200/added_tokens.json\n","Deleting older checkpoint [output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-800] due to args.save_total_limit\n","Saving model checkpoint to output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1400\n","Configuration saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1400/config.json\n","Model weights saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1400/pytorch_model.bin\n","tokenizer config file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1400/tokenizer_config.json\n","Special tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1400/special_tokens_map.json\n","added tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1400/added_tokens.json\n","Deleting older checkpoint [output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1000] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: input.\n","***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 1\n","Saving model checkpoint to output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1600\n","Configuration saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1600/config.json\n","Model weights saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1600/pytorch_model.bin\n","tokenizer config file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1600/tokenizer_config.json\n","Special tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1600/special_tokens_map.json\n","added tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1600/added_tokens.json\n","Deleting older checkpoint [output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1200] due to args.save_total_limit\n","Saving model checkpoint to output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1800\n","Configuration saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1800/config.json\n","Model weights saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1800/pytorch_model.bin\n","tokenizer config file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1800/tokenizer_config.json\n","Special tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1800/special_tokens_map.json\n","added tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1800/added_tokens.json\n","Deleting older checkpoint [output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1400] due to args.save_total_limit\n","Saving model checkpoint to output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2000\n","Configuration saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2000/config.json\n","Model weights saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2000/special_tokens_map.json\n","added tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2000/added_tokens.json\n","Deleting older checkpoint [output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1600] due to args.save_total_limit\n","Saving model checkpoint to output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2200\n","Configuration saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2200/config.json\n","Model weights saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2200/pytorch_model.bin\n","tokenizer config file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2200/tokenizer_config.json\n","Special tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2200/special_tokens_map.json\n","added tokens file saved in output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-2200/added_tokens.json\n","Deleting older checkpoint [output/gpt2/gpt2-finetuned-lm_al_paper/checkpoint-1800] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: input.\n","***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 1\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2223, training_loss=3.166638523192755, metrics={'train_runtime': 4347.4786, 'train_samples_per_second': 8.187, 'train_steps_per_second': 0.511, 'total_flos': 1.125907365888e+16, 'train_loss': 3.166638523192755, 'epoch': 3.0})"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["model.save_pretrained(\"./output/gpt2\")\n"],"metadata":{"id":"eXx-uoz8fuhf","executionInfo":{"status":"ok","timestamp":1643829861520,"user_tz":-60,"elapsed":8019,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"14963135-457d-45a4-d0d6-a897e6c19074"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Configuration saved in ./output/gpt2/config.json\n","Model weights saved in ./output/gpt2/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","test_samples = pd.read_csv(\"/content/drive/MyDrive/Thesis/data/1024_length_data/test_pairs.csv\", index_col=0)\n","test_samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"pcuMuXfxD-_E","executionInfo":{"status":"ok","timestamp":1644179869524,"user_tz":-60,"elapsed":904,"user":{"displayName":"yichen xie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05370341903943803742"}},"outputId":"4a20c8d4-1171-43c3-bb1b-1d2e73da0f51"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-1d51ab81-725b-4cd5-84c1-ef744fcb251a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>title_length</th>\n","      <th>abstract_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Learning Latent Semantic Annotations for Groun...</td>\n","      <td>Previous work on grounded language learning di...</td>\n","      <td>11</td>\n","      <td>121</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Partially Supervised Sense Disambiguation by L...</td>\n","      <td>Supervised and semi-supervised sense disambigu...</td>\n","      <td>13</td>\n","      <td>140</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hawkes Processes for Continuous Time Sequence ...</td>\n","      <td>Classification of temporal textual data sequen...</td>\n","      <td>15</td>\n","      <td>68</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A Unified Single Scan Algorithm for Japanese B...</td>\n","      <td>We describe an algorithm for Japanese analysis...</td>\n","      <td>13</td>\n","      <td>62</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Generating Coherent Event Schemas at Scale</td>\n","      <td>Chambers and Jurafsky (2009) demonstrated that...</td>\n","      <td>6</td>\n","      <td>127</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5356</th>\n","      <td>Bridging Information-Seeking Human Gaze and Ma...</td>\n","      <td>In this work, we analyze how human gaze during...</td>\n","      <td>8</td>\n","      <td>118</td>\n","    </tr>\n","    <tr>\n","      <th>5357</th>\n","      <td>Quantum-inspired Neural Network for Conversati...</td>\n","      <td>We provide a novel perspective on conversation...</td>\n","      <td>7</td>\n","      <td>116</td>\n","    </tr>\n","    <tr>\n","      <th>5358</th>\n","      <td>The BQ Corpus: A Large-scale Domain-specific C...</td>\n","      <td>This paper introduces the Bank Question (BQ) c...</td>\n","      <td>13</td>\n","      <td>174</td>\n","    </tr>\n","    <tr>\n","      <th>5359</th>\n","      <td>Doc2hash: Learning Discrete Latent variables f...</td>\n","      <td>Learning to hash via generative model has beco...</td>\n","      <td>8</td>\n","      <td>131</td>\n","    </tr>\n","    <tr>\n","      <th>5360</th>\n","      <td>Provable Benefits of Overparameterization in M...</td>\n","      <td>Deep networks are typically trained with many ...</td>\n","      <td>14</td>\n","      <td>228</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5361 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d51ab81-725b-4cd5-84c1-ef744fcb251a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1d51ab81-725b-4cd5-84c1-ef744fcb251a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1d51ab81-725b-4cd5-84c1-ef744fcb251a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                  title  ... abstract_length\n","0     Learning Latent Semantic Annotations for Groun...  ...             121\n","1     Partially Supervised Sense Disambiguation by L...  ...             140\n","2     Hawkes Processes for Continuous Time Sequence ...  ...              68\n","3     A Unified Single Scan Algorithm for Japanese B...  ...              62\n","4            Generating Coherent Event Schemas at Scale  ...             127\n","...                                                 ...  ...             ...\n","5356  Bridging Information-Seeking Human Gaze and Ma...  ...             118\n","5357  Quantum-inspired Neural Network for Conversati...  ...             116\n","5358  The BQ Corpus: A Large-scale Domain-specific C...  ...             174\n","5359  Doc2hash: Learning Discrete Latent variables f...  ...             131\n","5360  Provable Benefits of Overparameterization in M...  ...             228\n","\n","[5361 rows x 4 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["abstracts = test_samples.abstract.to_list()\n","titles = test_samples.title.to_list()"],"metadata":{"id":"nu4Ma5pMGK31"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def creat_eval_pairs(model, tokenizer, abstracts, titles):\n","  preds = []\n","  for abstract, title in zip(abstracts, titles):\n","    encoding = tokenizer(abstract + \"<TITLE>\", return_tensors = \"pt\", max_length=620)\n","    inputs = encoding[\"input_ids\"].to(\"cuda\")\n","    attention_masks = encoding[\"attention_mask\"].to(\"cuda\")\n","    title_ids = model.generate(\n","            input_ids = inputs,\n","            attention_mask = attention_masks,\n","            max_length = 1024,\n","            num_beams = 5,\n","            num_return_sequences = 5,\n","            repetition_penalty=2.0, \n","            length_penalty=10.0,\n","            early_stopping = True,\n","            )\n","    result = []\n","    for g in title_ids:\n","      result.append(tokenizer.decode(g).split(\"<TITLE>\")[1].split(\"<|endoftext|>\")[0])\n","    s=\"\"\n","    for t in result:\n","      s = s + \"<TITLE>\" + t\n","    preds.append(s)\n","    if len(preds) % 500 == 0:\n","      print(\"original title: \", title)\n","      print(\"generated title: \", preds[-1:])\n","  return preds, titles"],"metadata":{"id":"VMOeZlmNGOdM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.to(\"cuda\")"],"metadata":{"id":"zj9mSSMywkAt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds, titles = creat_eval_pairs(model, tokenizer, abstracts, titles)"],"metadata":{"id":"MG9tE6GcGQSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_target_pairs = pd.DataFrame(list(zip(preds, titles)), columns=['predictions', 'targets'])"],"metadata":{"id":"hXs3hibVNKVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_target_pairs.to_csv(\"gpt2.csv\")"],"metadata":{"id":"x4UAdH1pNMlt"},"execution_count":null,"outputs":[]}]}