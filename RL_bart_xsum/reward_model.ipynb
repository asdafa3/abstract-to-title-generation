{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4XjWOY_rrsW",
    "outputId": "280e6271-65ac-4629-948d-f538edff49bc"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "sys.path.append(\"/content/drive/MyDrive/DL4NLP/abstract-to-title-generation\")\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dqpfdl9a6sUx"
   },
   "outputs": [],
   "source": [
    "!cd \"{PROJECT_ROOT}\"\n",
    "sys.path.append(f\"{PROJECT_ROOT}/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_s7deoS1rrsa"
   },
   "outputs": [],
   "source": [
    "!pip install -r \"requirements.txt\" -f &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXY9zP1Orrsa"
   },
   "outputs": [],
   "source": [
    "#!dvc pull -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXU6DlgHrrsb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import Dataset\n",
    "from tqdm import trange \n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from transformers import BertModel,BertPreTrainedModel\n",
    "import torch.nn as nn\n",
    "from scipy import stats\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import model_utils\n",
    "import dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFuaCESNrrsb"
   },
   "outputs": [],
   "source": [
    "## Model Configurations\n",
    "p = {\n",
    "    'max_len': 512,\n",
    "    'batch_size': 6,\n",
    "    'lr': 4.0638e-05,\n",
    "    'epochs': 18, #18\n",
    "    'dropout': 0.5,\n",
    "    'num_threads': 1,\n",
    "    'model_name': 'allenai/scibert_scivocab_uncased',\n",
    "    #'model_name': 'bert-base-uncased',\n",
    "    'do_train': True,\n",
    "    'random_seed': 24\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwsPsv89rrsf"
   },
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i99Uf7oErrsg",
    "outputId": "25eba0e6-0d8b-434a-e39e-40ae8cf83903"
   },
   "outputs": [],
   "source": [
    "## Configuration loaded from AutoConfig \n",
    "aconfig = AutoConfig.from_pretrained(p['model_name'])\n",
    "## Tokenizer loaded from AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(p['model_name'])\n",
    "## Creating the model from the desired transformer model\n",
    "model = model_utils.BertRegresser.from_pretrained(p['model_name'], config=aconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHCn7mIQrrsh",
    "outputId": "cdca0d8d-3054-47a5-f739-d00d70129251"
   },
   "outputs": [],
   "source": [
    "#freeze all layers except regression head\n",
    "\n",
    "unfreeze_layers = ['bert.pooler', 'regressor.1']\n",
    "for name, params in model.named_parameters():\n",
    "  params.requires_grad = False\n",
    "  for ele in unfreeze_layers:\n",
    "    if ele in name:\n",
    "      params.requires_grad = True\n",
    "      break\n",
    "\n",
    "for name, params in model.named_parameters():\n",
    "  if params.requires_grad:\n",
    "    print(name, params.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEm9xCBXrrsh"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "## Putting model to device\n",
    "model = model.to(device)\n",
    "## Takes as the input the logits of the positive class and computes the binary cross-entropy \n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.MSELoss()\n",
    "## Optimizer\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=p['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1RqSFXRrrsi"
   },
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QslYO9JF6sU0",
    "outputId": "32b25257-0b6f-48b1-ef31-6b00c227d605"
   },
   "outputs": [],
   "source": [
    "annotations = pd.read_json(f'{DATA_DIR}/annotated/dataset_230samples.json')\n",
    "\n",
    "train_loader, dev_loader, test_loader = dataset_utils.gen_datasets(\n",
    "    tokenizer,\n",
    "    annotations,\n",
    "    p[\"max_len\"],\n",
    "    p[\"batch_size\"],\n",
    "    p[\"num_threads\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UyUMhVerrsk"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "sY2HnoMprrsl",
    "outputId": "b90fc21f-9948-4ce0-cc74-f6408f994f87"
   },
   "outputs": [],
   "source": [
    "# Do Train (do not use this for training of reward model, reward model trained using ray tune)\n",
    "\n",
    "if p['do_train']:\n",
    "  model_utils.train(model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=dev_loader,\n",
    "    epochs = p['epochs'],\n",
    "    device = device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJlhS6hthq2C"
   },
   "source": [
    "### Save model checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "biuNzG6stwPQ"
   },
   "outputs": [],
   "source": [
    "stats_df = pd.DataFrame(np.array(training_stats))\n",
    "stats_df.columns = [\"episode\", \"accuracy\", \"val_loss\"]\n",
    "display(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0KSJBkuhuYM"
   },
   "outputs": [],
   "source": [
    "save_folder = f\"{PROJECT_ROOT}/reward_model/finetuned_size{df_len}_ep{p['epochs']}_{datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d__%H_%M_%S')}\"\n",
    "save_file = \"model.pth\"\n",
    "save_path = f\"{save_folder}/{save_file}\"\n",
    "\n",
    "Path(save_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), save_path)\n",
    "stats_df.to_csv(f\"{save_folder}/stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2axQHWgTrrsl"
   },
   "source": [
    "### Load best read model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCURJRfOrrsl"
   },
   "outputs": [],
   "source": [
    "model_state, optimizer_state = torch.load(os.path.join(f'{PROJECT_ROOT}/reward_model/{save_path}', \"checkpoint\"))\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uUPiodtU6sU2",
    "outputId": "1bfb6918-8db4-4461-f6fc-644bd3913f00"
   },
   "outputs": [],
   "source": [
    "model = model_utils.BertRegresser.from_pretrained(p['model_name'], config=aconfig)\n",
    "\n",
    "model_path = f\"{PROJECT_ROOT}/reward_model/finetuned_size230_ep18_2022-08-08__15_59_58_05/model.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVDr7DC280wN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Je7iG4Fvrrsl"
   },
   "source": [
    "\n",
    "## Display Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npbQ_Oxprrsl"
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    predicted_label = []\n",
    "    actual_label = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, target in (dataloader):\n",
    "            \n",
    "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "            output = model(input_ids, attention_mask)\n",
    "                        \n",
    "            predicted_label += output\n",
    "            actual_label += target\n",
    "            \n",
    "    return predicted_label, actual_label\n",
    "\n",
    "def display_correlation(model, loader, device):\n",
    "    output,GS_label = predict(model, loader, device)\n",
    "    cpu_output = np.array([x.cpu().data.numpy() for x in output]).squeeze()\n",
    "    cpu_target = np.array([x.cpu().data.numpy() for x in GS_label]).squeeze()\n",
    "    print(stats.spearmanr(cpu_output, cpu_target)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "th5WSUdMrrsl"
   },
   "outputs": [],
   "source": [
    "print(\"Train\")\n",
    "display_correlation(model, train_loader, device)\n",
    "print(\"Dev\")\n",
    "display_correlation(model, dev_loader, device)\n",
    "print(\"Test\")\n",
    "display_correlation(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PXwJN5U6sU3"
   },
   "source": [
    "## Train Humor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "VsUTc-GF6sU3",
    "outputId": "af28d0b1-da4a-477f-bc37-0ab47dac89e8"
   },
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(f'{DATA_DIR}/humor/quirky_annotated.csv')\n",
    "quality_model = model\n",
    "\n",
    "# annotate quality score with quality_model\n",
    "df = dataset_utils.gen_humor_dataframe(\n",
    "    tokenizer,\n",
    "    quality_model,\n",
    "    device,\n",
    "    annotations,\n",
    "    p[\"max_len\"],\n",
    "    p[\"num_threads\"]\n",
    ")\n",
    "\n",
    "display(df)\n",
    "\n",
    "humor_model = model_utils.HumorBertRegresser.from_pretrained(p['model_name'], config=aconfig)\n",
    "#humor_model.load_state_dict(torch.load(model_path))\n",
    "humor_tokenizer = AutoTokenizer.from_pretrained(p['model_name'])\n",
    "humor_model.to(device)\n",
    "humor_tokenizer, humor_model = dataset_utils.add_humor_token(humor_tokenizer, humor_model)\n",
    "\n",
    "train_loader, dev_loader, test_loader = dataset_utils.gen_humor_datasets(\n",
    "    humor_tokenizer,\n",
    "    df,\n",
    "    p[\"max_len\"],\n",
    "    p[\"num_threads\"]\n",
    ")\n",
    "\n",
    "## HUMOR Optimizer\n",
    "humor_optimizer = optim.Adam(params=humor_model.parameters(), lr=p['lr'])\n",
    "\n",
    "unfreeze_layers = ['bert.pooler', 'regressor.1']\n",
    "for name, params in humor_model.named_parameters():\n",
    "  params.requires_grad = False\n",
    "  for ele in unfreeze_layers:\n",
    "    if ele in name:\n",
    "      params.requires_grad = True\n",
    "      break\n",
    "\n",
    "for name, params in humor_model.named_parameters():\n",
    "  if params.requires_grad:\n",
    "    print(name, params.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGXrF39Obit7"
   },
   "outputs": [],
   "source": [
    "def evaluate_humor(model, criterion, dataloader, device):\n",
    "    assert dataloader.dataset.humor\n",
    "    model.eval()\n",
    "    mean_acc, mean_loss, count = 0, 0, 0\n",
    "    preds = []\n",
    "    lst_label = []\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    def axis_corr(preds, labels, ax):\n",
    "        \"\"\"predss = np.array([x.tolist() for x in preds[:, ax]])#.squeeze()\n",
    "        lst_labels = np.array([x.tolist() for x in labels[:, ax]])#.squeeze()\"\"\"\n",
    "        preds_labels = np.array([preds[:, ax], labels[:, ax]])\n",
    "        return stats.spearmanr(preds_labels, axis=1)[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, target in (dataloader):\n",
    "\n",
    "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "            output = model(input_ids, attention_mask)\n",
    "            preds += output.cpu().data.numpy().tolist()\n",
    "            lst_label += target.cpu().data.numpy().tolist()\n",
    "            mean_loss += criterion(output, target.type_as(output)).item()\n",
    "            # mean_err += get_rmse(output, target)\n",
    "            count += 1\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        lst_label = np.array(lst_label)\n",
    "        plt.plot(preds[:,0])\n",
    "        plt.plot(lst_label[:,0])\n",
    "        plt.show()\n",
    "\n",
    "    return [axis_corr(preds, lst_label, ax) for ax in [0, 1]] #mean_loss/count\n",
    "\n",
    "def train_humor(model, criterion, optimizer, train_loader, val_loader, epochs, device):\n",
    "    # used for predicting target quality\n",
    "    assert train_loader.dataset.humor\n",
    "    assert val_loader.dataset.humor\n",
    "    for epoch in trange(epochs, desc=\"Epoch\"):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for i, (input_ids, attention_mask, target) in enumerate(iterable=train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "            output = model(input_ids, attention_mask)\n",
    "            loss = criterion(output, target.type_as(output))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        print(f\"Training loss is {train_loss/len(train_loader)}\")\n",
    "        val_loss = evaluate_humor(model, criterion=criterion, dataloader=val_loader, device=device)\n",
    "        print(\"Epoch {} complete! Correlations : {}\".format(epoch, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CqlH0CTC6sU3",
    "outputId": "26907911-4b04-4c6e-d813-0c28d4c46f4a"
   },
   "outputs": [],
   "source": [
    "if p['do_train']:\n",
    "    train_humor(\n",
    "        model=humor_model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=dev_loader,\n",
    "        epochs = p['epochs'],\n",
    "        device = device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mslp82Mnok2i",
    "outputId": "a09e2bec-6c35-442a-bf42-28277b1f4219"
   },
   "outputs": [],
   "source": [
    "#stats.spearmanr(np.array([[0.16607934, 0.08131046, -0.50477946, 0.19450632, -0.10593899],[0.13920161, 0.07102472, 0.25097752, 0.09419987, 0.03158583]]), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5hMDN6f6sU3"
   },
   "source": [
    "### Evaluate Humor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fOy5xQT6sU3"
   },
   "outputs": [],
   "source": [
    "print(\"Train\")\n",
    "display_correlation(humor_model, train_loader, device)\n",
    "print(\"Dev\")\n",
    "display_correlation(humor_model, dev_loader, device)\n",
    "print(\"Test\")\n",
    "display_correlation(humor_model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "reward_model-tmp.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('abstract-to-title')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "846c63257c8068d961f9bc7a1cc6d5c293f004d697fb3a71f59faad032bcda7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
