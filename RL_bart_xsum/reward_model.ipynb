{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4XjWOY_rrsW",
    "outputId": "60d7d450-a57e-44de-bcdc-7c9697aaae66"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "sys.path.append(\"/content/drive/MyDrive/DL4NLP/abstract-to-title-generation\")\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_s7deoS1rrsa",
    "outputId": "ab5b410a-5c44-45b1-a34a-11a6d61244d2"
   },
   "outputs": [],
   "source": [
    "!pip install -r \"{PROJECT_ROOT}/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXY9zP1Orrsa",
    "outputId": "58e75b9e-60cb-4c6a-904d-d0f95382465f"
   },
   "outputs": [],
   "source": [
    "!dvc pull -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXU6DlgHrrsb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import Dataset\n",
    "from tqdm import trange \n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from transformers import BertModel,BertPreTrainedModel\n",
    "import torch.nn as nn\n",
    "from scipy import stats\n",
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from model_utils import BertRegresser, Excerpt_Dataset, map2index, map_model, train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFuaCESNrrsb"
   },
   "outputs": [],
   "source": [
    "## Model Configurations\n",
    "p={\n",
    "    'max_len': 512,\n",
    "    'batch_size': 6,\n",
    "    'lr' : 4.0638e-05,\n",
    "    'epochs': 18, #18\n",
    "    'dropout': 0.5,\n",
    "    'num_threads' : 1,\n",
    "    'model_name' : 'allenai/scibert_scivocab_uncased',\n",
    "    #'model_name' : 'bert-base-uncased',\n",
    "    'do_train' : True,\n",
    "    'random_seed': 24\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwsPsv89rrsf"
   },
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i99Uf7oErrsg",
    "outputId": "61d76f3d-dd1b-4f7a-f00a-f9b01ce69878"
   },
   "outputs": [],
   "source": [
    "## Configuration loaded from AutoConfig \n",
    "aconfig = AutoConfig.from_pretrained(p['model_name'])\n",
    "## Tokenizer loaded from AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(p['model_name'])\n",
    "## Creating the model from the desired transformer model\n",
    "model = BertRegresser.from_pretrained(p['model_name'], config=aconfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHCn7mIQrrsh",
    "outputId": "77dbfef9-1266-4036-eee4-6d16a94b6879"
   },
   "outputs": [],
   "source": [
    "#freeze all layers except regression head\n",
    "\n",
    "unfreeze_layers = ['bert.pooler', 'regressor.1']\n",
    "for name, params in model.named_parameters():\n",
    "  params.requires_grad = False\n",
    "  for ele in unfreeze_layers:\n",
    "    if ele in name:\n",
    "      params.requires_grad = True\n",
    "      break\n",
    "\n",
    "for name, params in model.named_parameters():\n",
    "  if params.requires_grad:\n",
    "    print(name, params.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEm9xCBXrrsh"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "## Putting model to device\n",
    "model = model.to(device)\n",
    "## Takes as the input the logits of the positive class and computes the binary cross-entropy \n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.MSELoss()\n",
    "## Optimizer\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=p['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1RqSFXRrrsi"
   },
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LYJJbx3q5gaC",
    "outputId": "26f18789-cc7e-41ee-9062-128ab1e31453"
   },
   "outputs": [],
   "source": [
    "title_classes = ['human_title', 'bart_base', 'bart_cnn', 'bart_xsum', 't5_small', 'gpt2', 'pegasus_xsum']\n",
    "annotations = pd.read_json(f'{DATA_DIR}/annotated/dataset_230samples.json')\n",
    "\n",
    "def match_titles(titles, classes, fillin):\n",
    "  matched_titles = []\n",
    "  for title_row in titles:\n",
    "      matched_row = []\n",
    "      row = dict(title_row)\n",
    "      for generator in classes:\n",
    "        if generator in row:\n",
    "          matched_row.append(row[generator])\n",
    "        else:\n",
    "          matched_row.append(fillin)\n",
    "        \n",
    "      matched_titles.append(matched_row)\n",
    "      \n",
    "  return matched_titles\n",
    "\n",
    "# title dataframe\n",
    "\n",
    "human_annotation_pairs = []\n",
    "matched = match_titles(annotations[2], title_classes[1:], fillin=\"\")\n",
    "print(matched[1])\n",
    "human_annotation_pairs = [[row[0], row[1]] + matched[idx] for idx, row in annotations.iterrows()]\n",
    "\n",
    "human_annotations_230 = pd.DataFrame(np.array(human_annotation_pairs))\n",
    "human_annotations_230.columns = [\"abstract\"] + title_classes\n",
    "display(human_annotations_230)\n",
    "\n",
    "human_annotations_230.to_csv(f'{DATA_DIR}/annotated/230_annotations_pairs.csv')\n",
    "\n",
    "# scores\n",
    "\n",
    "score_classes = [cls + \"_bws\" for cls in title_classes]\n",
    "human_scores = []\n",
    "matched_human_scores = match_titles(annotations[3], score_classes, fillin=\"\")\n",
    "human_scores = [matched_human_scores[idx] for idx in range(len(annotations))]\n",
    "\n",
    "human_scores_230 = pd.DataFrame(np.array(human_scores))\n",
    "human_scores_230.columns = title_classes\n",
    "display(human_scores_230)\n",
    "\n",
    "human_scores_230.to_csv(f'{DATA_DIR}/annotated/230_humanannotation_withoutunannotated.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "g0Bg27-grrsi",
    "outputId": "5e15c6dc-518b-41f3-a1c3-07db256410f4"
   },
   "outputs": [],
   "source": [
    "text_map = pd.read_csv(f'{DATA_DIR}/annotated/230_annotations_pairs.csv', index_col=0)\n",
    "scores = pd.read_csv(f'{DATA_DIR}/annotated/230_humanannotation_withoutunannotated.csv', index_col=0)\n",
    "text_map.fillna('', inplace=True)\n",
    "scores.fillna('', inplace=True)\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "HWccRjAzrrsi",
    "outputId": "a4c0a3ce-4660-4cb2-f1d8-9a1b3f4db998"
   },
   "outputs": [],
   "source": [
    "abstract_df =text_map[['abstract']]\n",
    "title_df = text_map[['human_title', 'bart_base', 'bart_cnn', 'bart_xsum', 't5_small', 'gpt2', 'pegasus_xsum']]\n",
    "abstract_np = abstract_df.to_numpy()\n",
    "scores_np = scores.to_numpy()\n",
    "title_np = title_df.to_numpy()\n",
    "title_np_picked = np.array([[s for s in list(row) if s != ''] for row in title_np])\n",
    "score_np_picked = np.array([[s for s in list(row) if s != ''] for row in scores_np])\n",
    "\"\"\"idx_map = [map2index(row) for row in map_model[:140]]\n",
    "title_np_picked = np.array([np.take(row1, np.sort(row2)) for row1, row2 in zip(title_np, idx_map)])\n",
    "score_np_picked = np.array([np.take(row1, np.sort(row2)) for row1, row2 in zip(scores_np, idx_map)])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asKg2Ke8rrsi"
   },
   "outputs": [],
   "source": [
    "pairs_np_picked = np.concatenate([abstract_np, title_np_picked,score_np_picked], axis=1)\n",
    "pairs_np_picked_shuffled = np.random.permutation(pairs_np_picked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfCEHVhxrrsj"
   },
   "outputs": [],
   "source": [
    "abstracs = pairs_np_picked_shuffled[:,:1]\n",
    "titles = pairs_np_picked_shuffled[:,1:7]\n",
    "scores = pairs_np_picked_shuffled[:,7:].astype(float)\n",
    "scores = np.around(scores, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDTOk7rsrrsj"
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "\n",
    "for ab, row1, row2 in zip(abstracs, titles, scores):\n",
    "  assert len(row1) == len(row2), f\"{len(row1)}, {len(row2)}\"\n",
    "  assert len(row1) == 6\n",
    "  for t, s in zip(row1, row2):\n",
    "    \n",
    "    if np.isnan(s):\n",
    "      print('found nan score')\n",
    "    if t=='':\n",
    "      print('found empty title')\n",
    "    lst.append([ab[0] + '[SEP]' + t, s])\n",
    "df = pd.DataFrame(np.array(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXOSOiXprrsj"
   },
   "outputs": [],
   "source": [
    "df.columns = ['excerpt', 'target']\n",
    "#dataframe = dataframe.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjJ3qoUqrrsj",
    "outputId": "aa96543f-c0c6-4e96-9c98-a86911b31401"
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "val_ration = 0.1\n",
    "test_ratio = 0.2\n",
    "df_len = 230\n",
    "train_range = round(6 * train_ratio * df_len)\n",
    "val_range = round(6 * val_ration * df_len)\n",
    "test_range = round(6 * test_ratio * df_len)\n",
    "\n",
    "print(f\"{train_range}-{val_range}-{test_range}\")\n",
    "\n",
    "dftrain = df[:train_range].reset_index(drop=True)\n",
    "dfdev = df[val_range:test_range].reset_index(drop=True)\n",
    "dftest = df[test_range:].reset_index(drop=True)\n",
    "\n",
    "Path(f'{OUTPUT_DIR}/reward_model_robust_test/').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dftrain.to_csv(f'{OUTPUT_DIR}/reward_model_robust_test/sciBert_shuffled_train.csv')\n",
    "dfdev.to_csv(f'{OUTPUT_DIR}/reward_model_robust_test/sciBert_shuffled_dev.csv')\n",
    "dftest.to_csv(f'{OUTPUT_DIR}/reward_model_robust_test/sciBert_shuffled_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UyUMhVerrsk"
   },
   "source": [
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xd-QPxOKrrsk"
   },
   "outputs": [],
   "source": [
    "train_set = Excerpt_Dataset(data=dftrain, maxlen=p['max_len'], tokenizer=tokenizer)\n",
    "dev_set = Excerpt_Dataset(data=dfdev, maxlen=p['max_len'], tokenizer=tokenizer)\n",
    "test_set = Excerpt_Dataset(data=dftest, maxlen=p['max_len'], tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57tZAnzarrsk"
   },
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak3e41RZrrsk"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set, batch_size=p['batch_size'], num_workers=p['num_threads'], shuffle=True)\n",
    "dev_loader = DataLoader(dataset=dev_set, batch_size=p['batch_size'], num_workers=p['num_threads'], shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=p['batch_size'], num_workers=p['num_threads'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sY2HnoMprrsl",
    "outputId": "698d75ba-ab49-473b-cb37-a8eb2923d6db"
   },
   "outputs": [],
   "source": [
    "# Do Train (do not use this for training of reward model, reward model trained using ray tune)\n",
    "\n",
    "if p['do_train']:\n",
    "  train(model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=dev_loader,\n",
    "    epochs = p['epochs'],\n",
    "    device = device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJlhS6hthq2C"
   },
   "source": [
    "### Save model checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "biuNzG6stwPQ",
    "outputId": "9aa2cfb2-3746-4cd3-abf0-dcf4703f374f"
   },
   "outputs": [],
   "source": [
    "stats_df = pd.DataFrame(np.array(training_stats))\n",
    "stats_df.columns = [\"episode\", \"accuracy\", \"val_loss\"]\n",
    "display(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0KSJBkuhuYM"
   },
   "outputs": [],
   "source": [
    "save_folder = f\"{PROJECT_ROOT}/reward_model/finetuned_size{df_len}_ep{p['epochs']}_{datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d__%H_%M_%S')}\"\n",
    "save_file = \"model.pth\"\n",
    "save_path = f\"{save_folder}/{save_file}\"\n",
    "\n",
    "Path(save_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), save_path)\n",
    "stats_df.to_csv(f\"{save_folder}/stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2axQHWgTrrsl"
   },
   "source": [
    "### Load best read model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCURJRfOrrsl",
    "outputId": "11d6227a-55bd-4aa3-c641-02303a758682"
   },
   "outputs": [],
   "source": [
    "model_state, optimizer_state = torch.load(os.path.join(f'{PROJECT_ROOT}/reward_model/{save_path}', \"checkpoint\"))\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyhA9-_Drrsl"
   },
   "source": [
    "### Title prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npbQ_Oxprrsl"
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    predicted_label = []\n",
    "    actual_label = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, target in (dataloader):\n",
    "            \n",
    "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "            output = model(input_ids, attention_mask)\n",
    "                        \n",
    "            predicted_label += output\n",
    "            actual_label += target\n",
    "            \n",
    "    return predicted_label, actual_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Je7iG4Fvrrsl"
   },
   "source": [
    "\n",
    "## Display Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOQmOEHj3CS2",
    "outputId": "d4aec723-537d-4f9e-a2ad-85b57e3b53da"
   },
   "outputs": [],
   "source": [
    "model = BertRegresser.from_pretrained(p['model_name'], config=aconfig)\n",
    "model.load_state_dict(torch.load(f\"{PROJECT_ROOT}/reward_model/finetuned_size230_ep18_2022-08-08__14_05_45_false/model.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "th5WSUdMrrsl",
    "outputId": "b9dfba1a-f230-426e-852f-052195fb3a29"
   },
   "outputs": [],
   "source": [
    "output,GS_label = predict(model, train_loader, device)\n",
    "cpu_output = np.array([x.cpu().data.numpy() for x in output]).squeeze()\n",
    "cpu_target = np.array([x.cpu().data.numpy() for x in GS_label]).squeeze()\n",
    "stats.spearmanr(cpu_output, cpu_target)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8i9B84P1rrsm",
    "outputId": "bd82ab0a-d769-4f9b-b242-274b77168273"
   },
   "outputs": [],
   "source": [
    "dev_output,dev_GS_label = predict(model, dev_loader, device)\n",
    "cpu_dev_output = np.array([x.cpu().data.numpy() for x in dev_output]).squeeze()\n",
    "cpu_dev_target = np.array([x.cpu().data.numpy() for x in dev_GS_label]).squeeze()\n",
    "stats.spearmanr(cpu_dev_output, cpu_dev_target)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5hKG7OGrrsm",
    "outputId": "5ce85837-d661-4e58-e771-c0281192a32f"
   },
   "outputs": [],
   "source": [
    "test_output,test_GS_label = predict(model, test_loader, device)\n",
    "cpu_test_output = np.array([x.cpu().data.numpy() for x in test_output]).squeeze()\n",
    "cpu_test_target = np.array([x.cpu().data.numpy() for x in test_GS_label]).squeeze()\n",
    "stats.spearmanr(cpu_test_output, cpu_test_target)[0]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "reward_model.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('abstract-to-title')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "846c63257c8068d961f9bc7a1cc6d5c293f004d697fb3a71f59faad032bcda7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
