{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4XjWOY_rrsW",
    "outputId": "60d7d450-a57e-44de-bcdc-7c9697aaae66"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "sys.path.append(\"/content/drive/MyDrive/DL4NLP/abstract-to-title-generation\")\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd \"{PROJECT_ROOT}\"\n",
    "sys.path.append(f\"{PROJECT_ROOT}/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_s7deoS1rrsa",
    "outputId": "ab5b410a-5c44-45b1-a34a-11a6d61244d2"
   },
   "outputs": [],
   "source": [
    "#!pip install -r \"requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXY9zP1Orrsa",
    "outputId": "58e75b9e-60cb-4c6a-904d-d0f95382465f"
   },
   "outputs": [],
   "source": [
    "#!dvc pull -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXU6DlgHrrsb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import Dataset\n",
    "from tqdm import trange \n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from transformers import BertModel,BertPreTrainedModel\n",
    "import torch.nn as nn\n",
    "from scipy import stats\n",
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from model_utils import BertRegresser, Excerpt_Dataset, map2index, map_model, train, evaluate\n",
    "from dataset_utils import gen_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFuaCESNrrsb"
   },
   "outputs": [],
   "source": [
    "## Model Configurations\n",
    "p = {\n",
    "    'max_len': 512,\n",
    "    'batch_size': 6,\n",
    "    'lr': 4.0638e-05,\n",
    "    'epochs': 18, #18\n",
    "    'dropout': 0.5,\n",
    "    'num_threads': 1,\n",
    "    'model_name': 'allenai/scibert_scivocab_uncased',\n",
    "    #'model_name': 'bert-base-uncased',\n",
    "    'do_train': True,\n",
    "    'random_seed': 24\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwsPsv89rrsf"
   },
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i99Uf7oErrsg",
    "outputId": "61d76f3d-dd1b-4f7a-f00a-f9b01ce69878"
   },
   "outputs": [],
   "source": [
    "## Configuration loaded from AutoConfig \n",
    "aconfig = AutoConfig.from_pretrained(p['model_name'])\n",
    "## Tokenizer loaded from AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(p['model_name'])\n",
    "## Creating the model from the desired transformer model\n",
    "model = BertRegresser.from_pretrained(p['model_name'], config=aconfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHCn7mIQrrsh",
    "outputId": "77dbfef9-1266-4036-eee4-6d16a94b6879"
   },
   "outputs": [],
   "source": [
    "#freeze all layers except regression head\n",
    "\n",
    "unfreeze_layers = ['bert.pooler', 'regressor.1']\n",
    "for name, params in model.named_parameters():\n",
    "  params.requires_grad = False\n",
    "  for ele in unfreeze_layers:\n",
    "    if ele in name:\n",
    "      params.requires_grad = True\n",
    "      break\n",
    "\n",
    "for name, params in model.named_parameters():\n",
    "  if params.requires_grad:\n",
    "    print(name, params.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEm9xCBXrrsh"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "## Putting model to device\n",
    "model = model.to(device)\n",
    "## Takes as the input the logits of the positive class and computes the binary cross-entropy \n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.MSELoss()\n",
    "## Optimizer\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=p['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1RqSFXRrrsi"
   },
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_json(f'{DATA_DIR}/annotated/dataset_230samples.json')\n",
    "\n",
    "train_loader, dev_loader, test_loader = gen_datasets(\n",
    "    tokenizer,\n",
    "    annotations,\n",
    "    p[\"max_len\"],\n",
    "    p[\"batch_size\"],\n",
    "    p[\"num_threads\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UyUMhVerrsk"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sY2HnoMprrsl",
    "outputId": "698d75ba-ab49-473b-cb37-a8eb2923d6db"
   },
   "outputs": [],
   "source": [
    "# Do Train (do not use this for training of reward model, reward model trained using ray tune)\n",
    "\n",
    "if p['do_train']:\n",
    "  train(model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=dev_loader,\n",
    "    epochs = p['epochs'],\n",
    "    device = device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJlhS6hthq2C"
   },
   "source": [
    "### Save model checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "biuNzG6stwPQ",
    "outputId": "9aa2cfb2-3746-4cd3-abf0-dcf4703f374f"
   },
   "outputs": [],
   "source": [
    "stats_df = pd.DataFrame(np.array(training_stats))\n",
    "stats_df.columns = [\"episode\", \"accuracy\", \"val_loss\"]\n",
    "display(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0KSJBkuhuYM"
   },
   "outputs": [],
   "source": [
    "save_folder = f\"{PROJECT_ROOT}/reward_model/finetuned_size{df_len}_ep{p['epochs']}_{datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d__%H_%M_%S')}\"\n",
    "save_file = \"model.pth\"\n",
    "save_path = f\"{save_folder}/{save_file}\"\n",
    "\n",
    "Path(save_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), save_path)\n",
    "stats_df.to_csv(f\"{save_folder}/stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2axQHWgTrrsl"
   },
   "source": [
    "### Load best read model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCURJRfOrrsl",
    "outputId": "11d6227a-55bd-4aa3-c641-02303a758682"
   },
   "outputs": [],
   "source": [
    "model_state, optimizer_state = torch.load(os.path.join(f'{PROJECT_ROOT}/reward_model/{save_path}', \"checkpoint\"))\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyhA9-_Drrsl"
   },
   "source": [
    "### Title prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npbQ_Oxprrsl"
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    predicted_label = []\n",
    "    actual_label = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, target in (dataloader):\n",
    "            \n",
    "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "            output = model(input_ids, attention_mask)\n",
    "                        \n",
    "            predicted_label += output\n",
    "            actual_label += target\n",
    "            \n",
    "    return predicted_label, actual_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Je7iG4Fvrrsl"
   },
   "source": [
    "\n",
    "## Display Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOQmOEHj3CS2",
    "outputId": "d4aec723-537d-4f9e-a2ad-85b57e3b53da"
   },
   "outputs": [],
   "source": [
    "model = BertRegresser.from_pretrained(p['model_name'], config=aconfig)\n",
    "model.load_state_dict(torch.load(f\"{PROJECT_ROOT}/reward_model/finetuned_size230_ep18_2022-08-08__14_05_45_false/model.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "th5WSUdMrrsl",
    "outputId": "b9dfba1a-f230-426e-852f-052195fb3a29"
   },
   "outputs": [],
   "source": [
    "output,GS_label = predict(model, train_loader, device)\n",
    "cpu_output = np.array([x.cpu().data.numpy() for x in output]).squeeze()\n",
    "cpu_target = np.array([x.cpu().data.numpy() for x in GS_label]).squeeze()\n",
    "stats.spearmanr(cpu_output, cpu_target)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8i9B84P1rrsm",
    "outputId": "bd82ab0a-d769-4f9b-b242-274b77168273"
   },
   "outputs": [],
   "source": [
    "dev_output,dev_GS_label = predict(model, dev_loader, device)\n",
    "cpu_dev_output = np.array([x.cpu().data.numpy() for x in dev_output]).squeeze()\n",
    "cpu_dev_target = np.array([x.cpu().data.numpy() for x in dev_GS_label]).squeeze()\n",
    "stats.spearmanr(cpu_dev_output, cpu_dev_target)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5hKG7OGrrsm",
    "outputId": "5ce85837-d661-4e58-e771-c0281192a32f"
   },
   "outputs": [],
   "source": [
    "test_output,test_GS_label = predict(model, test_loader, device)\n",
    "cpu_test_output = np.array([x.cpu().data.numpy() for x in test_output]).squeeze()\n",
    "cpu_test_target = np.array([x.cpu().data.numpy() for x in test_GS_label]).squeeze()\n",
    "stats.spearmanr(cpu_test_output, cpu_test_target)[0]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "reward_model.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('abstract-to-title')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "846c63257c8068d961f9bc7a1cc6d5c293f004d697fb3a71f59faad032bcda7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
